{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-textbook",
   "metadata": {},
   "source": [
    "## Experiment on number of layers and pL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.neuralnets.StochasticNet import StochasticNet\n",
    "from utils.trainer import train\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D,Input,Flatten,Dense\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-vinyl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       " 'test': <PrefetchDataset shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
       " 'extra': <PrefetchDataset shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=tfds.load('svhn_cropped')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "filled-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(data1,data2,number_of_samples=[400,100]):\n",
    "    val = []\n",
    "    val_label = []\n",
    "    train = []\n",
    "    train_label =[]\n",
    "    label_count = np.zeros(10)\n",
    "    for sample in data1:\n",
    "        if label_count[sample['label']] < number_of_samples[0]:\n",
    "            val.append(sample['image'].numpy().astype('float32'))\n",
    "            val_label.append(sample['label'].numpy().astype('float32'))\n",
    "            label_count[sample['label']] += 1\n",
    "        else:\n",
    "            train.append(sample['image'].numpy().astype('float32'))\n",
    "            train_label.append(sample['label'].numpy().astype('float32'))\n",
    "    label_count = np.zeros(10)\n",
    "    extra_count = 0\n",
    "    for sample in data2:\n",
    "        if label_count[sample['label']] < number_of_samples[1]:\n",
    "            val.append(sample['image'].numpy().astype('float32'))\n",
    "            val_label.append(sample['label'].numpy().astype('float32'))\n",
    "            label_count[sample['label']] += 1\n",
    "        else:\n",
    "            train.append(sample['image'].numpy().astype('float32'))\n",
    "            train_label.append(sample['label'].numpy().astype('float32'))\n",
    "        extra_count += 1\n",
    "        if extra_count > 30000:\n",
    "            break\n",
    "    return (np.array(train),np.array(train_label)),(np.array(val),np.array(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcc13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_val_split(data['train'],data['extra'])\n",
    "x_train ,y_train = train_data\n",
    "x_val, y_val = val_data\n",
    "x_test = np.array([sample['image'].numpy().astype('float32') for sample in data['test']])\n",
    "y_test = np.array([sample['label'].numpy().astype('float32') for sample in data['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badd7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [20,38,56,74,92]\n",
    "prob = [0.5,0.6,0.7,0.8,0.9,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1324d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "num_class = 10\n",
    "batch_size = 128\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e1cc0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "Training loss at step 0: 8.9014\n",
      "Training loss at step 200: 2.3360\n",
      "Training loss at step 400: 2.2421\n",
      "Training loss at step 600: 2.2826\n",
      "Training accuracy: 0.1877 Validation accuracy: 0.1286 Time taken: 233.44s\n",
      "Epoch 2/24\n",
      "Training loss at step 0: 2.1879\n",
      "Training loss at step 200: 1.4141\n",
      "Training loss at step 400: 0.8798\n",
      "Training loss at step 600: 0.4570\n",
      "Training accuracy: 0.6419 Validation accuracy: 0.8046 Time taken: 218.96s\n",
      "Epoch 3/24\n",
      "Training loss at step 0: 4.2538\n",
      "Training loss at step 200: 0.4328\n",
      "Training loss at step 400: 0.4018\n",
      "Training loss at step 600: 0.1841\n",
      "Training accuracy: 0.8861 Validation accuracy: 0.8756 Time taken: 218.36s\n",
      "Epoch 4/24\n",
      "Training loss at step 0: 3.9273\n",
      "Training loss at step 200: 0.2743\n",
      "Training loss at step 400: 0.3195\n",
      "Training loss at step 600: 0.0760\n",
      "Training accuracy: 0.9218 Validation accuracy: 0.8872 Time taken: 217.93s\n",
      "Epoch 5/24\n",
      "Training loss at step 0: 3.4804\n",
      "Training loss at step 200: 0.2081\n",
      "Training loss at step 400: 0.2838\n",
      "Training loss at step 600: 0.0422\n",
      "Training accuracy: 0.9379 Validation accuracy: 0.8844 Time taken: 216.96s\n",
      "Epoch 6/24\n",
      "Training loss at step 0: 2.9344\n",
      "Training loss at step 200: 0.1315\n",
      "Training loss at step 400: 0.2457\n",
      "Training loss at step 600: 0.0325\n",
      "Training accuracy: 0.9500 Validation accuracy: 0.8844 Time taken: 217.71s\n",
      "Epoch 7/24\n",
      "Training loss at step 0: 2.7549\n",
      "Training loss at step 200: 0.0835\n",
      "Training loss at step 400: 0.1814\n",
      "Training loss at step 600: 0.0465\n",
      "Training accuracy: 0.9564 Validation accuracy: 0.8824 Time taken: 217.07s\n",
      "Epoch 8/24\n",
      "Training loss at step 0: 2.3907\n",
      "Training loss at step 200: 0.0701\n",
      "Training loss at step 400: 0.1835\n",
      "Training loss at step 600: 0.0331\n",
      "Training accuracy: 0.9627 Validation accuracy: 0.8842 Time taken: 217.10s\n",
      "Epoch 9/24\n",
      "Training loss at step 0: 2.3174\n",
      "Training loss at step 200: 0.0674\n",
      "Training loss at step 400: 0.1160\n",
      "Training loss at step 600: 0.0202\n",
      "Training accuracy: 0.9676 Validation accuracy: 0.9074 Time taken: 217.13s\n",
      "Epoch 10/24\n",
      "Training loss at step 0: 2.2242\n",
      "Training loss at step 200: 0.0461\n",
      "Training loss at step 400: 0.1213\n",
      "Training loss at step 600: 0.0394\n",
      "Training accuracy: 0.9709 Validation accuracy: 0.8836 Time taken: 216.27s\n",
      "Epoch 11/24\n",
      "Training loss at step 0: 1.8243\n",
      "Training loss at step 200: 0.0250\n",
      "Training loss at step 400: 0.0805\n",
      "Training loss at step 600: 0.0147\n",
      "Training accuracy: 0.9753 Validation accuracy: 0.9088 Time taken: 213.78s\n",
      "Epoch 12/24\n",
      "Training loss at step 0: 1.5832\n",
      "Training loss at step 200: 0.0351\n",
      "Training loss at step 400: 0.1457\n",
      "Training loss at step 600: 0.0454\n",
      "Training accuracy: 0.9765 Validation accuracy: 0.9026 Time taken: 217.09s\n",
      "Epoch 13/24\n",
      "Training loss at step 0: 2.0642\n",
      "Training loss at step 200: 0.0255\n",
      "Training loss at step 400: 0.0318\n",
      "Training loss at step 600: 0.0056\n",
      "Training accuracy: 0.9838 Validation accuracy: 0.9334 Time taken: 216.97s\n",
      "Epoch 14/24\n",
      "Training loss at step 0: 1.0640\n",
      "Training loss at step 200: 0.0135\n",
      "Training loss at step 400: 0.0191\n",
      "Training loss at step 600: 0.0020\n",
      "Training accuracy: 0.9913 Validation accuracy: 0.9334 Time taken: 216.90s\n",
      "Epoch 15/24\n",
      "Training loss at step 0: 0.7371\n",
      "Training loss at step 200: 0.0098\n",
      "Training loss at step 400: 0.0148\n",
      "Training loss at step 600: 0.0020\n",
      "Training accuracy: 0.9938 Validation accuracy: 0.9332 Time taken: 216.37s\n",
      "Epoch 16/24\n",
      "Training loss at step 0: 0.5851\n",
      "Training loss at step 200: 0.0077\n",
      "Training loss at step 400: 0.0121\n",
      "Training loss at step 600: 0.0020\n",
      "Training accuracy: 0.9955 Validation accuracy: 0.9308 Time taken: 217.50s\n",
      "Epoch 17/24\n",
      "Training loss at step 0: 0.4797\n",
      "Training loss at step 200: 0.0063\n",
      "Training loss at step 400: 0.0095\n",
      "Training loss at step 600: 0.0019\n",
      "Training accuracy: 0.9965 Validation accuracy: 0.9308 Time taken: 216.95s\n",
      "Epoch 18/24\n",
      "Training loss at step 0: 0.4087\n",
      "Training loss at step 200: 0.0053\n",
      "Training loss at step 400: 0.0072\n",
      "Training loss at step 600: 0.0015\n",
      "Training accuracy: 0.9974 Validation accuracy: 0.9304 Time taken: 217.32s\n",
      "Epoch 19/24\n",
      "Training loss at step 0: 0.3472\n",
      "Training loss at step 200: 0.0038\n",
      "Training loss at step 400: 0.0047\n",
      "Training loss at step 600: 0.0008\n",
      "Training accuracy: 0.9975 Validation accuracy: 0.9286 Time taken: 218.47s\n",
      "Epoch 20/24\n",
      "Training loss at step 0: 0.2980\n",
      "Training loss at step 200: 0.0037\n",
      "Training loss at step 400: 0.0047\n",
      "Training loss at step 600: 0.0009\n",
      "Training accuracy: 0.9978 Validation accuracy: 0.9280 Time taken: 216.75s\n",
      "Epoch 21/24\n",
      "Training loss at step 0: 0.2796\n",
      "Training loss at step 200: 0.0036\n",
      "Training loss at step 400: 0.0047\n",
      "Training loss at step 600: 0.0009\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9280 Time taken: 217.23s\n",
      "Epoch 22/24\n",
      "Training loss at step 0: 0.2691\n",
      "Training loss at step 200: 0.0036\n",
      "Training loss at step 400: 0.0048\n",
      "Training loss at step 600: 0.0009\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9280 Time taken: 217.35s\n",
      "Epoch 23/24\n",
      "Training loss at step 0: 0.2617\n",
      "Training loss at step 200: 0.0035\n",
      "Training loss at step 400: 0.0048\n",
      "Training loss at step 600: 0.0009\n",
      "Training accuracy: 0.9981 Validation accuracy: 0.9282 Time taken: 217.34s\n",
      "Epoch 24/24\n",
      "Training loss at step 0: 0.2560\n",
      "Training loss at step 200: 0.0035\n",
      "Training loss at step 400: 0.0047\n",
      "Training loss at step 600: 0.0010\n",
      "Training accuracy: 0.9981 Validation accuracy: 0.9282 Time taken: 217.13s\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for d in depth:\n",
    "    for p in prob:\n",
    "        model = StochasticNet(input_shape=input_shape,num_class=num_class,layers=d, p_L=p)\n",
    "        result = train(model,d,p,train_data,validation_data,x_test,y_test)\n",
    "        results.append(result)\n",
    "        file = open('./Accuracies/acc', 'a')\n",
    "        file.write('{}\\t{}\\n'.format(result[1],result[2]))\n",
    "        file.close()\n",
    "        np.save(\"./Logs/StochasticNet%d_%1.2f\"%(d,p),result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ea188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
