{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-array",
   "metadata": {},
   "source": [
    "## Training of CIFAR-10 using 110-layer ResNet with stochastic depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.neuralnets.StochasticNet110 import StochasticNet110\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D,Input,Flatten,Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data and standardize\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = (x_train - np.mean(x_train,axis=0))/np.std(x_train,axis=0)\n",
    "x_test = (x_test - np.mean(x_test,axis=0))/np.std(x_test,axis=0)\n",
    "##train validation split, 45000 for training and 5000 for validation\n",
    "np.random.seed(42)\n",
    "mask_val = np.random.choice(50000,5000,replace=False)\n",
    "mask_train = np.array([i for i in range(50000) if i not in mask_val])\n",
    "x_val, y_val = x_train[mask_val], y_train[mask_val]\n",
    "x_train, y_train = x_train[mask_train], y_train[mask_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "filled-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation\n",
    "##augmented with horizontal flip,random erasing and random shift by 0.1\n",
    "batch_size = 128\n",
    "datagen_for_train = ImageDataGenerator(horizontal_flip=True,width_shift_range= 4, height_shift_range= 4)\n",
    "# datagen_for_train = ImageDataGenerator()\n",
    "datagen_for_test = ImageDataGenerator()\n",
    "train_data = datagen_for_train.flow(x_train,y_train,batch_size=batch_size)\n",
    "validation_data = datagen_for_test.flow(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "under-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a ResNet110 model\n",
    "input_shape = x_train.shape[1:]\n",
    "num_class = 10\n",
    "model = StochasticNet110(input_shape=input_shape,num_class=num_class,p_L=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southwest-assessment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training loss at step 0: 10.0834\n",
      "Training loss at step 100: 2.4759\n",
      "Training loss at step 200: 2.3316\n",
      "Training loss at step 300: 1.9350\n",
      "Training accuracy: 0.1780 Validation accuracy: 0.1938 Time taken: 113.31s\n",
      "Epoch 2/200\n",
      "Training loss at step 0: 2.2369\n",
      "Training loss at step 100: 2.1650\n",
      "Training loss at step 200: 1.7367\n",
      "Training loss at step 300: 1.7610\n",
      "Training accuracy: 0.2849 Validation accuracy: 0.3144 Time taken: 110.06s\n",
      "Epoch 3/200\n",
      "Training loss at step 0: 1.8301\n",
      "Training loss at step 100: 1.6720\n",
      "Training loss at step 200: 1.8505\n",
      "Training loss at step 300: 1.8446\n",
      "Training accuracy: 0.3460 Validation accuracy: 0.3492 Time taken: 110.71s\n",
      "Epoch 4/200\n",
      "Training loss at step 0: 1.6876\n",
      "Training loss at step 100: 1.6152\n",
      "Training loss at step 200: 1.5658\n",
      "Training loss at step 300: 1.6877\n",
      "Training accuracy: 0.3960 Validation accuracy: 0.3010 Time taken: 110.74s\n",
      "Epoch 5/200\n",
      "Training loss at step 0: 1.4059\n",
      "Training loss at step 100: 1.5422\n",
      "Training loss at step 200: 1.3237\n",
      "Training loss at step 300: 1.2261\n",
      "Training accuracy: 0.4386 Validation accuracy: 0.3780 Time taken: 110.58s\n",
      "Epoch 6/200\n",
      "Training loss at step 0: 1.4685\n",
      "Training loss at step 100: 1.4318\n",
      "Training loss at step 200: 1.1647\n",
      "Training loss at step 300: 1.3218\n",
      "Training accuracy: 0.4795 Validation accuracy: 0.4476 Time taken: 110.17s\n",
      "Epoch 7/200\n",
      "Training loss at step 0: 1.5797\n",
      "Training loss at step 100: 1.4394\n",
      "Training loss at step 200: 1.4159\n",
      "Training loss at step 300: 1.3316\n",
      "Training accuracy: 0.5147 Validation accuracy: 0.4872 Time taken: 110.02s\n",
      "Epoch 8/200\n",
      "Training loss at step 0: 1.3054\n",
      "Training loss at step 100: 1.3207\n",
      "Training loss at step 200: 1.1566\n",
      "Training loss at step 300: 0.9781\n",
      "Training accuracy: 0.5424 Validation accuracy: 0.4212 Time taken: 110.26s\n",
      "Epoch 9/200\n",
      "Training loss at step 0: 1.1346\n",
      "Training loss at step 100: 1.0924\n",
      "Training loss at step 200: 1.2113\n",
      "Training loss at step 300: 1.1097\n",
      "Training accuracy: 0.5681 Validation accuracy: 0.5070 Time taken: 109.76s\n",
      "Epoch 10/200\n",
      "Training loss at step 0: 1.3517\n",
      "Training loss at step 100: 1.1950\n",
      "Training loss at step 200: 1.1140\n",
      "Training loss at step 300: 1.4410\n",
      "Training accuracy: 0.5888 Validation accuracy: 0.5406 Time taken: 111.94s\n",
      "Epoch 11/200\n",
      "Training loss at step 0: 1.1024\n",
      "Training loss at step 100: 1.2357\n",
      "Training loss at step 200: 1.2508\n",
      "Training loss at step 300: 1.1034\n",
      "Training accuracy: 0.6062 Validation accuracy: 0.5794 Time taken: 109.63s\n",
      "Epoch 12/200\n",
      "Training loss at step 0: 1.1257\n",
      "Training loss at step 100: 0.9910\n",
      "Training loss at step 200: 0.9717\n",
      "Training loss at step 300: 0.9143\n",
      "Training accuracy: 0.6268 Validation accuracy: 0.6480 Time taken: 110.65s\n",
      "Epoch 13/200\n",
      "Training loss at step 0: 0.9933\n",
      "Training loss at step 100: 0.9885\n",
      "Training loss at step 200: 0.8542\n",
      "Training loss at step 300: 0.8745\n",
      "Training accuracy: 0.6412 Validation accuracy: 0.6008 Time taken: 111.16s\n",
      "Epoch 14/200\n",
      "Training loss at step 0: 0.9289\n",
      "Training loss at step 100: 0.9825\n",
      "Training loss at step 200: 0.9362\n",
      "Training loss at step 300: 1.0153\n",
      "Training accuracy: 0.6500 Validation accuracy: 0.5328 Time taken: 110.23s\n",
      "Epoch 15/200\n",
      "Training loss at step 0: 1.0157\n",
      "Training loss at step 100: 1.1597\n",
      "Training loss at step 200: 0.8146\n",
      "Training loss at step 300: 0.9986\n",
      "Training accuracy: 0.6602 Validation accuracy: 0.6708 Time taken: 109.43s\n",
      "Epoch 16/200\n",
      "Training loss at step 0: 0.9944\n",
      "Training loss at step 100: 0.8219\n",
      "Training loss at step 200: 0.8702\n",
      "Training loss at step 300: 0.8839\n",
      "Training accuracy: 0.6704 Validation accuracy: 0.6278 Time taken: 110.25s\n",
      "Epoch 17/200\n",
      "Training loss at step 0: 0.7731\n",
      "Training loss at step 100: 1.0342\n",
      "Training loss at step 200: 1.0690\n",
      "Training loss at step 300: 0.8561\n",
      "Training accuracy: 0.6786 Validation accuracy: 0.6092 Time taken: 109.67s\n",
      "Epoch 18/200\n",
      "Training loss at step 0: 0.9415\n",
      "Training loss at step 100: 0.9981\n",
      "Training loss at step 200: 0.7501\n",
      "Training loss at step 300: 0.8487\n",
      "Training accuracy: 0.6869 Validation accuracy: 0.7132 Time taken: 112.19s\n",
      "Epoch 19/200\n",
      "Training loss at step 0: 0.8976\n",
      "Training loss at step 100: 0.9229\n",
      "Training loss at step 200: 0.9004\n",
      "Training loss at step 300: 0.7220\n",
      "Training accuracy: 0.6964 Validation accuracy: 0.6876 Time taken: 110.44s\n",
      "Epoch 20/200\n",
      "Training loss at step 0: 0.7902\n",
      "Training loss at step 100: 0.7523\n",
      "Training loss at step 200: 0.6361\n",
      "Training loss at step 300: 0.7605\n",
      "Training accuracy: 0.7073 Validation accuracy: 0.6808 Time taken: 110.58s\n",
      "Epoch 21/200\n",
      "Training loss at step 0: 1.0062\n",
      "Training loss at step 100: 0.8763\n",
      "Training loss at step 200: 0.9435\n",
      "Training loss at step 300: 0.7391\n",
      "Training accuracy: 0.7153 Validation accuracy: 0.6662 Time taken: 109.94s\n",
      "Epoch 22/200\n",
      "Training loss at step 0: 0.7820\n",
      "Training loss at step 100: 0.7217\n",
      "Training loss at step 200: 0.7458\n",
      "Training loss at step 300: 0.9518\n",
      "Training accuracy: 0.7180 Validation accuracy: 0.7168 Time taken: 110.16s\n",
      "Epoch 23/200\n",
      "Training loss at step 0: 0.7362\n",
      "Training loss at step 100: 0.8504\n",
      "Training loss at step 200: 0.9609\n",
      "Training loss at step 300: 0.9141\n",
      "Training accuracy: 0.7269 Validation accuracy: 0.6942 Time taken: 109.59s\n",
      "Epoch 24/200\n",
      "Training loss at step 0: 0.8961\n",
      "Training loss at step 100: 0.5721\n",
      "Training loss at step 200: 0.6583\n",
      "Training loss at step 300: 0.6262\n",
      "Training accuracy: 0.7330 Validation accuracy: 0.6514 Time taken: 109.31s\n",
      "Epoch 25/200\n",
      "Training loss at step 0: 0.6329\n",
      "Training loss at step 100: 0.7744\n",
      "Training loss at step 200: 0.6309\n",
      "Training loss at step 300: 0.6048\n",
      "Training accuracy: 0.7394 Validation accuracy: 0.7222 Time taken: 108.48s\n",
      "Epoch 26/200\n",
      "Training loss at step 0: 0.7131\n",
      "Training loss at step 100: 0.6650\n",
      "Training loss at step 200: 0.8432\n",
      "Training loss at step 300: 0.7990\n",
      "Training accuracy: 0.7451 Validation accuracy: 0.7120 Time taken: 110.26s\n",
      "Epoch 27/200\n",
      "Training loss at step 0: 0.6884\n",
      "Training loss at step 100: 0.5551\n",
      "Training loss at step 200: 0.6388\n",
      "Training loss at step 300: 0.8626\n",
      "Training accuracy: 0.7527 Validation accuracy: 0.6438 Time taken: 108.28s\n",
      "Epoch 28/200\n",
      "Training loss at step 0: 0.5758\n",
      "Training loss at step 100: 0.5882\n",
      "Training loss at step 200: 0.8234\n",
      "Training loss at step 300: 0.7377\n",
      "Training accuracy: 0.7607 Validation accuracy: 0.7170 Time taken: 110.17s\n",
      "Epoch 29/200\n",
      "Training loss at step 0: 0.6491\n",
      "Training loss at step 100: 0.7758\n",
      "Training loss at step 200: 0.8032\n",
      "Training loss at step 300: 0.7027\n",
      "Training accuracy: 0.7666 Validation accuracy: 0.6826 Time taken: 109.81s\n",
      "Epoch 30/200\n",
      "Training loss at step 0: 0.6822\n",
      "Training loss at step 100: 0.8604\n",
      "Training loss at step 200: 0.5982\n",
      "Training loss at step 300: 0.5837\n",
      "Training accuracy: 0.7654 Validation accuracy: 0.7464 Time taken: 109.92s\n",
      "Epoch 31/200\n",
      "Training loss at step 0: 0.5770\n",
      "Training loss at step 100: 0.5840\n",
      "Training loss at step 200: 0.5537\n",
      "Training loss at step 300: 0.7040\n",
      "Training accuracy: 0.7728 Validation accuracy: 0.7204 Time taken: 109.50s\n",
      "Epoch 32/200\n",
      "Training loss at step 0: 0.5723\n",
      "Training loss at step 100: 0.5918\n",
      "Training loss at step 200: 0.5037\n",
      "Training loss at step 300: 0.5856\n",
      "Training accuracy: 0.7800 Validation accuracy: 0.7740 Time taken: 110.35s\n",
      "Epoch 33/200\n",
      "Training loss at step 0: 0.6326\n",
      "Training loss at step 100: 0.6272\n",
      "Training loss at step 200: 0.6226\n",
      "Training loss at step 300: 0.7789\n",
      "Training accuracy: 0.7846 Validation accuracy: 0.7404 Time taken: 109.77s\n",
      "Epoch 34/200\n",
      "Training loss at step 0: 0.7131\n",
      "Training loss at step 100: 0.6088\n",
      "Training loss at step 200: 0.4701\n",
      "Training loss at step 300: 0.6149\n",
      "Training accuracy: 0.7872 Validation accuracy: 0.7424 Time taken: 109.73s\n",
      "Epoch 35/200\n",
      "Training loss at step 0: 0.4669\n",
      "Training loss at step 100: 0.6467\n",
      "Training loss at step 200: 0.7074\n",
      "Training loss at step 300: 0.4679\n",
      "Training accuracy: 0.7899 Validation accuracy: 0.7664 Time taken: 109.59s\n",
      "Epoch 36/200\n",
      "Training loss at step 0: 0.9913\n",
      "Training loss at step 100: 0.6096\n",
      "Training loss at step 200: 0.6387\n",
      "Training loss at step 300: 0.3254\n",
      "Training accuracy: 0.7951 Validation accuracy: 0.7828 Time taken: 108.92s\n",
      "Epoch 37/200\n",
      "Training loss at step 0: 0.5746\n",
      "Training loss at step 100: 0.5098\n",
      "Training loss at step 200: 0.6446\n",
      "Training loss at step 300: 0.7147\n",
      "Training accuracy: 0.7998 Validation accuracy: 0.7978 Time taken: 109.44s\n",
      "Epoch 38/200\n",
      "Training loss at step 0: 0.6803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 100: 0.4981\n",
      "Training loss at step 200: 0.6194\n",
      "Training loss at step 300: 0.5166\n",
      "Training accuracy: 0.8033 Validation accuracy: 0.7444 Time taken: 109.07s\n",
      "Epoch 39/200\n",
      "Training loss at step 0: 0.5662\n",
      "Training loss at step 100: 0.6729\n",
      "Training loss at step 200: 0.4938\n",
      "Training loss at step 300: 0.3967\n",
      "Training accuracy: 0.8067 Validation accuracy: 0.7812 Time taken: 108.87s\n",
      "Epoch 40/200\n",
      "Training loss at step 0: 0.5644\n",
      "Training loss at step 100: 0.6582\n",
      "Training loss at step 200: 0.6305\n",
      "Training loss at step 300: 0.3041\n",
      "Training accuracy: 0.8106 Validation accuracy: 0.7792 Time taken: 108.42s\n",
      "Epoch 41/200\n",
      "Training loss at step 0: 0.6007\n",
      "Training loss at step 100: 0.5437\n",
      "Training loss at step 200: 0.4777\n",
      "Training loss at step 300: 0.6580\n",
      "Training accuracy: 0.8130 Validation accuracy: 0.7762 Time taken: 110.09s\n",
      "Epoch 42/200\n",
      "Training loss at step 0: 0.4132\n",
      "Training loss at step 100: 0.5441\n",
      "Training loss at step 200: 0.5301\n",
      "Training loss at step 300: 0.5395\n",
      "Training accuracy: 0.8180 Validation accuracy: 0.7642 Time taken: 108.50s\n",
      "Epoch 43/200\n",
      "Training loss at step 0: 0.5607\n",
      "Training loss at step 100: 0.5970\n",
      "Training loss at step 200: 0.4534\n",
      "Training loss at step 300: 0.5255\n",
      "Training accuracy: 0.8192 Validation accuracy: 0.7944 Time taken: 109.74s\n",
      "Epoch 44/200\n",
      "Training loss at step 0: 0.4448\n",
      "Training loss at step 100: 0.5088\n",
      "Training loss at step 200: 0.4926\n",
      "Training loss at step 300: 0.4633\n",
      "Training accuracy: 0.8222 Validation accuracy: 0.7094 Time taken: 109.97s\n",
      "Epoch 45/200\n",
      "Training loss at step 0: 0.4750\n",
      "Training loss at step 100: 0.5549\n",
      "Training loss at step 200: 0.3755\n",
      "Training loss at step 300: 0.5311\n",
      "Training accuracy: 0.8247 Validation accuracy: 0.8182 Time taken: 110.37s\n",
      "Epoch 46/200\n",
      "Training loss at step 0: 0.4919\n",
      "Training loss at step 100: 0.5358\n",
      "Training loss at step 200: 0.5368\n",
      "Training loss at step 300: 0.5913\n",
      "Training accuracy: 0.8272 Validation accuracy: 0.7940 Time taken: 109.97s\n",
      "Epoch 47/200\n",
      "Training loss at step 0: 0.6273\n",
      "Training loss at step 100: 0.4972\n",
      "Training loss at step 200: 0.5194\n",
      "Training loss at step 300: 0.4497\n",
      "Training accuracy: 0.8311 Validation accuracy: 0.8122 Time taken: 109.82s\n",
      "Epoch 48/200\n",
      "Training loss at step 0: 0.6438\n",
      "Training loss at step 100: 0.5186\n",
      "Training loss at step 200: 0.3326\n",
      "Training loss at step 300: 0.4129\n",
      "Training accuracy: 0.8305 Validation accuracy: 0.7938 Time taken: 110.28s\n",
      "Epoch 49/200\n",
      "Training loss at step 0: 0.4517\n",
      "Training loss at step 100: 0.4555\n",
      "Training loss at step 200: 0.4247\n",
      "Training loss at step 300: 0.5547\n",
      "Training accuracy: 0.8353 Validation accuracy: 0.8246 Time taken: 109.85s\n",
      "Epoch 50/200\n",
      "Training loss at step 0: 0.3627\n",
      "Training loss at step 100: 0.4270\n",
      "Training loss at step 200: 0.4079\n",
      "Training loss at step 300: 0.4817\n",
      "Training accuracy: 0.8365 Validation accuracy: 0.8334 Time taken: 110.77s\n",
      "Epoch 51/200\n",
      "Training loss at step 0: 0.4857\n",
      "Training loss at step 100: 0.4511\n",
      "Training loss at step 200: 0.5577\n",
      "Training loss at step 300: 0.5149\n",
      "Training accuracy: 0.8359 Validation accuracy: 0.8008 Time taken: 109.82s\n",
      "Epoch 52/200\n",
      "Training loss at step 0: 0.5235\n",
      "Training loss at step 100: 0.6602\n",
      "Training loss at step 200: 0.3838\n",
      "Training loss at step 300: 0.6339\n",
      "Training accuracy: 0.8437 Validation accuracy: 0.7992 Time taken: 109.57s\n",
      "Epoch 53/200\n",
      "Training loss at step 0: 0.4763\n",
      "Training loss at step 100: 0.5281\n",
      "Training loss at step 200: 0.5697\n",
      "Training loss at step 300: 0.4609\n",
      "Training accuracy: 0.8429 Validation accuracy: 0.8036 Time taken: 109.25s\n",
      "Epoch 54/200\n",
      "Training loss at step 0: 0.3784\n",
      "Training loss at step 100: 0.3911\n",
      "Training loss at step 200: 0.4161\n",
      "Training loss at step 300: 0.4876\n",
      "Training accuracy: 0.8459 Validation accuracy: 0.8226 Time taken: 108.37s\n",
      "Epoch 55/200\n",
      "Training loss at step 0: 0.4424\n",
      "Training loss at step 100: 0.4770\n",
      "Training loss at step 200: 0.3503\n",
      "Training loss at step 300: 0.4674\n",
      "Training accuracy: 0.8469 Validation accuracy: 0.7994 Time taken: 108.64s\n",
      "Epoch 56/200\n",
      "Training loss at step 0: 0.5036\n",
      "Training loss at step 100: 0.3562\n",
      "Training loss at step 200: 0.6484\n",
      "Training loss at step 300: 0.5549\n",
      "Training accuracy: 0.8489 Validation accuracy: 0.8064 Time taken: 110.00s\n",
      "Epoch 57/200\n",
      "Training loss at step 0: 0.4784\n",
      "Training loss at step 100: 0.5526\n",
      "Training loss at step 200: 0.3496\n",
      "Training loss at step 300: 0.4536\n",
      "Training accuracy: 0.8519 Validation accuracy: 0.1782 Time taken: 110.30s\n",
      "Epoch 58/200\n",
      "Training loss at step 0: 0.5496\n",
      "Training loss at step 100: 0.2363\n",
      "Training loss at step 200: 0.4026\n",
      "Training loss at step 300: 0.4398\n",
      "Training accuracy: 0.8509 Validation accuracy: 0.8132 Time taken: 109.08s\n",
      "Epoch 59/200\n",
      "Training loss at step 0: 0.4124\n",
      "Training loss at step 100: 0.5160\n",
      "Training loss at step 200: 0.3542\n",
      "Training loss at step 300: 0.4292\n",
      "Training accuracy: 0.8533 Validation accuracy: 0.8218 Time taken: 110.74s\n",
      "Epoch 60/200\n",
      "Training loss at step 0: 0.2735\n",
      "Training loss at step 100: 0.4253\n",
      "Training loss at step 200: 0.5001\n",
      "Training loss at step 300: 0.3507\n",
      "Training accuracy: 0.8560 Validation accuracy: 0.8308 Time taken: 110.77s\n",
      "Epoch 61/200\n",
      "Training loss at step 0: 0.5027\n",
      "Training loss at step 100: 0.4932\n",
      "Training loss at step 200: 0.3824\n",
      "Training loss at step 300: 0.2878\n",
      "Training accuracy: 0.8572 Validation accuracy: 0.8242 Time taken: 110.17s\n",
      "Epoch 62/200\n",
      "Training loss at step 0: 0.3717\n",
      "Training loss at step 100: 0.4079\n",
      "Training loss at step 200: 0.5617\n",
      "Training loss at step 300: 0.4140\n",
      "Training accuracy: 0.8622 Validation accuracy: 0.7570 Time taken: 109.51s\n",
      "Epoch 63/200\n",
      "Training loss at step 0: 0.4599\n",
      "Training loss at step 100: 0.3967\n",
      "Training loss at step 200: 0.3930\n",
      "Training loss at step 300: 0.5143\n",
      "Training accuracy: 0.8653 Validation accuracy: 0.8464 Time taken: 109.40s\n",
      "Epoch 64/200\n",
      "Training loss at step 0: 0.4111\n",
      "Training loss at step 100: 0.2881\n",
      "Training loss at step 200: 0.2471\n",
      "Training loss at step 300: 0.2838\n",
      "Training accuracy: 0.8655 Validation accuracy: 0.8264 Time taken: 109.94s\n",
      "Epoch 65/200\n",
      "Training loss at step 0: 0.4461\n",
      "Training loss at step 100: 0.4955\n",
      "Training loss at step 200: 0.2794\n",
      "Training loss at step 300: 0.3666\n",
      "Training accuracy: 0.8632 Validation accuracy: 0.8494 Time taken: 110.03s\n",
      "Epoch 66/200\n",
      "Training loss at step 0: 0.3614\n",
      "Training loss at step 100: 0.4114\n",
      "Training loss at step 200: 0.3172\n",
      "Training loss at step 300: 0.3100\n",
      "Training accuracy: 0.8685 Validation accuracy: 0.7756 Time taken: 109.85s\n",
      "Epoch 67/200\n",
      "Training loss at step 0: 0.4470\n",
      "Training loss at step 100: 0.5238\n",
      "Training loss at step 200: 0.3689\n",
      "Training loss at step 300: 0.3093\n",
      "Training accuracy: 0.8673 Validation accuracy: 0.8504 Time taken: 109.24s\n",
      "Epoch 68/200\n",
      "Training loss at step 0: 0.1898\n",
      "Training loss at step 100: 0.3827\n",
      "Training loss at step 200: 0.4090\n",
      "Training loss at step 300: 0.5239\n",
      "Training accuracy: 0.8701 Validation accuracy: 0.8122 Time taken: 109.90s\n",
      "Epoch 69/200\n",
      "Training loss at step 0: 0.4076\n",
      "Training loss at step 100: 0.3319\n",
      "Training loss at step 200: 0.5006\n",
      "Training loss at step 300: 0.3463\n",
      "Training accuracy: 0.8697 Validation accuracy: 0.7924 Time taken: 109.71s\n",
      "Epoch 70/200\n",
      "Training loss at step 0: 0.4667\n",
      "Training loss at step 100: 0.4643\n",
      "Training loss at step 200: 0.2325\n",
      "Training loss at step 300: 0.3954\n",
      "Training accuracy: 0.8728 Validation accuracy: 0.8122 Time taken: 108.41s\n",
      "Epoch 71/200\n",
      "Training loss at step 0: 0.3016\n",
      "Training loss at step 100: 0.6702\n",
      "Training loss at step 200: 0.4161\n",
      "Training loss at step 300: 0.3618\n",
      "Training accuracy: 0.8743 Validation accuracy: 0.8544 Time taken: 109.66s\n",
      "Epoch 72/200\n",
      "Training loss at step 0: 0.3604\n",
      "Training loss at step 100: 0.3307\n",
      "Training loss at step 200: 0.4103\n",
      "Training loss at step 300: 0.3073\n",
      "Training accuracy: 0.8775 Validation accuracy: 0.8174 Time taken: 109.75s\n",
      "Epoch 73/200\n",
      "Training loss at step 0: 0.6927\n",
      "Training loss at step 100: 0.3741\n",
      "Training loss at step 200: 0.4140\n",
      "Training loss at step 300: 0.3035\n",
      "Training accuracy: 0.8745 Validation accuracy: 0.8006 Time taken: 109.17s\n",
      "Epoch 74/200\n",
      "Training loss at step 0: 0.5683\n",
      "Training loss at step 100: 0.3198\n",
      "Training loss at step 200: 0.3819\n",
      "Training loss at step 300: 0.4501\n",
      "Training accuracy: 0.8749 Validation accuracy: 0.8488 Time taken: 110.62s\n",
      "Epoch 75/200\n",
      "Training loss at step 0: 0.3199\n",
      "Training loss at step 100: 0.3824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 200: 0.4669\n",
      "Training loss at step 300: 0.3328\n",
      "Training accuracy: 0.8786 Validation accuracy: 0.8440 Time taken: 109.52s\n",
      "Epoch 76/200\n",
      "Training loss at step 0: 0.5956\n",
      "Training loss at step 100: 0.3763\n",
      "Training loss at step 200: 0.4187\n",
      "Training loss at step 300: 0.2540\n",
      "Training accuracy: 0.8794 Validation accuracy: 0.8558 Time taken: 109.55s\n",
      "Epoch 77/200\n",
      "Training loss at step 0: 0.2894\n",
      "Training loss at step 100: 0.3724\n",
      "Training loss at step 200: 0.3807\n",
      "Training loss at step 300: 0.4112\n",
      "Training accuracy: 0.8804 Validation accuracy: 0.8276 Time taken: 110.10s\n",
      "Epoch 78/200\n",
      "Training loss at step 0: 0.4289\n",
      "Training loss at step 100: 0.2349\n",
      "Training loss at step 200: 0.8506\n",
      "Training loss at step 300: 0.4190\n",
      "Training accuracy: 0.8822 Validation accuracy: 0.7990 Time taken: 110.17s\n",
      "Epoch 79/200\n",
      "Training loss at step 0: 0.3333\n",
      "Training loss at step 100: 0.2652\n",
      "Training loss at step 200: 0.3002\n",
      "Training loss at step 300: 0.2960\n",
      "Training accuracy: 0.8849 Validation accuracy: 0.8486 Time taken: 109.95s\n",
      "Epoch 80/200\n",
      "Training loss at step 0: 0.3279\n",
      "Training loss at step 100: 0.4057\n",
      "Training loss at step 200: 0.3220\n",
      "Training loss at step 300: 0.3157\n",
      "Training accuracy: 0.8825 Validation accuracy: 0.8158 Time taken: 110.16s\n",
      "Epoch 81/200\n",
      "Training loss at step 0: 0.3553\n",
      "Training loss at step 100: 0.2735\n",
      "Training loss at step 200: 0.3462\n",
      "Training loss at step 300: 0.2147\n",
      "Training accuracy: 0.8851 Validation accuracy: 0.8492 Time taken: 109.90s\n",
      "Epoch 82/200\n",
      "Training loss at step 0: 0.2933\n",
      "Training loss at step 100: 0.3428\n",
      "Training loss at step 200: 0.4497\n",
      "Training loss at step 300: 0.3150\n",
      "Training accuracy: 0.8863 Validation accuracy: 0.8458 Time taken: 109.64s\n",
      "Epoch 83/200\n",
      "Training loss at step 0: 0.3380\n",
      "Training loss at step 100: 0.2036\n",
      "Training loss at step 200: 0.3556\n",
      "Training loss at step 300: 0.4011\n",
      "Training accuracy: 0.8869 Validation accuracy: 0.8482 Time taken: 111.59s\n",
      "Epoch 84/200\n",
      "Training loss at step 0: 0.2603\n",
      "Training loss at step 100: 0.4481\n",
      "Training loss at step 200: 0.3734\n",
      "Training loss at step 300: 0.3756\n",
      "Training accuracy: 0.8903 Validation accuracy: 0.8674 Time taken: 110.70s\n",
      "Epoch 85/200\n",
      "Training loss at step 0: 0.3504\n",
      "Training loss at step 100: 0.3937\n",
      "Training loss at step 200: 0.2873\n",
      "Training loss at step 300: 0.2981\n",
      "Training accuracy: 0.8874 Validation accuracy: 0.8562 Time taken: 111.11s\n",
      "Epoch 86/200\n",
      "Training loss at step 0: 0.3146\n",
      "Training loss at step 100: 0.3077\n",
      "Training loss at step 200: 0.2621\n",
      "Training loss at step 300: 0.3104\n",
      "Training accuracy: 0.8907 Validation accuracy: 0.8508 Time taken: 110.96s\n",
      "Epoch 87/200\n",
      "Training loss at step 0: 0.2964\n",
      "Training loss at step 100: 0.3335\n",
      "Training loss at step 200: 0.2257\n",
      "Training loss at step 300: 0.3835\n",
      "Training accuracy: 0.8928 Validation accuracy: 0.8394 Time taken: 110.70s\n",
      "Epoch 88/200\n",
      "Training loss at step 0: 0.3042\n",
      "Training loss at step 100: 0.2635\n",
      "Training loss at step 200: 0.2675\n",
      "Training loss at step 300: 0.3122\n",
      "Training accuracy: 0.8962 Validation accuracy: 0.8282 Time taken: 110.00s\n",
      "Epoch 89/200\n",
      "Training loss at step 0: 0.2944\n",
      "Training loss at step 100: 0.2322\n",
      "Training loss at step 200: 0.2924\n",
      "Training loss at step 300: 0.2191\n",
      "Training accuracy: 0.8924 Validation accuracy: 0.8544 Time taken: 109.64s\n",
      "Epoch 90/200\n",
      "Training loss at step 0: 0.4838\n",
      "Training loss at step 100: 0.2525\n",
      "Training loss at step 200: 0.3048\n",
      "Training loss at step 300: 0.3073\n",
      "Training accuracy: 0.8951 Validation accuracy: 0.4332 Time taken: 108.93s\n",
      "Epoch 91/200\n",
      "Training loss at step 0: 0.2131\n",
      "Training loss at step 100: 0.1770\n",
      "Training loss at step 200: 0.3567\n",
      "Training loss at step 300: 0.3797\n",
      "Training accuracy: 0.8932 Validation accuracy: 0.8698 Time taken: 109.53s\n",
      "Epoch 92/200\n",
      "Training loss at step 0: 0.3938\n",
      "Training loss at step 100: 0.1737\n",
      "Training loss at step 200: 0.4929\n",
      "Training loss at step 300: 0.4229\n",
      "Training accuracy: 0.8951 Validation accuracy: 0.8470 Time taken: 107.76s\n",
      "Epoch 93/200\n",
      "Training loss at step 0: 0.2833\n",
      "Training loss at step 100: 0.1983\n",
      "Training loss at step 200: 0.1705\n",
      "Training loss at step 300: 0.2326\n",
      "Training accuracy: 0.8966 Validation accuracy: 0.8466 Time taken: 109.34s\n",
      "Epoch 94/200\n",
      "Training loss at step 0: 0.3437\n",
      "Training loss at step 100: 0.3082\n",
      "Training loss at step 200: 0.3762\n",
      "Training loss at step 300: 0.4078\n",
      "Training accuracy: 0.8965 Validation accuracy: 0.8584 Time taken: 109.54s\n",
      "Epoch 95/200\n",
      "Training loss at step 0: 0.4826\n",
      "Training loss at step 100: 0.3494\n",
      "Training loss at step 200: 0.2181\n",
      "Training loss at step 300: 0.2456\n",
      "Training accuracy: 0.8970 Validation accuracy: 0.7652 Time taken: 110.17s\n",
      "Epoch 96/200\n",
      "Training loss at step 0: 0.2281\n",
      "Training loss at step 100: 0.2035\n",
      "Training loss at step 200: 0.2242\n",
      "Training loss at step 300: 0.2958\n",
      "Training accuracy: 0.8981 Validation accuracy: 0.8232 Time taken: 109.23s\n",
      "Epoch 97/200\n",
      "Training loss at step 0: 0.3025\n",
      "Training loss at step 100: 0.2021\n",
      "Training loss at step 200: 0.2786\n",
      "Training loss at step 300: 0.3348\n",
      "Training accuracy: 0.8997 Validation accuracy: 0.8594 Time taken: 110.40s\n",
      "Epoch 98/200\n",
      "Training loss at step 0: 0.2023\n",
      "Training loss at step 100: 0.1864\n",
      "Training loss at step 200: 0.3743\n",
      "Training loss at step 300: 0.2271\n",
      "Training accuracy: 0.8996 Validation accuracy: 0.8460 Time taken: 109.86s\n",
      "Epoch 99/200\n",
      "Training loss at step 0: 0.3099\n",
      "Training loss at step 100: 0.2071\n",
      "Training loss at step 200: 0.2722\n",
      "Training loss at step 300: 0.4240\n",
      "Training accuracy: 0.9022 Validation accuracy: 0.8692 Time taken: 110.31s\n",
      "Epoch 100/200\n",
      "Training loss at step 0: 0.4409\n",
      "Training loss at step 100: 0.2703\n",
      "Training loss at step 200: 0.2565\n",
      "Training loss at step 300: 0.1934\n",
      "Training accuracy: 0.9039 Validation accuracy: 0.8204 Time taken: 110.78s\n",
      "Epoch 101/200\n",
      "Training loss at step 0: 0.4001\n",
      "Training loss at step 100: 0.2544\n",
      "Training loss at step 200: 0.1638\n",
      "Training loss at step 300: 0.3722\n",
      "Training accuracy: 0.9141 Validation accuracy: 0.8900 Time taken: 110.43s\n",
      "Epoch 102/200\n",
      "Training loss at step 0: 0.3212\n",
      "Training loss at step 100: 0.2566\n",
      "Training loss at step 200: 0.2438\n",
      "Training loss at step 300: 0.3783\n",
      "Training accuracy: 0.9179 Validation accuracy: 0.8916 Time taken: 110.41s\n",
      "Epoch 103/200\n",
      "Training loss at step 0: 0.3335\n",
      "Training loss at step 100: 0.2455\n",
      "Training loss at step 200: 0.2460\n",
      "Training loss at step 300: 0.1373\n",
      "Training accuracy: 0.9170 Validation accuracy: 0.8942 Time taken: 110.14s\n",
      "Epoch 104/200\n",
      "Training loss at step 0: 0.2458\n",
      "Training loss at step 100: 0.2190\n",
      "Training loss at step 200: 0.1583\n",
      "Training loss at step 300: 0.2392\n",
      "Training accuracy: 0.9199 Validation accuracy: 0.8870 Time taken: 111.04s\n",
      "Epoch 105/200\n",
      "Training loss at step 0: 0.2313\n",
      "Training loss at step 100: 0.1799\n",
      "Training loss at step 200: 0.2391\n",
      "Training loss at step 300: 0.2107\n",
      "Training accuracy: 0.9194 Validation accuracy: 0.8888 Time taken: 109.55s\n",
      "Epoch 106/200\n",
      "Training loss at step 0: 0.2637\n",
      "Training loss at step 100: 0.2249\n",
      "Training loss at step 200: 0.1502\n",
      "Training loss at step 300: 0.2132\n",
      "Training accuracy: 0.9227 Validation accuracy: 0.8914 Time taken: 109.95s\n",
      "Epoch 107/200\n",
      "Training loss at step 0: 0.1593\n",
      "Training loss at step 100: 0.3078\n",
      "Training loss at step 200: 0.3204\n",
      "Training loss at step 300: 0.1746\n",
      "Training accuracy: 0.9200 Validation accuracy: 0.8908 Time taken: 109.02s\n",
      "Epoch 108/200\n",
      "Training loss at step 0: 0.1286\n",
      "Training loss at step 100: 0.1807\n",
      "Training loss at step 200: 0.2931\n",
      "Training loss at step 300: 0.2438\n",
      "Training accuracy: 0.9247 Validation accuracy: 0.8876 Time taken: 109.09s\n",
      "Epoch 109/200\n",
      "Training loss at step 0: 0.1346\n",
      "Training loss at step 100: 0.2186\n",
      "Training loss at step 200: 0.1643\n",
      "Training loss at step 300: 0.0967\n",
      "Training accuracy: 0.9223 Validation accuracy: 0.8920 Time taken: 108.56s\n",
      "Epoch 110/200\n",
      "Training loss at step 0: 0.2084\n",
      "Training loss at step 100: 0.1456\n",
      "Training loss at step 200: 0.2257\n",
      "Training loss at step 300: 0.1924\n",
      "Training accuracy: 0.9230 Validation accuracy: 0.8922 Time taken: 108.52s\n",
      "Epoch 111/200\n",
      "Training loss at step 0: 0.2630\n",
      "Training loss at step 100: 0.4952\n",
      "Training loss at step 200: 0.1935\n",
      "Training loss at step 300: 0.2714\n",
      "Training accuracy: 0.9238 Validation accuracy: 0.8942 Time taken: 108.61s\n",
      "Epoch 112/200\n",
      "Training loss at step 0: 0.1679\n",
      "Training loss at step 100: 0.3062\n",
      "Training loss at step 200: 0.1354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.2072\n",
      "Training accuracy: 0.9261 Validation accuracy: 0.8904 Time taken: 108.94s\n",
      "Epoch 113/200\n",
      "Training loss at step 0: 0.3134\n",
      "Training loss at step 100: 0.1836\n",
      "Training loss at step 200: 0.3500\n",
      "Training loss at step 300: 0.2698\n",
      "Training accuracy: 0.9232 Validation accuracy: 0.8946 Time taken: 108.22s\n",
      "Epoch 114/200\n",
      "Training loss at step 0: 0.3235\n",
      "Training loss at step 100: 0.1778\n",
      "Training loss at step 200: 0.2153\n",
      "Training loss at step 300: 0.1986\n",
      "Training accuracy: 0.9241 Validation accuracy: 0.8904 Time taken: 108.54s\n",
      "Epoch 115/200\n",
      "Training loss at step 0: 0.2356\n",
      "Training loss at step 100: 0.2130\n",
      "Training loss at step 200: 0.2368\n",
      "Training loss at step 300: 0.1720\n",
      "Training accuracy: 0.9233 Validation accuracy: 0.8928 Time taken: 107.79s\n",
      "Epoch 116/200\n",
      "Training loss at step 0: 0.2967\n",
      "Training loss at step 100: 0.2883\n",
      "Training loss at step 200: 0.1819\n",
      "Training loss at step 300: 0.1488\n",
      "Training accuracy: 0.9260 Validation accuracy: 0.8878 Time taken: 108.26s\n",
      "Epoch 117/200\n",
      "Training loss at step 0: 0.2355\n",
      "Training loss at step 100: 0.1616\n",
      "Training loss at step 200: 0.2899\n",
      "Training loss at step 300: 0.1891\n",
      "Training accuracy: 0.9245 Validation accuracy: 0.8920 Time taken: 107.59s\n",
      "Epoch 118/200\n",
      "Training loss at step 0: 0.1875\n",
      "Training loss at step 100: 0.1394\n",
      "Training loss at step 200: 0.2846\n",
      "Training loss at step 300: 0.2950\n",
      "Training accuracy: 0.9256 Validation accuracy: 0.8924 Time taken: 107.90s\n",
      "Epoch 119/200\n",
      "Training loss at step 0: 0.2626\n",
      "Training loss at step 100: 0.2419\n",
      "Training loss at step 200: 0.2227\n",
      "Training loss at step 300: 0.1355\n",
      "Training accuracy: 0.9218 Validation accuracy: 0.8922 Time taken: 107.86s\n",
      "Epoch 120/200\n",
      "Training loss at step 0: 0.2310\n",
      "Training loss at step 100: 0.1425\n",
      "Training loss at step 200: 0.1835\n",
      "Training loss at step 300: 0.2138\n",
      "Training accuracy: 0.9257 Validation accuracy: 0.8910 Time taken: 108.40s\n",
      "Epoch 121/200\n",
      "Training loss at step 0: 0.2475\n",
      "Training loss at step 100: 0.1317\n",
      "Training loss at step 200: 0.2202\n",
      "Training loss at step 300: 0.2373\n",
      "Training accuracy: 0.9260 Validation accuracy: 0.8954 Time taken: 108.44s\n",
      "Epoch 122/200\n",
      "Training loss at step 0: 0.2589\n",
      "Training loss at step 100: 0.2847\n",
      "Training loss at step 200: 0.2163\n",
      "Training loss at step 300: 0.1103\n",
      "Training accuracy: 0.9265 Validation accuracy: 0.8926 Time taken: 108.79s\n",
      "Epoch 123/200\n",
      "Training loss at step 0: 0.2398\n",
      "Training loss at step 100: 0.2500\n",
      "Training loss at step 200: 0.2223\n",
      "Training loss at step 300: 0.1196\n",
      "Training accuracy: 0.9274 Validation accuracy: 0.8944 Time taken: 109.57s\n",
      "Epoch 124/200\n",
      "Training loss at step 0: 0.2249\n",
      "Training loss at step 100: 0.1571\n",
      "Training loss at step 200: 0.2117\n",
      "Training loss at step 300: 0.1647\n",
      "Training accuracy: 0.9246 Validation accuracy: 0.8916 Time taken: 108.05s\n",
      "Epoch 125/200\n",
      "Training loss at step 0: 0.1868\n",
      "Training loss at step 100: 0.2578\n",
      "Training loss at step 200: 0.1745\n",
      "Training loss at step 300: 0.1635\n",
      "Training accuracy: 0.9262 Validation accuracy: 0.8916 Time taken: 107.95s\n",
      "Epoch 126/200\n",
      "Training loss at step 0: 0.2058\n",
      "Training loss at step 100: 0.1964\n",
      "Training loss at step 200: 0.1081\n",
      "Training loss at step 300: 0.2595\n",
      "Training accuracy: 0.9294 Validation accuracy: 0.8938 Time taken: 109.50s\n",
      "Epoch 127/200\n",
      "Training loss at step 0: 0.2945\n",
      "Training loss at step 100: 0.2722\n",
      "Training loss at step 200: 0.1330\n",
      "Training loss at step 300: 0.2347\n",
      "Training accuracy: 0.9269 Validation accuracy: 0.8934 Time taken: 108.56s\n",
      "Epoch 128/200\n",
      "Training loss at step 0: 0.1506\n",
      "Training loss at step 100: 0.2137\n",
      "Training loss at step 200: 0.1863\n",
      "Training loss at step 300: 0.1456\n",
      "Training accuracy: 0.9266 Validation accuracy: 0.8894 Time taken: 109.19s\n",
      "Epoch 129/200\n",
      "Training loss at step 0: 0.2043\n",
      "Training loss at step 100: 0.1783\n",
      "Training loss at step 200: 0.1483\n",
      "Training loss at step 300: 0.1742\n",
      "Training accuracy: 0.9269 Validation accuracy: 0.8910 Time taken: 109.20s\n",
      "Epoch 130/200\n",
      "Training loss at step 0: 0.2363\n",
      "Training loss at step 100: 0.1872\n",
      "Training loss at step 200: 0.2083\n",
      "Training loss at step 300: 0.2349\n",
      "Training accuracy: 0.9281 Validation accuracy: 0.8906 Time taken: 110.79s\n",
      "Epoch 131/200\n",
      "Training loss at step 0: 0.3243\n",
      "Training loss at step 100: 0.3242\n",
      "Training loss at step 200: 0.2948\n",
      "Training loss at step 300: 0.1390\n",
      "Training accuracy: 0.9260 Validation accuracy: 0.8950 Time taken: 107.93s\n",
      "Epoch 132/200\n",
      "Training loss at step 0: 0.3494\n",
      "Training loss at step 100: 0.2665\n",
      "Training loss at step 200: 0.2574\n",
      "Training loss at step 300: 0.1288\n",
      "Training accuracy: 0.9267 Validation accuracy: 0.8898 Time taken: 109.51s\n",
      "Epoch 133/200\n",
      "Training loss at step 0: 0.2517\n",
      "Training loss at step 100: 0.1962\n",
      "Training loss at step 200: 0.1335\n",
      "Training loss at step 300: 0.2503\n",
      "Training accuracy: 0.9273 Validation accuracy: 0.8924 Time taken: 108.18s\n",
      "Epoch 134/200\n",
      "Training loss at step 0: 0.0930\n",
      "Training loss at step 100: 0.1407\n",
      "Training loss at step 200: 0.2011\n",
      "Training loss at step 300: 0.3055\n",
      "Training accuracy: 0.9288 Validation accuracy: 0.8922 Time taken: 108.98s\n",
      "Epoch 135/200\n",
      "Training loss at step 0: 0.1175\n",
      "Training loss at step 100: 0.2472\n",
      "Training loss at step 200: 0.2311\n",
      "Training loss at step 300: 0.2051\n",
      "Training accuracy: 0.9276 Validation accuracy: 0.8926 Time taken: 108.64s\n",
      "Epoch 136/200\n",
      "Training loss at step 0: 0.1220\n",
      "Training loss at step 100: 0.1442\n",
      "Training loss at step 200: 0.1620\n",
      "Training loss at step 300: 0.2004\n",
      "Training accuracy: 0.9291 Validation accuracy: 0.8918 Time taken: 109.54s\n",
      "Epoch 137/200\n",
      "Training loss at step 0: 0.1587\n",
      "Training loss at step 100: 0.1265\n",
      "Training loss at step 200: 0.2975\n",
      "Training loss at step 300: 0.1171\n",
      "Training accuracy: 0.9262 Validation accuracy: 0.8900 Time taken: 109.11s\n",
      "Epoch 138/200\n",
      "Training loss at step 0: 0.1442\n",
      "Training loss at step 100: 0.0656\n",
      "Training loss at step 200: 0.2021\n",
      "Training loss at step 300: 0.1267\n",
      "Training accuracy: 0.9278 Validation accuracy: 0.8930 Time taken: 109.08s\n",
      "Epoch 139/200\n",
      "Training loss at step 0: 0.2282\n",
      "Training loss at step 100: 0.1890\n",
      "Training loss at step 200: 0.1321\n",
      "Training loss at step 300: 0.1515\n",
      "Training accuracy: 0.9265 Validation accuracy: 0.8952 Time taken: 108.06s\n",
      "Epoch 140/200\n",
      "Training loss at step 0: 0.0870\n",
      "Training loss at step 100: 0.1695\n",
      "Training loss at step 200: 0.2036\n",
      "Training loss at step 300: 0.1612\n",
      "Training accuracy: 0.9276 Validation accuracy: 0.8936 Time taken: 108.13s\n",
      "Epoch 141/200\n",
      "Training loss at step 0: 0.2716\n",
      "Training loss at step 100: 0.3003\n",
      "Training loss at step 200: 0.1052\n",
      "Training loss at step 300: 0.1900\n",
      "Training accuracy: 0.9287 Validation accuracy: 0.8938 Time taken: 108.47s\n",
      "Epoch 142/200\n",
      "Training loss at step 0: 0.2696\n",
      "Training loss at step 100: 0.2658\n",
      "Training loss at step 200: 0.1762\n",
      "Training loss at step 300: 0.0999\n",
      "Training accuracy: 0.9297 Validation accuracy: 0.8942 Time taken: 108.08s\n",
      "Epoch 143/200\n",
      "Training loss at step 0: 0.1295\n",
      "Training loss at step 100: 0.2222\n",
      "Training loss at step 200: 0.2637\n",
      "Training loss at step 300: 0.2304\n",
      "Training accuracy: 0.9290 Validation accuracy: 0.8920 Time taken: 108.92s\n",
      "Epoch 144/200\n",
      "Training loss at step 0: 0.3708\n",
      "Training loss at step 100: 0.1465\n",
      "Training loss at step 200: 0.2161\n",
      "Training loss at step 300: 0.1810\n",
      "Training accuracy: 0.9276 Validation accuracy: 0.8910 Time taken: 108.50s\n",
      "Epoch 145/200\n",
      "Training loss at step 0: 0.1724\n",
      "Training loss at step 100: 0.2890\n",
      "Training loss at step 200: 0.1646\n",
      "Training loss at step 300: 0.1998\n",
      "Training accuracy: 0.9298 Validation accuracy: 0.8916 Time taken: 109.53s\n",
      "Epoch 146/200\n",
      "Training loss at step 0: 0.1330\n",
      "Training loss at step 100: 0.1484\n",
      "Training loss at step 200: 0.1839\n",
      "Training loss at step 300: 0.1889\n",
      "Training accuracy: 0.9306 Validation accuracy: 0.8934 Time taken: 109.31s\n",
      "Epoch 147/200\n",
      "Training loss at step 0: 0.1418\n",
      "Training loss at step 100: 0.1477\n",
      "Training loss at step 200: 0.1686\n",
      "Training loss at step 300: 0.1902\n",
      "Training accuracy: 0.9318 Validation accuracy: 0.8926 Time taken: 109.42s\n",
      "Epoch 148/200\n",
      "Training loss at step 0: 0.2368\n",
      "Training loss at step 100: 0.0801\n",
      "Training loss at step 200: 0.3070\n",
      "Training loss at step 300: 0.1499\n",
      "Training accuracy: 0.9300 Validation accuracy: 0.8950 Time taken: 109.57s\n",
      "Epoch 149/200\n",
      "Training loss at step 0: 0.1628\n",
      "Training loss at step 100: 0.0905\n",
      "Training loss at step 200: 0.1581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.1846\n",
      "Training accuracy: 0.9314 Validation accuracy: 0.8920 Time taken: 109.97s\n",
      "Epoch 150/200\n",
      "Training loss at step 0: 0.2522\n",
      "Training loss at step 100: 0.1196\n",
      "Training loss at step 200: 0.1706\n",
      "Training loss at step 300: 0.1598\n",
      "Training accuracy: 0.9288 Validation accuracy: 0.8912 Time taken: 110.04s\n",
      "Epoch 151/200\n",
      "Training loss at step 0: 0.1288\n",
      "Training loss at step 100: 0.1640\n",
      "Training loss at step 200: 0.1410\n",
      "Training loss at step 300: 0.2276\n",
      "Training accuracy: 0.9319 Validation accuracy: 0.8946 Time taken: 109.95s\n",
      "Epoch 152/200\n",
      "Training loss at step 0: 0.1609\n",
      "Training loss at step 100: 0.2679\n",
      "Training loss at step 200: 0.1893\n",
      "Training loss at step 300: 0.1389\n",
      "Training accuracy: 0.9316 Validation accuracy: 0.8944 Time taken: 109.07s\n",
      "Epoch 153/200\n",
      "Training loss at step 0: 0.3052\n",
      "Training loss at step 100: 0.1977\n",
      "Training loss at step 200: 0.1553\n",
      "Training loss at step 300: 0.1267\n",
      "Training accuracy: 0.9308 Validation accuracy: 0.8946 Time taken: 108.82s\n",
      "Epoch 154/200\n",
      "Training loss at step 0: 0.1343\n",
      "Training loss at step 100: 0.2307\n",
      "Training loss at step 200: 0.1439\n",
      "Training loss at step 300: 0.2649\n",
      "Training accuracy: 0.9313 Validation accuracy: 0.8936 Time taken: 109.33s\n",
      "Epoch 155/200\n",
      "Training loss at step 0: 0.2073\n",
      "Training loss at step 100: 0.0827\n",
      "Training loss at step 200: 0.1149\n",
      "Training loss at step 300: 0.1850\n",
      "Training accuracy: 0.9296 Validation accuracy: 0.8940 Time taken: 108.96s\n",
      "Epoch 156/200\n",
      "Training loss at step 0: 0.2554\n",
      "Training loss at step 100: 0.1478\n",
      "Training loss at step 200: 0.1784\n",
      "Training loss at step 300: 0.0651\n",
      "Training accuracy: 0.9309 Validation accuracy: 0.8944 Time taken: 109.09s\n",
      "Epoch 157/200\n",
      "Training loss at step 0: 0.1319\n",
      "Training loss at step 100: 0.4728\n",
      "Training loss at step 200: 0.3311\n",
      "Training loss at step 300: 0.1327\n",
      "Training accuracy: 0.9325 Validation accuracy: 0.8952 Time taken: 109.31s\n",
      "Epoch 158/200\n",
      "Training loss at step 0: 0.1919\n",
      "Training loss at step 100: 0.1407\n",
      "Training loss at step 200: 0.1740\n",
      "Training loss at step 300: 0.1278\n",
      "Training accuracy: 0.9310 Validation accuracy: 0.8956 Time taken: 108.78s\n",
      "Epoch 159/200\n",
      "Training loss at step 0: 0.1790\n",
      "Training loss at step 100: 0.1767\n",
      "Training loss at step 200: 0.0733\n",
      "Training loss at step 300: 0.1291\n",
      "Training accuracy: 0.9314 Validation accuracy: 0.8946 Time taken: 109.69s\n",
      "Epoch 160/200\n",
      "Training loss at step 0: 0.1558\n",
      "Training loss at step 100: 0.1377\n",
      "Training loss at step 200: 0.2171\n",
      "Training loss at step 300: 0.2164\n",
      "Training accuracy: 0.9295 Validation accuracy: 0.8948 Time taken: 109.00s\n",
      "Epoch 161/200\n",
      "Training loss at step 0: 0.1817\n",
      "Training loss at step 100: 0.1224\n",
      "Training loss at step 200: 0.1090\n",
      "Training loss at step 300: 0.1581\n",
      "Training accuracy: 0.9313 Validation accuracy: 0.8952 Time taken: 109.37s\n",
      "Epoch 162/200\n",
      "Training loss at step 0: 0.3187\n",
      "Training loss at step 100: 0.1999\n",
      "Training loss at step 200: 0.3542\n",
      "Training loss at step 300: 0.2144\n",
      "Training accuracy: 0.9303 Validation accuracy: 0.8954 Time taken: 109.08s\n",
      "Epoch 163/200\n",
      "Training loss at step 0: 0.2604\n",
      "Training loss at step 100: 0.3780\n",
      "Training loss at step 200: 0.1667\n",
      "Training loss at step 300: 0.1368\n",
      "Training accuracy: 0.9321 Validation accuracy: 0.8916 Time taken: 108.90s\n",
      "Epoch 164/200\n",
      "Training loss at step 0: 0.1443\n",
      "Training loss at step 100: 0.1603\n",
      "Training loss at step 200: 0.1522\n",
      "Training loss at step 300: 0.1506\n",
      "Training accuracy: 0.9326 Validation accuracy: 0.8928 Time taken: 108.97s\n",
      "Epoch 165/200\n",
      "Training loss at step 0: 0.1820\n",
      "Training loss at step 100: 0.2137\n",
      "Training loss at step 200: 0.1247\n",
      "Training loss at step 300: 0.2352\n",
      "Training accuracy: 0.9317 Validation accuracy: 0.8952 Time taken: 108.31s\n",
      "Epoch 166/200\n",
      "Training loss at step 0: 0.1639\n",
      "Training loss at step 100: 0.1906\n",
      "Training loss at step 200: 0.3264\n",
      "Training loss at step 300: 0.2150\n",
      "Training accuracy: 0.9311 Validation accuracy: 0.8948 Time taken: 109.22s\n",
      "Epoch 167/200\n",
      "Training loss at step 0: 0.3670\n",
      "Training loss at step 100: 0.1772\n",
      "Training loss at step 200: 0.3424\n",
      "Training loss at step 300: 0.1440\n",
      "Training accuracy: 0.9309 Validation accuracy: 0.8952 Time taken: 108.50s\n",
      "Epoch 168/200\n",
      "Training loss at step 0: 0.1972\n",
      "Training loss at step 100: 0.1804\n",
      "Training loss at step 200: 0.1607\n",
      "Training loss at step 300: 0.1260\n",
      "Training accuracy: 0.9322 Validation accuracy: 0.8934 Time taken: 109.23s\n",
      "Epoch 169/200\n",
      "Training loss at step 0: 0.2123\n",
      "Training loss at step 100: 0.1930\n",
      "Training loss at step 200: 0.2763\n",
      "Training loss at step 300: 0.1312\n",
      "Training accuracy: 0.9309 Validation accuracy: 0.8936 Time taken: 108.28s\n",
      "Epoch 170/200\n",
      "Training loss at step 0: 0.2073\n",
      "Training loss at step 100: 0.1501\n",
      "Training loss at step 200: 0.2015\n",
      "Training loss at step 300: 0.0668\n",
      "Training accuracy: 0.9336 Validation accuracy: 0.8904 Time taken: 109.31s\n",
      "Epoch 171/200\n",
      "Training loss at step 0: 0.1775\n",
      "Training loss at step 100: 0.2250\n",
      "Training loss at step 200: 0.1897\n",
      "Training loss at step 300: 0.1293\n",
      "Training accuracy: 0.9317 Validation accuracy: 0.8926 Time taken: 108.76s\n",
      "Epoch 172/200\n",
      "Training loss at step 0: 0.2585\n",
      "Training loss at step 100: 0.1657\n",
      "Training loss at step 200: 0.1660\n",
      "Training loss at step 300: 0.2069\n",
      "Training accuracy: 0.9308 Validation accuracy: 0.8940 Time taken: 109.21s\n",
      "Epoch 173/200\n",
      "Training loss at step 0: 0.1787\n",
      "Training loss at step 100: 0.1360\n",
      "Training loss at step 200: 0.2201\n",
      "Training loss at step 300: 0.1391\n",
      "Training accuracy: 0.9333 Validation accuracy: 0.8944 Time taken: 109.13s\n",
      "Epoch 174/200\n",
      "Training loss at step 0: 0.1070\n",
      "Training loss at step 100: 0.1572\n",
      "Training loss at step 200: 0.2775\n",
      "Training loss at step 300: 0.1721\n",
      "Training accuracy: 0.9327 Validation accuracy: 0.8936 Time taken: 109.61s\n",
      "Epoch 175/200\n",
      "Training loss at step 0: 0.1965\n",
      "Training loss at step 100: 0.1311\n",
      "Training loss at step 200: 0.2325\n",
      "Training loss at step 300: 0.2021\n",
      "Training accuracy: 0.9304 Validation accuracy: 0.8928 Time taken: 109.53s\n",
      "Epoch 176/200\n",
      "Training loss at step 0: 0.1098\n",
      "Training loss at step 100: 0.1224\n",
      "Training loss at step 200: 0.0693\n",
      "Training loss at step 300: 0.1656\n",
      "Training accuracy: 0.9343 Validation accuracy: 0.8948 Time taken: 109.50s\n",
      "Epoch 177/200\n",
      "Training loss at step 0: 0.1831\n",
      "Training loss at step 100: 0.1722\n",
      "Training loss at step 200: 0.2661\n",
      "Training loss at step 300: 0.2942\n",
      "Training accuracy: 0.9312 Validation accuracy: 0.8956 Time taken: 108.83s\n",
      "Epoch 178/200\n",
      "Training loss at step 0: 0.1644\n",
      "Training loss at step 100: 0.1695\n",
      "Training loss at step 200: 0.2204\n",
      "Training loss at step 300: 0.1426\n",
      "Training accuracy: 0.9316 Validation accuracy: 0.8938 Time taken: 108.91s\n",
      "Epoch 179/200\n",
      "Training loss at step 0: 0.1979\n",
      "Training loss at step 100: 0.1985\n",
      "Training loss at step 200: 0.1916\n",
      "Training loss at step 300: 0.1567\n",
      "Training accuracy: 0.9302 Validation accuracy: 0.8938 Time taken: 108.25s\n",
      "Epoch 180/200\n",
      "Training loss at step 0: 0.1788\n",
      "Training loss at step 100: 0.1811\n",
      "Training loss at step 200: 0.2517\n",
      "Training loss at step 300: 0.1842\n",
      "Training accuracy: 0.9318 Validation accuracy: 0.8950 Time taken: 109.05s\n",
      "Epoch 181/200\n",
      "Training loss at step 0: 0.1963\n",
      "Training loss at step 100: 0.2384\n",
      "Training loss at step 200: 0.2216\n",
      "Training loss at step 300: 0.2035\n",
      "Training accuracy: 0.9315 Validation accuracy: 0.8924 Time taken: 108.36s\n",
      "Epoch 182/200\n",
      "Training loss at step 0: 0.1781\n",
      "Training loss at step 100: 0.2031\n",
      "Training loss at step 200: 0.1594\n",
      "Training loss at step 300: 0.2200\n",
      "Training accuracy: 0.9321 Validation accuracy: 0.8934 Time taken: 109.09s\n",
      "Epoch 183/200\n",
      "Training loss at step 0: 0.1939\n",
      "Training loss at step 100: 0.2489\n",
      "Training loss at step 200: 0.1121\n",
      "Training loss at step 300: 0.1348\n",
      "Training accuracy: 0.9340 Validation accuracy: 0.8922 Time taken: 109.32s\n",
      "Epoch 184/200\n",
      "Training loss at step 0: 0.3171\n",
      "Training loss at step 100: 0.1893\n",
      "Training loss at step 200: 0.1626\n",
      "Training loss at step 300: 0.1473\n",
      "Training accuracy: 0.9298 Validation accuracy: 0.8944 Time taken: 108.98s\n",
      "Epoch 185/200\n",
      "Training loss at step 0: 0.1139\n",
      "Training loss at step 100: 0.1512\n",
      "Training loss at step 200: 0.3059\n",
      "Training loss at step 300: 0.2318\n",
      "Training accuracy: 0.9312 Validation accuracy: 0.8946 Time taken: 108.83s\n",
      "Epoch 186/200\n",
      "Training loss at step 0: 0.2219\n",
      "Training loss at step 100: 0.1133\n",
      "Training loss at step 200: 0.2047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.1611\n",
      "Training accuracy: 0.9295 Validation accuracy: 0.8960 Time taken: 108.34s\n",
      "Epoch 187/200\n",
      "Training loss at step 0: 0.1353\n",
      "Training loss at step 100: 0.2670\n",
      "Training loss at step 200: 0.1253\n",
      "Training loss at step 300: 0.2790\n",
      "Training accuracy: 0.9322 Validation accuracy: 0.8952 Time taken: 109.02s\n",
      "Epoch 188/200\n",
      "Training loss at step 0: 0.2042\n",
      "Training loss at step 100: 0.1356\n",
      "Training loss at step 200: 0.1077\n",
      "Training loss at step 300: 0.2434\n",
      "Training accuracy: 0.9319 Validation accuracy: 0.8976 Time taken: 108.39s\n",
      "Epoch 189/200\n",
      "Training loss at step 0: 0.2601\n",
      "Training loss at step 100: 0.1615\n",
      "Training loss at step 200: 0.1647\n",
      "Training loss at step 300: 0.1627\n",
      "Training accuracy: 0.9320 Validation accuracy: 0.8936 Time taken: 108.48s\n",
      "Epoch 190/200\n",
      "Training loss at step 0: 0.1639\n",
      "Training loss at step 100: 0.2228\n",
      "Training loss at step 200: 0.1813\n",
      "Training loss at step 300: 0.2015\n",
      "Training accuracy: 0.9344 Validation accuracy: 0.8938 Time taken: 108.85s\n",
      "Epoch 191/200\n",
      "Training loss at step 0: 0.1124\n",
      "Training loss at step 100: 0.4148\n",
      "Training loss at step 200: 0.2018\n",
      "Training loss at step 300: 0.1898\n",
      "Training accuracy: 0.9335 Validation accuracy: 0.8936 Time taken: 108.56s\n",
      "Epoch 192/200\n",
      "Training loss at step 0: 0.1920\n",
      "Training loss at step 100: 0.2598\n",
      "Training loss at step 200: 0.1633\n",
      "Training loss at step 300: 0.3573\n",
      "Training accuracy: 0.9327 Validation accuracy: 0.8940 Time taken: 109.06s\n",
      "Epoch 193/200\n",
      "Training loss at step 0: 0.3018\n",
      "Training loss at step 100: 0.0803\n",
      "Training loss at step 200: 0.1601\n",
      "Training loss at step 300: 0.2399\n",
      "Training accuracy: 0.9306 Validation accuracy: 0.8948 Time taken: 108.88s\n",
      "Epoch 194/200\n",
      "Training loss at step 0: 0.1538\n",
      "Training loss at step 100: 0.1839\n",
      "Training loss at step 200: 0.1964\n",
      "Training loss at step 300: 0.1770\n",
      "Training accuracy: 0.9340 Validation accuracy: 0.8926 Time taken: 112.65s\n",
      "Epoch 195/200\n",
      "Training loss at step 0: 0.3325\n",
      "Training loss at step 100: 0.2137\n",
      "Training loss at step 200: 0.1028\n",
      "Training loss at step 300: 0.4176\n",
      "Training accuracy: 0.9321 Validation accuracy: 0.8938 Time taken: 111.50s\n",
      "Epoch 196/200\n",
      "Training loss at step 0: 0.2599\n",
      "Training loss at step 100: 0.0935\n",
      "Training loss at step 200: 0.1829\n",
      "Training loss at step 300: 0.2448\n",
      "Training accuracy: 0.9317 Validation accuracy: 0.8936 Time taken: 113.21s\n",
      "Epoch 197/200\n",
      "Training loss at step 0: 0.1540\n",
      "Training loss at step 100: 0.1771\n",
      "Training loss at step 200: 0.2505\n",
      "Training loss at step 300: 0.2201\n",
      "Training accuracy: 0.9313 Validation accuracy: 0.8940 Time taken: 112.24s\n",
      "Epoch 198/200\n",
      "Training loss at step 0: 0.1955\n",
      "Training loss at step 100: 0.2447\n",
      "Training loss at step 200: 0.1218\n",
      "Training loss at step 300: 0.1190\n",
      "Training accuracy: 0.9366 Validation accuracy: 0.8936 Time taken: 112.78s\n",
      "Epoch 199/200\n",
      "Training loss at step 0: 0.1559\n",
      "Training loss at step 100: 0.0991\n",
      "Training loss at step 200: 0.1341\n",
      "Training loss at step 300: 0.1003\n",
      "Training accuracy: 0.9337 Validation accuracy: 0.8956 Time taken: 112.04s\n",
      "Epoch 200/200\n",
      "Training loss at step 0: 0.1818\n",
      "Training loss at step 100: 0.1136\n",
      "Training loss at step 200: 0.3022\n",
      "Training loss at step 300: 0.1555\n",
      "Training accuracy: 0.9304 Validation accuracy: 0.8952 Time taken: 112.10s\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1,nesterov=True)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "history = [[],[],[]]\n",
    "time_0 = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch %d/%d\" % (epoch+1,epochs))\n",
    "    if (epoch==100) | (epoch==150):\n",
    "        optimizer.learning_rate = optimizer.learning_rate/10\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    for x_batch_train, y_batch_train in train_data:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                \"Training loss at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "        step += 1\n",
    "        if step > len(x_train)/batch_size:\n",
    "            break\n",
    "\n",
    "    history[0].append(loss_value)\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    \n",
    "    step = 0\n",
    "    for x_batch_val, y_batch_val in validation_data:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "        step += 1\n",
    "        if step > len(x_val)/batch_size:\n",
    "            break\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    history[1].append(train_acc)\n",
    "    history[2].append(val_acc)\n",
    "    print(\"Training accuracy: %.4f\" % (float(train_acc),)\n",
    "          ,\"Validation accuracy: %.4f\" % (float(val_acc),),\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "total_time=time.time()-time_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74e4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = np.array(history)\n",
    "np.save(\"./Logs/StochasticNet110_cifar10\",log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b674eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "m.update_state(y_test, y_predict)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dca6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Logs/StochasticNet110_cifar10.npy', 'rb') as f:\n",
    "     log = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6285406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5cf23eb5f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1-log[1],label='training error')\n",
    "plt.plot(1-log[2],label='validation error')\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f505df7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21912.673411130905"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77d32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
