{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "under-warrior",
   "metadata": {},
   "source": [
    "## Training of CIFAR-10 using 110-layer ResNet with constant depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.neuralnets.ResNet110 import ResNet110\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D,Input,Flatten,Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "personalized-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data and standardize cifar10\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = (x_train - np.mean(x_train,axis=0))/np.std(x_train,axis=0)\n",
    "x_test = (x_test - np.mean(x_test,axis=0))/np.std(x_test,axis=0)\n",
    "##train validation split, 45000 for training and 5000 for validation\n",
    "np.random.seed(42)\n",
    "mask_val = np.random.choice(50000,5000,replace=False)\n",
    "mask_train = np.array([i for i in range(50000) if i not in mask_val])\n",
    "x_val, y_val = x_train[mask_val], y_train[mask_val]\n",
    "x_train, y_train = x_train[mask_train], y_train[mask_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation\n",
    "##augmented with horizontal flip,random erasing and random shift by 0.1\n",
    "# def randomErasing(x, cut_size=16):\n",
    "#     x = np.copy(x)\n",
    "#     fill = x.mean()\n",
    "\n",
    "#     h, w, _ = x.shape\n",
    "#     top = np.random.randint(0 - cut_size // 2, h - cut_size)\n",
    "#     left = np.random.randint(0 - cut_size // 2, w - cut_size)\n",
    "#     bottom = top + cut_size\n",
    "#     right = left + cut_size\n",
    "#     if top < 0:\n",
    "#         top = 0\n",
    "#     if left < 0:\n",
    "#         left = 0\n",
    "#     x[top:bottom, left:right, :].fill(fill)\n",
    "#     return x\n",
    "batch_size = 128\n",
    "datagen_for_train = ImageDataGenerator(horizontal_flip=True,width_shift_range= 4, height_shift_range= 4)\n",
    "datagen_for_test = ImageDataGenerator()\n",
    "train_data = datagen_for_train.flow(x_train,y_train,batch_size=batch_size)\n",
    "validation_data = datagen_for_test.flow(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "martial-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a ResNet110 model\n",
    "input_shape = x_train.shape[1:]\n",
    "num_class = 10\n",
    "model = ResNet110(input_shape=input_shape,num_class=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wound-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training loss at step 0: 10.1663\n",
      "Training loss at step 100: 2.1765\n",
      "Training loss at step 200: 2.0896\n",
      "Training loss at step 300: 1.9884\n",
      "Training accuracy: 0.2155 Validation accuracy: 0.2412 Time taken: 133.28s\n",
      "Epoch 2/200\n",
      "Training loss at step 0: 1.9539\n",
      "Training loss at step 100: 1.7224\n",
      "Training loss at step 200: 1.7275\n",
      "Training loss at step 300: 1.6132\n",
      "Training accuracy: 0.3532 Validation accuracy: 0.3948 Time taken: 127.62s\n",
      "Epoch 3/200\n",
      "Training loss at step 0: 1.6383\n",
      "Training loss at step 100: 1.5576\n",
      "Training loss at step 200: 1.5411\n",
      "Training loss at step 300: 1.3775\n",
      "Training accuracy: 0.4372 Validation accuracy: 0.4698 Time taken: 126.92s\n",
      "Epoch 4/200\n",
      "Training loss at step 0: 1.3810\n",
      "Training loss at step 100: 1.4250\n",
      "Training loss at step 200: 1.2638\n",
      "Training loss at step 300: 1.3891\n",
      "Training accuracy: 0.4964 Validation accuracy: 0.4476 Time taken: 127.18s\n",
      "Epoch 5/200\n",
      "Training loss at step 0: 1.3492\n",
      "Training loss at step 100: 1.2902\n",
      "Training loss at step 200: 1.2527\n",
      "Training loss at step 300: 1.2162\n",
      "Training accuracy: 0.5390 Validation accuracy: 0.4580 Time taken: 127.11s\n",
      "Epoch 6/200\n",
      "Training loss at step 0: 1.3009\n",
      "Training loss at step 100: 1.1159\n",
      "Training loss at step 200: 1.1523\n",
      "Training loss at step 300: 1.1781\n",
      "Training accuracy: 0.5803 Validation accuracy: 0.4338 Time taken: 127.57s\n",
      "Epoch 7/200\n",
      "Training loss at step 0: 1.1945\n",
      "Training loss at step 100: 0.8862\n",
      "Training loss at step 200: 0.9884\n",
      "Training loss at step 300: 1.0134\n",
      "Training accuracy: 0.6169 Validation accuracy: 0.5406 Time taken: 128.06s\n",
      "Epoch 8/200\n",
      "Training loss at step 0: 0.9998\n",
      "Training loss at step 100: 1.0723\n",
      "Training loss at step 200: 1.0557\n",
      "Training loss at step 300: 0.8790\n",
      "Training accuracy: 0.6424 Validation accuracy: 0.6136 Time taken: 127.38s\n",
      "Epoch 9/200\n",
      "Training loss at step 0: 0.8972\n",
      "Training loss at step 100: 1.0237\n",
      "Training loss at step 200: 0.9928\n",
      "Training loss at step 300: 0.8636\n",
      "Training accuracy: 0.6688 Validation accuracy: 0.6192 Time taken: 126.33s\n",
      "Epoch 10/200\n",
      "Training loss at step 0: 0.9654\n",
      "Training loss at step 100: 0.9833\n",
      "Training loss at step 200: 0.7744\n",
      "Training loss at step 300: 0.7566\n",
      "Training accuracy: 0.6917 Validation accuracy: 0.5500 Time taken: 125.18s\n",
      "Epoch 11/200\n",
      "Training loss at step 0: 0.8363\n",
      "Training loss at step 100: 0.6963\n",
      "Training loss at step 200: 0.8220\n",
      "Training loss at step 300: 0.8194\n",
      "Training accuracy: 0.7107 Validation accuracy: 0.6952 Time taken: 125.69s\n",
      "Epoch 12/200\n",
      "Training loss at step 0: 0.8917\n",
      "Training loss at step 100: 0.6268\n",
      "Training loss at step 200: 0.7962\n",
      "Training loss at step 300: 0.8474\n",
      "Training accuracy: 0.7297 Validation accuracy: 0.6834 Time taken: 125.93s\n",
      "Epoch 13/200\n",
      "Training loss at step 0: 0.7279\n",
      "Training loss at step 100: 0.7518\n",
      "Training loss at step 200: 0.8046\n",
      "Training loss at step 300: 0.6989\n",
      "Training accuracy: 0.7446 Validation accuracy: 0.6676 Time taken: 125.27s\n",
      "Epoch 14/200\n",
      "Training loss at step 0: 0.7515\n",
      "Training loss at step 100: 0.6630\n",
      "Training loss at step 200: 0.6091\n",
      "Training loss at step 300: 0.7046\n",
      "Training accuracy: 0.7599 Validation accuracy: 0.6920 Time taken: 126.55s\n",
      "Epoch 15/200\n",
      "Training loss at step 0: 0.5875\n",
      "Training loss at step 100: 0.7011\n",
      "Training loss at step 200: 0.8229\n",
      "Training loss at step 300: 0.5683\n",
      "Training accuracy: 0.7740 Validation accuracy: 0.6960 Time taken: 126.43s\n",
      "Epoch 16/200\n",
      "Training loss at step 0: 0.7663\n",
      "Training loss at step 100: 0.5687\n",
      "Training loss at step 200: 0.5734\n",
      "Training loss at step 300: 0.7947\n",
      "Training accuracy: 0.7814 Validation accuracy: 0.7672 Time taken: 126.46s\n",
      "Epoch 17/200\n",
      "Training loss at step 0: 0.6363\n",
      "Training loss at step 100: 0.6443\n",
      "Training loss at step 200: 0.6388\n",
      "Training loss at step 300: 0.5344\n",
      "Training accuracy: 0.7956 Validation accuracy: 0.7304 Time taken: 125.72s\n",
      "Epoch 18/200\n",
      "Training loss at step 0: 0.5877\n",
      "Training loss at step 100: 0.4396\n",
      "Training loss at step 200: 0.6897\n",
      "Training loss at step 300: 0.5703\n",
      "Training accuracy: 0.8041 Validation accuracy: 0.6474 Time taken: 124.19s\n",
      "Epoch 19/200\n",
      "Training loss at step 0: 0.4426\n",
      "Training loss at step 100: 0.6581\n",
      "Training loss at step 200: 0.5140\n",
      "Training loss at step 300: 0.6379\n",
      "Training accuracy: 0.8090 Validation accuracy: 0.7660 Time taken: 124.79s\n",
      "Epoch 20/200\n",
      "Training loss at step 0: 0.6031\n",
      "Training loss at step 100: 0.5374\n",
      "Training loss at step 200: 0.5318\n",
      "Training loss at step 300: 0.4109\n",
      "Training accuracy: 0.8203 Validation accuracy: 0.7540 Time taken: 125.06s\n",
      "Epoch 21/200\n",
      "Training loss at step 0: 0.6954\n",
      "Training loss at step 100: 0.7340\n",
      "Training loss at step 200: 0.5975\n",
      "Training loss at step 300: 0.5351\n",
      "Training accuracy: 0.8269 Validation accuracy: 0.7122 Time taken: 125.26s\n",
      "Epoch 22/200\n",
      "Training loss at step 0: 0.5091\n",
      "Training loss at step 100: 0.5052\n",
      "Training loss at step 200: 0.6024\n",
      "Training loss at step 300: 0.4076\n",
      "Training accuracy: 0.8314 Validation accuracy: 0.7832 Time taken: 125.98s\n",
      "Epoch 23/200\n",
      "Training loss at step 0: 0.4279\n",
      "Training loss at step 100: 0.4644\n",
      "Training loss at step 200: 0.4874\n",
      "Training loss at step 300: 0.5548\n",
      "Training accuracy: 0.8371 Validation accuracy: 0.7742 Time taken: 125.02s\n",
      "Epoch 24/200\n",
      "Training loss at step 0: 0.4113\n",
      "Training loss at step 100: 0.4028\n",
      "Training loss at step 200: 0.5696\n",
      "Training loss at step 300: 0.4634\n",
      "Training accuracy: 0.8445 Validation accuracy: 0.7852 Time taken: 125.89s\n",
      "Epoch 25/200\n",
      "Training loss at step 0: 0.5060\n",
      "Training loss at step 100: 0.4051\n",
      "Training loss at step 200: 0.4346\n",
      "Training loss at step 300: 0.3610\n",
      "Training accuracy: 0.8488 Validation accuracy: 0.7736 Time taken: 124.74s\n",
      "Epoch 26/200\n",
      "Training loss at step 0: 0.4936\n",
      "Training loss at step 100: 0.4518\n",
      "Training loss at step 200: 0.3239\n",
      "Training loss at step 300: 0.5005\n",
      "Training accuracy: 0.8542 Validation accuracy: 0.7702 Time taken: 126.43s\n",
      "Epoch 27/200\n",
      "Training loss at step 0: 0.5401\n",
      "Training loss at step 100: 0.3975\n",
      "Training loss at step 200: 0.4111\n",
      "Training loss at step 300: 0.3588\n",
      "Training accuracy: 0.8576 Validation accuracy: 0.7886 Time taken: 125.52s\n",
      "Epoch 28/200\n",
      "Training loss at step 0: 0.3245\n",
      "Training loss at step 100: 0.5336\n",
      "Training loss at step 200: 0.5392\n",
      "Training loss at step 300: 0.3787\n",
      "Training accuracy: 0.8630 Validation accuracy: 0.8176 Time taken: 125.94s\n",
      "Epoch 29/200\n",
      "Training loss at step 0: 0.3809\n",
      "Training loss at step 100: 0.2625\n",
      "Training loss at step 200: 0.3610\n",
      "Training loss at step 300: 0.4683\n",
      "Training accuracy: 0.8698 Validation accuracy: 0.7950 Time taken: 125.08s\n",
      "Epoch 30/200\n",
      "Training loss at step 0: 0.4383\n",
      "Training loss at step 100: 0.4197\n",
      "Training loss at step 200: 0.1903\n",
      "Training loss at step 300: 0.4282\n",
      "Training accuracy: 0.8718 Validation accuracy: 0.7732 Time taken: 125.69s\n",
      "Epoch 31/200\n",
      "Training loss at step 0: 0.2521\n",
      "Training loss at step 100: 0.4053\n",
      "Training loss at step 200: 0.3689\n",
      "Training loss at step 300: 0.2961\n",
      "Training accuracy: 0.8778 Validation accuracy: 0.8108 Time taken: 124.58s\n",
      "Epoch 32/200\n",
      "Training loss at step 0: 0.2345\n",
      "Training loss at step 100: 0.3738\n",
      "Training loss at step 200: 0.4563\n",
      "Training loss at step 300: 0.5145\n",
      "Training accuracy: 0.8790 Validation accuracy: 0.7314 Time taken: 125.58s\n",
      "Epoch 33/200\n",
      "Training loss at step 0: 0.3157\n",
      "Training loss at step 100: 0.2732\n",
      "Training loss at step 200: 0.3676\n",
      "Training loss at step 300: 0.2677\n",
      "Training accuracy: 0.8842 Validation accuracy: 0.8004 Time taken: 127.05s\n",
      "Epoch 34/200\n",
      "Training loss at step 0: 0.2278\n",
      "Training loss at step 100: 0.3569\n",
      "Training loss at step 200: 0.3779\n",
      "Training loss at step 300: 0.4001\n",
      "Training accuracy: 0.8881 Validation accuracy: 0.8104 Time taken: 127.12s\n",
      "Epoch 35/200\n",
      "Training loss at step 0: 0.3095\n",
      "Training loss at step 100: 0.3321\n",
      "Training loss at step 200: 0.3632\n",
      "Training loss at step 300: 0.2503\n",
      "Training accuracy: 0.8908 Validation accuracy: 0.7996 Time taken: 124.70s\n",
      "Epoch 36/200\n",
      "Training loss at step 0: 0.3889\n",
      "Training loss at step 100: 0.2395\n",
      "Training loss at step 200: 0.3218\n",
      "Training loss at step 300: 0.2804\n",
      "Training accuracy: 0.8932 Validation accuracy: 0.8058 Time taken: 125.12s\n",
      "Epoch 37/200\n",
      "Training loss at step 0: 0.2396\n",
      "Training loss at step 100: 0.2216\n",
      "Training loss at step 200: 0.2812\n",
      "Training loss at step 300: 0.3018\n",
      "Training accuracy: 0.8988 Validation accuracy: 0.7730 Time taken: 125.51s\n",
      "Epoch 38/200\n",
      "Training loss at step 0: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 100: 0.1918\n",
      "Training loss at step 200: 0.1783\n",
      "Training loss at step 300: 0.3194\n",
      "Training accuracy: 0.8994 Validation accuracy: 0.7776 Time taken: 124.79s\n",
      "Epoch 39/200\n",
      "Training loss at step 0: 0.2797\n",
      "Training loss at step 100: 0.2272\n",
      "Training loss at step 200: 0.2617\n",
      "Training loss at step 300: 0.3087\n",
      "Training accuracy: 0.9039 Validation accuracy: 0.8344 Time taken: 124.72s\n",
      "Epoch 40/200\n",
      "Training loss at step 0: 0.3150\n",
      "Training loss at step 100: 0.2466\n",
      "Training loss at step 200: 0.2887\n",
      "Training loss at step 300: 0.3186\n",
      "Training accuracy: 0.9068 Validation accuracy: 0.8156 Time taken: 125.33s\n",
      "Epoch 41/200\n",
      "Training loss at step 0: 0.3470\n",
      "Training loss at step 100: 0.3342\n",
      "Training loss at step 200: 0.2608\n",
      "Training loss at step 300: 0.2427\n",
      "Training accuracy: 0.9061 Validation accuracy: 0.7912 Time taken: 125.59s\n",
      "Epoch 42/200\n",
      "Training loss at step 0: 0.2840\n",
      "Training loss at step 100: 0.2318\n",
      "Training loss at step 200: 0.2509\n",
      "Training loss at step 300: 0.3523\n",
      "Training accuracy: 0.9109 Validation accuracy: 0.8316 Time taken: 126.03s\n",
      "Epoch 43/200\n",
      "Training loss at step 0: 0.3085\n",
      "Training loss at step 100: 0.1498\n",
      "Training loss at step 200: 0.3207\n",
      "Training loss at step 300: 0.2409\n",
      "Training accuracy: 0.9118 Validation accuracy: 0.8058 Time taken: 124.67s\n",
      "Epoch 44/200\n",
      "Training loss at step 0: 0.3624\n",
      "Training loss at step 100: 0.2367\n",
      "Training loss at step 200: 0.3018\n",
      "Training loss at step 300: 0.2470\n",
      "Training accuracy: 0.9150 Validation accuracy: 0.7756 Time taken: 124.51s\n",
      "Epoch 45/200\n",
      "Training loss at step 0: 0.2555\n",
      "Training loss at step 100: 0.2407\n",
      "Training loss at step 200: 0.2124\n",
      "Training loss at step 300: 0.1033\n",
      "Training accuracy: 0.9171 Validation accuracy: 0.8196 Time taken: 125.47s\n",
      "Epoch 46/200\n",
      "Training loss at step 0: 0.2849\n",
      "Training loss at step 100: 0.2288\n",
      "Training loss at step 200: 0.1227\n",
      "Training loss at step 300: 0.2030\n",
      "Training accuracy: 0.9225 Validation accuracy: 0.8056 Time taken: 124.96s\n",
      "Epoch 47/200\n",
      "Training loss at step 0: 0.2471\n",
      "Training loss at step 100: 0.2044\n",
      "Training loss at step 200: 0.2294\n",
      "Training loss at step 300: 0.1983\n",
      "Training accuracy: 0.9211 Validation accuracy: 0.8140 Time taken: 125.13s\n",
      "Epoch 48/200\n",
      "Training loss at step 0: 0.3364\n",
      "Training loss at step 100: 0.2028\n",
      "Training loss at step 200: 0.1894\n",
      "Training loss at step 300: 0.2452\n",
      "Training accuracy: 0.9272 Validation accuracy: 0.8462 Time taken: 125.65s\n",
      "Epoch 49/200\n",
      "Training loss at step 0: 0.2905\n",
      "Training loss at step 100: 0.1575\n",
      "Training loss at step 200: 0.3046\n",
      "Training loss at step 300: 0.1431\n",
      "Training accuracy: 0.9283 Validation accuracy: 0.8248 Time taken: 125.95s\n",
      "Epoch 50/200\n",
      "Training loss at step 0: 0.1442\n",
      "Training loss at step 100: 0.1145\n",
      "Training loss at step 200: 0.2166\n",
      "Training loss at step 300: 0.2289\n",
      "Training accuracy: 0.9299 Validation accuracy: 0.7972 Time taken: 126.12s\n",
      "Epoch 51/200\n",
      "Training loss at step 0: 0.2754\n",
      "Training loss at step 100: 0.1321\n",
      "Training loss at step 200: 0.2254\n",
      "Training loss at step 300: 0.1625\n",
      "Training accuracy: 0.9318 Validation accuracy: 0.7976 Time taken: 126.02s\n",
      "Epoch 52/200\n",
      "Training loss at step 0: 0.2874\n",
      "Training loss at step 100: 0.1359\n",
      "Training loss at step 200: 0.2818\n",
      "Training loss at step 300: 0.1416\n",
      "Training accuracy: 0.9315 Validation accuracy: 0.7700 Time taken: 125.19s\n",
      "Epoch 53/200\n",
      "Training loss at step 0: 0.1721\n",
      "Training loss at step 100: 0.1272\n",
      "Training loss at step 200: 0.1924\n",
      "Training loss at step 300: 0.2443\n",
      "Training accuracy: 0.9369 Validation accuracy: 0.7734 Time taken: 126.40s\n",
      "Epoch 54/200\n",
      "Training loss at step 0: 0.2921\n",
      "Training loss at step 100: 0.2045\n",
      "Training loss at step 200: 0.1423\n",
      "Training loss at step 300: 0.1568\n",
      "Training accuracy: 0.9356 Validation accuracy: 0.8108 Time taken: 125.90s\n",
      "Epoch 55/200\n",
      "Training loss at step 0: 0.1484\n",
      "Training loss at step 100: 0.1452\n",
      "Training loss at step 200: 0.1607\n",
      "Training loss at step 300: 0.1458\n",
      "Training accuracy: 0.9356 Validation accuracy: 0.8274 Time taken: 126.20s\n",
      "Epoch 56/200\n",
      "Training loss at step 0: 0.1784\n",
      "Training loss at step 100: 0.1441\n",
      "Training loss at step 200: 0.1171\n",
      "Training loss at step 300: 0.2371\n",
      "Training accuracy: 0.9379 Validation accuracy: 0.8276 Time taken: 125.31s\n",
      "Epoch 57/200\n",
      "Training loss at step 0: 0.1260\n",
      "Training loss at step 100: 0.1560\n",
      "Training loss at step 200: 0.2321\n",
      "Training loss at step 300: 0.1229\n",
      "Training accuracy: 0.9415 Validation accuracy: 0.7576 Time taken: 125.80s\n",
      "Epoch 58/200\n",
      "Training loss at step 0: 0.1309\n",
      "Training loss at step 100: 0.1751\n",
      "Training loss at step 200: 0.1411\n",
      "Training loss at step 300: 0.0697\n",
      "Training accuracy: 0.9432 Validation accuracy: 0.8124 Time taken: 124.61s\n",
      "Epoch 59/200\n",
      "Training loss at step 0: 0.1387\n",
      "Training loss at step 100: 0.0942\n",
      "Training loss at step 200: 0.1418\n",
      "Training loss at step 300: 0.1572\n",
      "Training accuracy: 0.9442 Validation accuracy: 0.8506 Time taken: 126.25s\n",
      "Epoch 60/200\n",
      "Training loss at step 0: 0.1309\n",
      "Training loss at step 100: 0.1986\n",
      "Training loss at step 200: 0.1008\n",
      "Training loss at step 300: 0.1960\n",
      "Training accuracy: 0.9454 Validation accuracy: 0.7836 Time taken: 126.11s\n",
      "Epoch 61/200\n",
      "Training loss at step 0: 0.1939\n",
      "Training loss at step 100: 0.1570\n",
      "Training loss at step 200: 0.1110\n",
      "Training loss at step 300: 0.1564\n",
      "Training accuracy: 0.9466 Validation accuracy: 0.8174 Time taken: 126.09s\n",
      "Epoch 62/200\n",
      "Training loss at step 0: 0.1613\n",
      "Training loss at step 100: 0.1949\n",
      "Training loss at step 200: 0.1940\n",
      "Training loss at step 300: 0.1790\n",
      "Training accuracy: 0.9500 Validation accuracy: 0.8116 Time taken: 126.80s\n",
      "Epoch 63/200\n",
      "Training loss at step 0: 0.0987\n",
      "Training loss at step 100: 0.1215\n",
      "Training loss at step 200: 0.0827\n",
      "Training loss at step 300: 0.0999\n",
      "Training accuracy: 0.9508 Validation accuracy: 0.8678 Time taken: 126.05s\n",
      "Epoch 64/200\n",
      "Training loss at step 0: 0.1194\n",
      "Training loss at step 100: 0.1027\n",
      "Training loss at step 200: 0.1921\n",
      "Training loss at step 300: 0.1201\n",
      "Training accuracy: 0.9516 Validation accuracy: 0.8232 Time taken: 125.47s\n",
      "Epoch 65/200\n",
      "Training loss at step 0: 0.1498\n",
      "Training loss at step 100: 0.0578\n",
      "Training loss at step 200: 0.0665\n",
      "Training loss at step 300: 0.1728\n",
      "Training accuracy: 0.9549 Validation accuracy: 0.8074 Time taken: 125.32s\n",
      "Epoch 66/200\n",
      "Training loss at step 0: 0.1908\n",
      "Training loss at step 100: 0.0860\n",
      "Training loss at step 200: 0.1178\n",
      "Training loss at step 300: 0.2933\n",
      "Training accuracy: 0.9546 Validation accuracy: 0.7714 Time taken: 124.28s\n",
      "Epoch 67/200\n",
      "Training loss at step 0: 0.3397\n",
      "Training loss at step 100: 0.1846\n",
      "Training loss at step 200: 0.1762\n",
      "Training loss at step 300: 0.1746\n",
      "Training accuracy: 0.9550 Validation accuracy: 0.8556 Time taken: 124.93s\n",
      "Epoch 68/200\n",
      "Training loss at step 0: 0.0933\n",
      "Training loss at step 100: 0.1631\n",
      "Training loss at step 200: 0.0799\n",
      "Training loss at step 300: 0.1120\n",
      "Training accuracy: 0.9580 Validation accuracy: 0.8472 Time taken: 124.29s\n",
      "Epoch 69/200\n",
      "Training loss at step 0: 0.0696\n",
      "Training loss at step 100: 0.0326\n",
      "Training loss at step 200: 0.1515\n",
      "Training loss at step 300: 0.1405\n",
      "Training accuracy: 0.9594 Validation accuracy: 0.8492 Time taken: 124.76s\n",
      "Epoch 70/200\n",
      "Training loss at step 0: 0.0927\n",
      "Training loss at step 100: 0.0392\n",
      "Training loss at step 200: 0.1492\n",
      "Training loss at step 300: 0.1107\n",
      "Training accuracy: 0.9570 Validation accuracy: 0.8400 Time taken: 124.36s\n",
      "Epoch 71/200\n",
      "Training loss at step 0: 0.0910\n",
      "Training loss at step 100: 0.1173\n",
      "Training loss at step 200: 0.0732\n",
      "Training loss at step 300: 0.1166\n",
      "Training accuracy: 0.9599 Validation accuracy: 0.8128 Time taken: 122.72s\n",
      "Epoch 72/200\n",
      "Training loss at step 0: 0.1108\n",
      "Training loss at step 100: 0.0531\n",
      "Training loss at step 200: 0.1014\n",
      "Training loss at step 300: 0.0811\n",
      "Training accuracy: 0.9608 Validation accuracy: 0.8482 Time taken: 121.88s\n",
      "Epoch 73/200\n",
      "Training loss at step 0: 0.1817\n",
      "Training loss at step 100: 0.0588\n",
      "Training loss at step 200: 0.1241\n",
      "Training loss at step 300: 0.1293\n",
      "Training accuracy: 0.9610 Validation accuracy: 0.8198 Time taken: 122.70s\n",
      "Epoch 74/200\n",
      "Training loss at step 0: 0.1283\n",
      "Training loss at step 100: 0.1282\n",
      "Training loss at step 200: 0.0969\n",
      "Training loss at step 300: 0.0732\n",
      "Training accuracy: 0.9616 Validation accuracy: 0.8598 Time taken: 122.66s\n",
      "Epoch 75/200\n",
      "Training loss at step 0: 0.1359\n",
      "Training loss at step 100: 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 200: 0.0945\n",
      "Training loss at step 300: 0.0923\n",
      "Training accuracy: 0.9650 Validation accuracy: 0.8498 Time taken: 123.20s\n",
      "Epoch 76/200\n",
      "Training loss at step 0: 0.1747\n",
      "Training loss at step 100: 0.1109\n",
      "Training loss at step 200: 0.1068\n",
      "Training loss at step 300: 0.0872\n",
      "Training accuracy: 0.9659 Validation accuracy: 0.8516 Time taken: 122.68s\n",
      "Epoch 77/200\n",
      "Training loss at step 0: 0.0723\n",
      "Training loss at step 100: 0.1560\n",
      "Training loss at step 200: 0.1156\n",
      "Training loss at step 300: 0.1487\n",
      "Training accuracy: 0.9644 Validation accuracy: 0.8198 Time taken: 123.58s\n",
      "Epoch 78/200\n",
      "Training loss at step 0: 0.1266\n",
      "Training loss at step 100: 0.0622\n",
      "Training loss at step 200: 0.0972\n",
      "Training loss at step 300: 0.1108\n",
      "Training accuracy: 0.9668 Validation accuracy: 0.8116 Time taken: 124.64s\n",
      "Epoch 79/200\n",
      "Training loss at step 0: 0.1646\n",
      "Training loss at step 100: 0.0389\n",
      "Training loss at step 200: 0.1630\n",
      "Training loss at step 300: 0.0791\n",
      "Training accuracy: 0.9692 Validation accuracy: 0.8136 Time taken: 123.41s\n",
      "Epoch 80/200\n",
      "Training loss at step 0: 0.0479\n",
      "Training loss at step 100: 0.0734\n",
      "Training loss at step 200: 0.1077\n",
      "Training loss at step 300: 0.1399\n",
      "Training accuracy: 0.9675 Validation accuracy: 0.8012 Time taken: 123.99s\n",
      "Epoch 81/200\n",
      "Training loss at step 0: 0.1871\n",
      "Training loss at step 100: 0.0578\n",
      "Training loss at step 200: 0.0474\n",
      "Training loss at step 300: 0.0795\n",
      "Training accuracy: 0.9704 Validation accuracy: 0.8144 Time taken: 124.01s\n",
      "Epoch 82/200\n",
      "Training loss at step 0: 0.0919\n",
      "Training loss at step 100: 0.0962\n",
      "Training loss at step 200: 0.1604\n",
      "Training loss at step 300: 0.0584\n",
      "Training accuracy: 0.9708 Validation accuracy: 0.7742 Time taken: 123.37s\n",
      "Epoch 83/200\n",
      "Training loss at step 0: 0.0579\n",
      "Training loss at step 100: 0.0586\n",
      "Training loss at step 200: 0.1397\n",
      "Training loss at step 300: 0.0793\n",
      "Training accuracy: 0.9686 Validation accuracy: 0.7858 Time taken: 123.60s\n",
      "Epoch 84/200\n",
      "Training loss at step 0: 0.0997\n",
      "Training loss at step 100: 0.0574\n",
      "Training loss at step 200: 0.0213\n",
      "Training loss at step 300: 0.0366\n",
      "Training accuracy: 0.9705 Validation accuracy: 0.8636 Time taken: 124.80s\n",
      "Epoch 85/200\n",
      "Training loss at step 0: 0.0744\n",
      "Training loss at step 100: 0.0807\n",
      "Training loss at step 200: 0.0405\n",
      "Training loss at step 300: 0.0977\n",
      "Training accuracy: 0.9716 Validation accuracy: 0.8378 Time taken: 126.93s\n",
      "Epoch 86/200\n",
      "Training loss at step 0: 0.1453\n",
      "Training loss at step 100: 0.0507\n",
      "Training loss at step 200: 0.1146\n",
      "Training loss at step 300: 0.0499\n",
      "Training accuracy: 0.9728 Validation accuracy: 0.8246 Time taken: 125.71s\n",
      "Epoch 87/200\n",
      "Training loss at step 0: 0.1225\n",
      "Training loss at step 100: 0.0525\n",
      "Training loss at step 200: 0.0990\n",
      "Training loss at step 300: 0.0167\n",
      "Training accuracy: 0.9716 Validation accuracy: 0.8272 Time taken: 123.58s\n",
      "Epoch 88/200\n",
      "Training loss at step 0: 0.2076\n",
      "Training loss at step 100: 0.0463\n",
      "Training loss at step 200: 0.0567\n",
      "Training loss at step 300: 0.0538\n",
      "Training accuracy: 0.9738 Validation accuracy: 0.8302 Time taken: 126.98s\n",
      "Epoch 89/200\n",
      "Training loss at step 0: 0.0558\n",
      "Training loss at step 100: 0.0664\n",
      "Training loss at step 200: 0.0688\n",
      "Training loss at step 300: 0.1326\n",
      "Training accuracy: 0.9742 Validation accuracy: 0.8190 Time taken: 123.92s\n",
      "Epoch 90/200\n",
      "Training loss at step 0: 0.2793\n",
      "Training loss at step 100: 0.0593\n",
      "Training loss at step 200: 0.0956\n",
      "Training loss at step 300: 0.0849\n",
      "Training accuracy: 0.9750 Validation accuracy: 0.8644 Time taken: 124.18s\n",
      "Epoch 91/200\n",
      "Training loss at step 0: 0.0267\n",
      "Training loss at step 100: 0.0635\n",
      "Training loss at step 200: 0.0320\n",
      "Training loss at step 300: 0.0413\n",
      "Training accuracy: 0.9756 Validation accuracy: 0.8416 Time taken: 124.53s\n",
      "Epoch 92/200\n",
      "Training loss at step 0: 0.0591\n",
      "Training loss at step 100: 0.1271\n",
      "Training loss at step 200: 0.0525\n",
      "Training loss at step 300: 0.0330\n",
      "Training accuracy: 0.9769 Validation accuracy: 0.8266 Time taken: 124.79s\n",
      "Epoch 93/200\n",
      "Training loss at step 0: 0.1121\n",
      "Training loss at step 100: 0.0417\n",
      "Training loss at step 200: 0.1069\n",
      "Training loss at step 300: 0.0947\n",
      "Training accuracy: 0.9757 Validation accuracy: 0.8566 Time taken: 124.41s\n",
      "Epoch 94/200\n",
      "Training loss at step 0: 0.0522\n",
      "Training loss at step 100: 0.1976\n",
      "Training loss at step 200: 0.0408\n",
      "Training loss at step 300: 0.0342\n",
      "Training accuracy: 0.9765 Validation accuracy: 0.8088 Time taken: 124.65s\n",
      "Epoch 95/200\n",
      "Training loss at step 0: 0.1296\n",
      "Training loss at step 100: 0.0643\n",
      "Training loss at step 200: 0.0679\n",
      "Training loss at step 300: 0.1180\n",
      "Training accuracy: 0.9779 Validation accuracy: 0.8278 Time taken: 124.24s\n",
      "Epoch 96/200\n",
      "Training loss at step 0: 0.0711\n",
      "Training loss at step 100: 0.0509\n",
      "Training loss at step 200: 0.0708\n",
      "Training loss at step 300: 0.1016\n",
      "Training accuracy: 0.9797 Validation accuracy: 0.8434 Time taken: 124.34s\n",
      "Epoch 97/200\n",
      "Training loss at step 0: 0.0393\n",
      "Training loss at step 100: 0.0810\n",
      "Training loss at step 200: 0.0388\n",
      "Training loss at step 300: 0.0113\n",
      "Training accuracy: 0.9776 Validation accuracy: 0.8604 Time taken: 124.45s\n",
      "Epoch 98/200\n",
      "Training loss at step 0: 0.0531\n",
      "Training loss at step 100: 0.0553\n",
      "Training loss at step 200: 0.0389\n",
      "Training loss at step 300: 0.0253\n",
      "Training accuracy: 0.9784 Validation accuracy: 0.8524 Time taken: 123.72s\n",
      "Epoch 99/200\n",
      "Training loss at step 0: 0.0413\n",
      "Training loss at step 100: 0.0873\n",
      "Training loss at step 200: 0.0922\n",
      "Training loss at step 300: 0.0421\n",
      "Training accuracy: 0.9801 Validation accuracy: 0.8602 Time taken: 124.53s\n",
      "Epoch 100/200\n",
      "Training loss at step 0: 0.0603\n",
      "Training loss at step 100: 0.0614\n",
      "Training loss at step 200: 0.0933\n",
      "Training loss at step 300: 0.0469\n",
      "Training accuracy: 0.9802 Validation accuracy: 0.8566 Time taken: 123.94s\n",
      "Epoch 101/200\n",
      "Training loss at step 0: 0.0314\n",
      "Training loss at step 100: 0.0349\n",
      "Training loss at step 200: 0.0105\n",
      "Training loss at step 300: 0.0291\n",
      "Training accuracy: 0.9886 Validation accuracy: 0.8942 Time taken: 124.82s\n",
      "Epoch 102/200\n",
      "Training loss at step 0: 0.0146\n",
      "Training loss at step 100: 0.0283\n",
      "Training loss at step 200: 0.0237\n",
      "Training loss at step 300: 0.0127\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.8974 Time taken: 123.55s\n",
      "Epoch 103/200\n",
      "Training loss at step 0: 0.0313\n",
      "Training loss at step 100: 0.0346\n",
      "Training loss at step 200: 0.0082\n",
      "Training loss at step 300: 0.0065\n",
      "Training accuracy: 0.9933 Validation accuracy: 0.8958 Time taken: 122.29s\n",
      "Epoch 104/200\n",
      "Training loss at step 0: 0.0094\n",
      "Training loss at step 100: 0.0304\n",
      "Training loss at step 200: 0.0128\n",
      "Training loss at step 300: 0.0284\n",
      "Training accuracy: 0.9940 Validation accuracy: 0.8988 Time taken: 122.57s\n",
      "Epoch 105/200\n",
      "Training loss at step 0: 0.0078\n",
      "Training loss at step 100: 0.0150\n",
      "Training loss at step 200: 0.0033\n",
      "Training loss at step 300: 0.0151\n",
      "Training accuracy: 0.9941 Validation accuracy: 0.8980 Time taken: 123.98s\n",
      "Epoch 106/200\n",
      "Training loss at step 0: 0.0032\n",
      "Training loss at step 100: 0.0039\n",
      "Training loss at step 200: 0.0039\n",
      "Training loss at step 300: 0.0044\n",
      "Training accuracy: 0.9942 Validation accuracy: 0.9004 Time taken: 124.04s\n",
      "Epoch 107/200\n",
      "Training loss at step 0: 0.0304\n",
      "Training loss at step 100: 0.0129\n",
      "Training loss at step 200: 0.0106\n",
      "Training loss at step 300: 0.0051\n",
      "Training accuracy: 0.9948 Validation accuracy: 0.9000 Time taken: 123.92s\n",
      "Epoch 108/200\n",
      "Training loss at step 0: 0.0038\n",
      "Training loss at step 100: 0.0366\n",
      "Training loss at step 200: 0.0118\n",
      "Training loss at step 300: 0.0439\n",
      "Training accuracy: 0.9952 Validation accuracy: 0.8984 Time taken: 123.21s\n",
      "Epoch 109/200\n",
      "Training loss at step 0: 0.0057\n",
      "Training loss at step 100: 0.0217\n",
      "Training loss at step 200: 0.0028\n",
      "Training loss at step 300: 0.0095\n",
      "Training accuracy: 0.9951 Validation accuracy: 0.8996 Time taken: 123.77s\n",
      "Epoch 110/200\n",
      "Training loss at step 0: 0.0041\n",
      "Training loss at step 100: 0.0191\n",
      "Training loss at step 200: 0.0101\n",
      "Training loss at step 300: 0.0069\n",
      "Training accuracy: 0.9956 Validation accuracy: 0.8972 Time taken: 122.44s\n",
      "Epoch 111/200\n",
      "Training loss at step 0: 0.0097\n",
      "Training loss at step 100: 0.0039\n",
      "Training loss at step 200: 0.0315\n",
      "Training loss at step 300: 0.0085\n",
      "Training accuracy: 0.9954 Validation accuracy: 0.8996 Time taken: 122.72s\n",
      "Epoch 112/200\n",
      "Training loss at step 0: 0.0021\n",
      "Training loss at step 100: 0.0069\n",
      "Training loss at step 200: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.0124\n",
      "Training accuracy: 0.9965 Validation accuracy: 0.8986 Time taken: 122.82s\n",
      "Epoch 113/200\n",
      "Training loss at step 0: 0.0456\n",
      "Training loss at step 100: 0.0365\n",
      "Training loss at step 200: 0.0277\n",
      "Training loss at step 300: 0.0023\n",
      "Training accuracy: 0.9958 Validation accuracy: 0.9004 Time taken: 123.89s\n",
      "Epoch 114/200\n",
      "Training loss at step 0: 0.0044\n",
      "Training loss at step 100: 0.0249\n",
      "Training loss at step 200: 0.0039\n",
      "Training loss at step 300: 0.0186\n",
      "Training accuracy: 0.9961 Validation accuracy: 0.8982 Time taken: 122.91s\n",
      "Epoch 115/200\n",
      "Training loss at step 0: 0.0118\n",
      "Training loss at step 100: 0.0075\n",
      "Training loss at step 200: 0.0046\n",
      "Training loss at step 300: 0.0152\n",
      "Training accuracy: 0.9963 Validation accuracy: 0.8996 Time taken: 122.27s\n",
      "Epoch 116/200\n",
      "Training loss at step 0: 0.0013\n",
      "Training loss at step 100: 0.0077\n",
      "Training loss at step 200: 0.0062\n",
      "Training loss at step 300: 0.0212\n",
      "Training accuracy: 0.9960 Validation accuracy: 0.9018 Time taken: 122.71s\n",
      "Epoch 117/200\n",
      "Training loss at step 0: 0.0024\n",
      "Training loss at step 100: 0.0109\n",
      "Training loss at step 200: 0.0018\n",
      "Training loss at step 300: 0.0018\n",
      "Training accuracy: 0.9967 Validation accuracy: 0.8982 Time taken: 123.28s\n",
      "Epoch 118/200\n",
      "Training loss at step 0: 0.0035\n",
      "Training loss at step 100: 0.0047\n",
      "Training loss at step 200: 0.0041\n",
      "Training loss at step 300: 0.0109\n",
      "Training accuracy: 0.9964 Validation accuracy: 0.8994 Time taken: 123.04s\n",
      "Epoch 119/200\n",
      "Training loss at step 0: 0.0055\n",
      "Training loss at step 100: 0.0558\n",
      "Training loss at step 200: 0.0155\n",
      "Training loss at step 300: 0.0086\n",
      "Training accuracy: 0.9961 Validation accuracy: 0.8994 Time taken: 122.63s\n",
      "Epoch 120/200\n",
      "Training loss at step 0: 0.0024\n",
      "Training loss at step 100: 0.0015\n",
      "Training loss at step 200: 0.0070\n",
      "Training loss at step 300: 0.0031\n",
      "Training accuracy: 0.9968 Validation accuracy: 0.8976 Time taken: 122.51s\n",
      "Epoch 121/200\n",
      "Training loss at step 0: 0.0049\n",
      "Training loss at step 100: 0.0111\n",
      "Training loss at step 200: 0.0045\n",
      "Training loss at step 300: 0.0035\n",
      "Training accuracy: 0.9975 Validation accuracy: 0.8980 Time taken: 122.80s\n",
      "Epoch 122/200\n",
      "Training loss at step 0: 0.0198\n",
      "Training loss at step 100: 0.0037\n",
      "Training loss at step 200: 0.0015\n",
      "Training loss at step 300: 0.0022\n",
      "Training accuracy: 0.9967 Validation accuracy: 0.8990 Time taken: 124.88s\n",
      "Epoch 123/200\n",
      "Training loss at step 0: 0.0054\n",
      "Training loss at step 100: 0.0125\n",
      "Training loss at step 200: 0.0016\n",
      "Training loss at step 300: 0.0207\n",
      "Training accuracy: 0.9975 Validation accuracy: 0.8990 Time taken: 123.04s\n",
      "Epoch 124/200\n",
      "Training loss at step 0: 0.0040\n",
      "Training loss at step 100: 0.0102\n",
      "Training loss at step 200: 0.0028\n",
      "Training loss at step 300: 0.0108\n",
      "Training accuracy: 0.9976 Validation accuracy: 0.8978 Time taken: 123.65s\n",
      "Epoch 125/200\n",
      "Training loss at step 0: 0.0028\n",
      "Training loss at step 100: 0.0036\n",
      "Training loss at step 200: 0.0019\n",
      "Training loss at step 300: 0.0077\n",
      "Training accuracy: 0.9968 Validation accuracy: 0.8976 Time taken: 124.20s\n",
      "Epoch 126/200\n",
      "Training loss at step 0: 0.0139\n",
      "Training loss at step 100: 0.0016\n",
      "Training loss at step 200: 0.0070\n",
      "Training loss at step 300: 0.0182\n",
      "Training accuracy: 0.9974 Validation accuracy: 0.8998 Time taken: 124.84s\n",
      "Epoch 127/200\n",
      "Training loss at step 0: 0.0078\n",
      "Training loss at step 100: 0.0046\n",
      "Training loss at step 200: 0.0008\n",
      "Training loss at step 300: 0.0061\n",
      "Training accuracy: 0.9972 Validation accuracy: 0.8990 Time taken: 124.05s\n",
      "Epoch 128/200\n",
      "Training loss at step 0: 0.0069\n",
      "Training loss at step 100: 0.0118\n",
      "Training loss at step 200: 0.0123\n",
      "Training loss at step 300: 0.0007\n",
      "Training accuracy: 0.9973 Validation accuracy: 0.9000 Time taken: 124.57s\n",
      "Epoch 129/200\n",
      "Training loss at step 0: 0.0050\n",
      "Training loss at step 100: 0.0205\n",
      "Training loss at step 200: 0.0126\n",
      "Training loss at step 300: 0.0059\n",
      "Training accuracy: 0.9973 Validation accuracy: 0.9002 Time taken: 123.80s\n",
      "Epoch 130/200\n",
      "Training loss at step 0: 0.0058\n",
      "Training loss at step 100: 0.0097\n",
      "Training loss at step 200: 0.0008\n",
      "Training loss at step 300: 0.0065\n",
      "Training accuracy: 0.9976 Validation accuracy: 0.9002 Time taken: 124.08s\n",
      "Epoch 131/200\n",
      "Training loss at step 0: 0.0011\n",
      "Training loss at step 100: 0.0140\n",
      "Training loss at step 200: 0.0079\n",
      "Training loss at step 300: 0.0049\n",
      "Training accuracy: 0.9970 Validation accuracy: 0.8984 Time taken: 123.28s\n",
      "Epoch 132/200\n",
      "Training loss at step 0: 0.0029\n",
      "Training loss at step 100: 0.0135\n",
      "Training loss at step 200: 0.0031\n",
      "Training loss at step 300: 0.0263\n",
      "Training accuracy: 0.9974 Validation accuracy: 0.9004 Time taken: 123.26s\n",
      "Epoch 133/200\n",
      "Training loss at step 0: 0.0074\n",
      "Training loss at step 100: 0.0055\n",
      "Training loss at step 200: 0.0377\n",
      "Training loss at step 300: 0.0012\n",
      "Training accuracy: 0.9970 Validation accuracy: 0.9008 Time taken: 124.17s\n",
      "Epoch 134/200\n",
      "Training loss at step 0: 0.0086\n",
      "Training loss at step 100: 0.0039\n",
      "Training loss at step 200: 0.0148\n",
      "Training loss at step 300: 0.0045\n",
      "Training accuracy: 0.9976 Validation accuracy: 0.8990 Time taken: 123.75s\n",
      "Epoch 135/200\n",
      "Training loss at step 0: 0.0026\n",
      "Training loss at step 100: 0.0064\n",
      "Training loss at step 200: 0.0093\n",
      "Training loss at step 300: 0.0033\n",
      "Training accuracy: 0.9977 Validation accuracy: 0.9016 Time taken: 122.83s\n",
      "Epoch 136/200\n",
      "Training loss at step 0: 0.0179\n",
      "Training loss at step 100: 0.0047\n",
      "Training loss at step 200: 0.0023\n",
      "Training loss at step 300: 0.0014\n",
      "Training accuracy: 0.9974 Validation accuracy: 0.9010 Time taken: 121.74s\n",
      "Epoch 137/200\n",
      "Training loss at step 0: 0.0121\n",
      "Training loss at step 100: 0.0088\n",
      "Training loss at step 200: 0.0026\n",
      "Training loss at step 300: 0.0254\n",
      "Training accuracy: 0.9976 Validation accuracy: 0.8980 Time taken: 123.21s\n",
      "Epoch 138/200\n",
      "Training loss at step 0: 0.0038\n",
      "Training loss at step 100: 0.0042\n",
      "Training loss at step 200: 0.0048\n",
      "Training loss at step 300: 0.0084\n",
      "Training accuracy: 0.9977 Validation accuracy: 0.8984 Time taken: 123.33s\n",
      "Epoch 139/200\n",
      "Training loss at step 0: 0.0035\n",
      "Training loss at step 100: 0.0018\n",
      "Training loss at step 200: 0.0023\n",
      "Training loss at step 300: 0.0040\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.8982 Time taken: 121.45s\n",
      "Epoch 140/200\n",
      "Training loss at step 0: 0.0071\n",
      "Training loss at step 100: 0.0171\n",
      "Training loss at step 200: 0.0012\n",
      "Training loss at step 300: 0.0008\n",
      "Training accuracy: 0.9978 Validation accuracy: 0.9004 Time taken: 123.35s\n",
      "Epoch 141/200\n",
      "Training loss at step 0: 0.0037\n",
      "Training loss at step 100: 0.0078\n",
      "Training loss at step 200: 0.0102\n",
      "Training loss at step 300: 0.0022\n",
      "Training accuracy: 0.9981 Validation accuracy: 0.9030 Time taken: 126.18s\n",
      "Epoch 142/200\n",
      "Training loss at step 0: 0.0113\n",
      "Training loss at step 100: 0.0014\n",
      "Training loss at step 200: 0.0054\n",
      "Training loss at step 300: 0.0040\n",
      "Training accuracy: 0.9978 Validation accuracy: 0.8990 Time taken: 124.05s\n",
      "Epoch 143/200\n",
      "Training loss at step 0: 0.0062\n",
      "Training loss at step 100: 0.0048\n",
      "Training loss at step 200: 0.0014\n",
      "Training loss at step 300: 0.0272\n",
      "Training accuracy: 0.9975 Validation accuracy: 0.8990 Time taken: 123.61s\n",
      "Epoch 144/200\n",
      "Training loss at step 0: 0.0119\n",
      "Training loss at step 100: 0.0005\n",
      "Training loss at step 200: 0.0251\n",
      "Training loss at step 300: 0.0032\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.8990 Time taken: 121.51s\n",
      "Epoch 145/200\n",
      "Training loss at step 0: 0.0151\n",
      "Training loss at step 100: 0.0012\n",
      "Training loss at step 200: 0.0029\n",
      "Training loss at step 300: 0.0081\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.8978 Time taken: 122.71s\n",
      "Epoch 146/200\n",
      "Training loss at step 0: 0.0213\n",
      "Training loss at step 100: 0.0012\n",
      "Training loss at step 200: 0.0024\n",
      "Training loss at step 300: 0.0023\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.8986 Time taken: 123.17s\n",
      "Epoch 147/200\n",
      "Training loss at step 0: 0.0027\n",
      "Training loss at step 100: 0.0181\n",
      "Training loss at step 200: 0.0055\n",
      "Training loss at step 300: 0.0020\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9002 Time taken: 124.95s\n",
      "Epoch 148/200\n",
      "Training loss at step 0: 0.0019\n",
      "Training loss at step 100: 0.0033\n",
      "Training loss at step 200: 0.0010\n",
      "Training loss at step 300: 0.0016\n",
      "Training accuracy: 0.9981 Validation accuracy: 0.9000 Time taken: 123.57s\n",
      "Epoch 149/200\n",
      "Training loss at step 0: 0.0011\n",
      "Training loss at step 100: 0.0048\n",
      "Training loss at step 200: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.0054\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9000 Time taken: 124.45s\n",
      "Epoch 150/200\n",
      "Training loss at step 0: 0.0052\n",
      "Training loss at step 100: 0.0238\n",
      "Training loss at step 200: 0.0103\n",
      "Training loss at step 300: 0.0014\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9000 Time taken: 126.47s\n",
      "Epoch 151/200\n",
      "Training loss at step 0: 0.0050\n",
      "Training loss at step 100: 0.0112\n",
      "Training loss at step 200: 0.0022\n",
      "Training loss at step 300: 0.0021\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9006 Time taken: 123.11s\n",
      "Epoch 152/200\n",
      "Training loss at step 0: 0.0037\n",
      "Training loss at step 100: 0.0112\n",
      "Training loss at step 200: 0.0007\n",
      "Training loss at step 300: 0.0008\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9006 Time taken: 123.58s\n",
      "Epoch 153/200\n",
      "Training loss at step 0: 0.0086\n",
      "Training loss at step 100: 0.0070\n",
      "Training loss at step 200: 0.0052\n",
      "Training loss at step 300: 0.0057\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9002 Time taken: 122.61s\n",
      "Epoch 154/200\n",
      "Training loss at step 0: 0.0037\n",
      "Training loss at step 100: 0.0081\n",
      "Training loss at step 200: 0.0232\n",
      "Training loss at step 300: 0.0010\n",
      "Training accuracy: 0.9985 Validation accuracy: 0.9002 Time taken: 123.34s\n",
      "Epoch 155/200\n",
      "Training loss at step 0: 0.0042\n",
      "Training loss at step 100: 0.0452\n",
      "Training loss at step 200: 0.0027\n",
      "Training loss at step 300: 0.0021\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9010 Time taken: 123.73s\n",
      "Epoch 156/200\n",
      "Training loss at step 0: 0.0115\n",
      "Training loss at step 100: 0.0077\n",
      "Training loss at step 200: 0.0053\n",
      "Training loss at step 300: 0.0248\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9006 Time taken: 123.88s\n",
      "Epoch 157/200\n",
      "Training loss at step 0: 0.0008\n",
      "Training loss at step 100: 0.0112\n",
      "Training loss at step 200: 0.0008\n",
      "Training loss at step 300: 0.0051\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9008 Time taken: 124.15s\n",
      "Epoch 158/200\n",
      "Training loss at step 0: 0.0058\n",
      "Training loss at step 100: 0.0038\n",
      "Training loss at step 200: 0.0052\n",
      "Training loss at step 300: 0.0164\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9010 Time taken: 125.61s\n",
      "Epoch 159/200\n",
      "Training loss at step 0: 0.0237\n",
      "Training loss at step 100: 0.0007\n",
      "Training loss at step 200: 0.0082\n",
      "Training loss at step 300: 0.0087\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9016 Time taken: 124.32s\n",
      "Epoch 160/200\n",
      "Training loss at step 0: 0.0032\n",
      "Training loss at step 100: 0.0023\n",
      "Training loss at step 200: 0.0073\n",
      "Training loss at step 300: 0.0042\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.9012 Time taken: 123.30s\n",
      "Epoch 161/200\n",
      "Training loss at step 0: 0.0082\n",
      "Training loss at step 100: 0.0056\n",
      "Training loss at step 200: 0.0006\n",
      "Training loss at step 300: 0.0106\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9010 Time taken: 124.58s\n",
      "Epoch 162/200\n",
      "Training loss at step 0: 0.0016\n",
      "Training loss at step 100: 0.0008\n",
      "Training loss at step 200: 0.0047\n",
      "Training loss at step 300: 0.0046\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9002 Time taken: 124.56s\n",
      "Epoch 163/200\n",
      "Training loss at step 0: 0.0080\n",
      "Training loss at step 100: 0.0010\n",
      "Training loss at step 200: 0.0610\n",
      "Training loss at step 300: 0.0057\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9002 Time taken: 122.82s\n",
      "Epoch 164/200\n",
      "Training loss at step 0: 0.0043\n",
      "Training loss at step 100: 0.0026\n",
      "Training loss at step 200: 0.0005\n",
      "Training loss at step 300: 0.0166\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.9000 Time taken: 123.30s\n",
      "Epoch 165/200\n",
      "Training loss at step 0: 0.0079\n",
      "Training loss at step 100: 0.0052\n",
      "Training loss at step 200: 0.0065\n",
      "Training loss at step 300: 0.0016\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9002 Time taken: 123.51s\n",
      "Epoch 166/200\n",
      "Training loss at step 0: 0.0014\n",
      "Training loss at step 100: 0.0066\n",
      "Training loss at step 200: 0.0266\n",
      "Training loss at step 300: 0.0067\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.9008 Time taken: 123.66s\n",
      "Epoch 167/200\n",
      "Training loss at step 0: 0.0018\n",
      "Training loss at step 100: 0.0005\n",
      "Training loss at step 200: 0.0013\n",
      "Training loss at step 300: 0.0008\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9002 Time taken: 123.48s\n",
      "Epoch 168/200\n",
      "Training loss at step 0: 0.0064\n",
      "Training loss at step 100: 0.0057\n",
      "Training loss at step 200: 0.0021\n",
      "Training loss at step 300: 0.0009\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9004 Time taken: 123.38s\n",
      "Epoch 169/200\n",
      "Training loss at step 0: 0.0012\n",
      "Training loss at step 100: 0.0019\n",
      "Training loss at step 200: 0.0061\n",
      "Training loss at step 300: 0.0031\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.9008 Time taken: 124.10s\n",
      "Epoch 170/200\n",
      "Training loss at step 0: 0.0248\n",
      "Training loss at step 100: 0.0014\n",
      "Training loss at step 200: 0.0013\n",
      "Training loss at step 300: 0.0006\n",
      "Training accuracy: 0.9986 Validation accuracy: 0.9010 Time taken: 123.17s\n",
      "Epoch 171/200\n",
      "Training loss at step 0: 0.0024\n",
      "Training loss at step 100: 0.0096\n",
      "Training loss at step 200: 0.0013\n",
      "Training loss at step 300: 0.0017\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9010 Time taken: 122.98s\n",
      "Epoch 172/200\n",
      "Training loss at step 0: 0.0034\n",
      "Training loss at step 100: 0.0011\n",
      "Training loss at step 200: 0.0022\n",
      "Training loss at step 300: 0.0021\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.9012 Time taken: 122.51s\n",
      "Epoch 173/200\n",
      "Training loss at step 0: 0.0009\n",
      "Training loss at step 100: 0.0025\n",
      "Training loss at step 200: 0.0018\n",
      "Training loss at step 300: 0.0025\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.9010 Time taken: 123.88s\n",
      "Epoch 174/200\n",
      "Training loss at step 0: 0.0152\n",
      "Training loss at step 100: 0.0250\n",
      "Training loss at step 200: 0.0055\n",
      "Training loss at step 300: 0.0274\n",
      "Training accuracy: 0.9978 Validation accuracy: 0.9004 Time taken: 124.55s\n",
      "Epoch 175/200\n",
      "Training loss at step 0: 0.0021\n",
      "Training loss at step 100: 0.0358\n",
      "Training loss at step 200: 0.0093\n",
      "Training loss at step 300: 0.0036\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9010 Time taken: 122.54s\n",
      "Epoch 176/200\n",
      "Training loss at step 0: 0.0008\n",
      "Training loss at step 100: 0.0208\n",
      "Training loss at step 200: 0.0021\n",
      "Training loss at step 300: 0.0008\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9008 Time taken: 122.92s\n",
      "Epoch 177/200\n",
      "Training loss at step 0: 0.0014\n",
      "Training loss at step 100: 0.0011\n",
      "Training loss at step 200: 0.0052\n",
      "Training loss at step 300: 0.0036\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.9012 Time taken: 123.39s\n",
      "Epoch 178/200\n",
      "Training loss at step 0: 0.0004\n",
      "Training loss at step 100: 0.0020\n",
      "Training loss at step 200: 0.0355\n",
      "Training loss at step 300: 0.0044\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9000 Time taken: 123.17s\n",
      "Epoch 179/200\n",
      "Training loss at step 0: 0.0022\n",
      "Training loss at step 100: 0.0053\n",
      "Training loss at step 200: 0.0149\n",
      "Training loss at step 300: 0.0008\n",
      "Training accuracy: 0.9979 Validation accuracy: 0.9000 Time taken: 123.17s\n",
      "Epoch 180/200\n",
      "Training loss at step 0: 0.0062\n",
      "Training loss at step 100: 0.0042\n",
      "Training loss at step 200: 0.0007\n",
      "Training loss at step 300: 0.0051\n",
      "Training accuracy: 0.9986 Validation accuracy: 0.8992 Time taken: 124.02s\n",
      "Epoch 181/200\n",
      "Training loss at step 0: 0.0043\n",
      "Training loss at step 100: 0.0010\n",
      "Training loss at step 200: 0.0066\n",
      "Training loss at step 300: 0.0091\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.8994 Time taken: 124.57s\n",
      "Epoch 182/200\n",
      "Training loss at step 0: 0.0043\n",
      "Training loss at step 100: 0.0013\n",
      "Training loss at step 200: 0.0069\n",
      "Training loss at step 300: 0.0009\n",
      "Training accuracy: 0.9980 Validation accuracy: 0.8994 Time taken: 124.85s\n",
      "Epoch 183/200\n",
      "Training loss at step 0: 0.0011\n",
      "Training loss at step 100: 0.0160\n",
      "Training loss at step 200: 0.0031\n",
      "Training loss at step 300: 0.0070\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.8996 Time taken: 123.35s\n",
      "Epoch 184/200\n",
      "Training loss at step 0: 0.0116\n",
      "Training loss at step 100: 0.0053\n",
      "Training loss at step 200: 0.0012\n",
      "Training loss at step 300: 0.0030\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.9002 Time taken: 122.55s\n",
      "Epoch 185/200\n",
      "Training loss at step 0: 0.0108\n",
      "Training loss at step 100: 0.0243\n",
      "Training loss at step 200: 0.0007\n",
      "Training loss at step 300: 0.0093\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.8994 Time taken: 123.54s\n",
      "Epoch 186/200\n",
      "Training loss at step 0: 0.0038\n",
      "Training loss at step 100: 0.0023\n",
      "Training loss at step 200: 0.0008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.0055\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.9000 Time taken: 123.71s\n",
      "Epoch 187/200\n",
      "Training loss at step 0: 0.0027\n",
      "Training loss at step 100: 0.0005\n",
      "Training loss at step 200: 0.0045\n",
      "Training loss at step 300: 0.0082\n",
      "Training accuracy: 0.9981 Validation accuracy: 0.9006 Time taken: 123.57s\n",
      "Epoch 188/200\n",
      "Training loss at step 0: 0.0041\n",
      "Training loss at step 100: 0.0017\n",
      "Training loss at step 200: 0.0034\n",
      "Training loss at step 300: 0.0054\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.8998 Time taken: 123.14s\n",
      "Epoch 189/200\n",
      "Training loss at step 0: 0.0034\n",
      "Training loss at step 100: 0.0087\n",
      "Training loss at step 200: 0.0025\n",
      "Training loss at step 300: 0.0054\n",
      "Training accuracy: 0.9986 Validation accuracy: 0.8998 Time taken: 123.49s\n",
      "Epoch 190/200\n",
      "Training loss at step 0: 0.0068\n",
      "Training loss at step 100: 0.0006\n",
      "Training loss at step 200: 0.0018\n",
      "Training loss at step 300: 0.0031\n",
      "Training accuracy: 0.9986 Validation accuracy: 0.9010 Time taken: 123.29s\n",
      "Epoch 191/200\n",
      "Training loss at step 0: 0.0023\n",
      "Training loss at step 100: 0.0011\n",
      "Training loss at step 200: 0.0013\n",
      "Training loss at step 300: 0.0015\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.8998 Time taken: 123.20s\n",
      "Epoch 192/200\n",
      "Training loss at step 0: 0.0007\n",
      "Training loss at step 100: 0.0022\n",
      "Training loss at step 200: 0.0040\n",
      "Training loss at step 300: 0.0306\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.8998 Time taken: 123.50s\n",
      "Epoch 193/200\n",
      "Training loss at step 0: 0.0203\n",
      "Training loss at step 100: 0.0019\n",
      "Training loss at step 200: 0.0209\n",
      "Training loss at step 300: 0.0012\n",
      "Training accuracy: 0.9985 Validation accuracy: 0.9002 Time taken: 123.03s\n",
      "Epoch 194/200\n",
      "Training loss at step 0: 0.0019\n",
      "Training loss at step 100: 0.0080\n",
      "Training loss at step 200: 0.0021\n",
      "Training loss at step 300: 0.0018\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.9000 Time taken: 122.58s\n",
      "Epoch 195/200\n",
      "Training loss at step 0: 0.0037\n",
      "Training loss at step 100: 0.0018\n",
      "Training loss at step 200: 0.0179\n",
      "Training loss at step 300: 0.0026\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.8996 Time taken: 122.02s\n",
      "Epoch 196/200\n",
      "Training loss at step 0: 0.0033\n",
      "Training loss at step 100: 0.0046\n",
      "Training loss at step 200: 0.0053\n",
      "Training loss at step 300: 0.0054\n",
      "Training accuracy: 0.9985 Validation accuracy: 0.8994 Time taken: 121.96s\n",
      "Epoch 197/200\n",
      "Training loss at step 0: 0.0020\n",
      "Training loss at step 100: 0.0114\n",
      "Training loss at step 200: 0.0009\n",
      "Training loss at step 300: 0.0021\n",
      "Training accuracy: 0.9984 Validation accuracy: 0.8994 Time taken: 122.51s\n",
      "Epoch 198/200\n",
      "Training loss at step 0: 0.0009\n",
      "Training loss at step 100: 0.0020\n",
      "Training loss at step 200: 0.0016\n",
      "Training loss at step 300: 0.0036\n",
      "Training accuracy: 0.9982 Validation accuracy: 0.8994 Time taken: 124.60s\n",
      "Epoch 199/200\n",
      "Training loss at step 0: 0.0526\n",
      "Training loss at step 100: 0.0045\n",
      "Training loss at step 200: 0.0113\n",
      "Training loss at step 300: 0.0139\n",
      "Training accuracy: 0.9985 Validation accuracy: 0.9008 Time taken: 122.46s\n",
      "Epoch 200/200\n",
      "Training loss at step 0: 0.0035\n",
      "Training loss at step 100: 0.0031\n",
      "Training loss at step 200: 0.0003\n",
      "Training loss at step 300: 0.0076\n",
      "Training accuracy: 0.9983 Validation accuracy: 0.9004 Time taken: 122.12s\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1,nesterov=True)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "history = [[],[],[]]\n",
    "time_0 = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch %d/%d\" % (epoch+1,epochs))\n",
    "    if (epoch==100) | (epoch==150):\n",
    "        optimizer.learning_rate = optimizer.learning_rate/10\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    for x_batch_train, y_batch_train in train_data:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                \"Training loss at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "        step += 1\n",
    "        if step > len(x_train)/batch_size:\n",
    "            break\n",
    "\n",
    "    history[0].append(loss_value.numpy())\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    \n",
    "    step = 0\n",
    "    for x_batch_val, y_batch_val in validation_data:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "        step += 1\n",
    "        if step > len(x_val)/batch_size:\n",
    "            break\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    history[1].append(train_acc.numpy())\n",
    "    history[2].append(val_acc.numpy())\n",
    "    print(\"Training accuracy: %.4f\" % (float(train_acc),)\n",
    "          ,\"Validation accuracy: %.4f\" % (float(val_acc),),\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "total_time=time.time()-time_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9b850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = np.array(history)\n",
    "np.save(\"./Logs/ResNet110_cifar10\",log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9967c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Logs/ResNet110_cifar10.npy', 'rb') as f:\n",
    "     log = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d0d541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb0fcdd66a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1-log[1],label='training error')\n",
    "plt.plot(1-log[2],label='validation error')\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2fdf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8907"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "m.update_state(y_test, y_pred)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ee7bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24874.805114269257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4251ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
