{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-momentum",
   "metadata": {},
   "source": [
    "## Training of CIFAR-100 using 110-layer ResNet with stochastic depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.neuralnets.StochasticNet import StochasticNet110\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D,Input,Flatten,Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data and standardize\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train = (x_train - np.mean(x_train,axis=0))/np.std(x_train,axis=0)\n",
    "x_test = (x_test - np.mean(x_test,axis=0))/np.std(x_test,axis=0)\n",
    "##train validation split, 45000 for training and 5000 for validation\n",
    "np.random.seed(42)\n",
    "mask_val = np.random.choice(50000,5000,replace=False)\n",
    "mask_train = np.array([i for i in range(50000) if i not in mask_val])\n",
    "x_val, y_val = x_train[mask_val], y_train[mask_val]\n",
    "x_train, y_train = x_train[mask_train], y_train[mask_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "filled-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datagen_for_train = ImageDataGenerator(horizontal_flip=True,width_shift_range= 4, height_shift_range= 4)\n",
    "datagen_for_test = ImageDataGenerator()\n",
    "train_data = datagen_for_train.flow(x_train,y_train,batch_size=batch_size)\n",
    "validation_data = datagen_for_test.flow(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "under-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a ResNet110 model\n",
    "input_shape = x_train.shape[1:]\n",
    "num_class = 100\n",
    "model = StochasticNet110(input_shape=input_shape,num_class=num_class,p_L=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southwest-assessment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training loss at step 0: 11.8484\n",
      "Training loss at step 100: 4.7865\n",
      "Training loss at step 200: 4.7037\n",
      "Training loss at step 300: 4.7963\n",
      "Training accuracy: 0.0116 Validation accuracy: 0.0090 Time taken: 136.86s\n",
      "Epoch 2/200\n",
      "Training loss at step 0: 4.7097\n",
      "Training loss at step 100: 4.6589\n",
      "Training loss at step 200: 4.4617\n",
      "Training loss at step 300: 4.2278\n",
      "Training accuracy: 0.0348 Validation accuracy: 0.0554 Time taken: 110.93s\n",
      "Epoch 3/200\n",
      "Training loss at step 0: 4.2007\n",
      "Training loss at step 100: 4.1381\n",
      "Training loss at step 200: 4.2622\n",
      "Training loss at step 300: 3.9663\n",
      "Training accuracy: 0.0627 Validation accuracy: 0.0722 Time taken: 111.97s\n",
      "Epoch 4/200\n",
      "Training loss at step 0: 4.1284\n",
      "Training loss at step 100: 3.8883\n",
      "Training loss at step 200: 3.9603\n",
      "Training loss at step 300: 3.7853\n",
      "Training accuracy: 0.0849 Validation accuracy: 0.1006 Time taken: 112.65s\n",
      "Epoch 5/200\n",
      "Training loss at step 0: 3.7128\n",
      "Training loss at step 100: 4.1292\n",
      "Training loss at step 200: 3.7507\n",
      "Training loss at step 300: 3.9024\n",
      "Training accuracy: 0.1035 Validation accuracy: 0.1056 Time taken: 110.92s\n",
      "Epoch 6/200\n",
      "Training loss at step 0: 3.9549\n",
      "Training loss at step 100: 3.6391\n",
      "Training loss at step 200: 3.5992\n",
      "Training loss at step 300: 3.7060\n",
      "Training accuracy: 0.1188 Validation accuracy: 0.1256 Time taken: 110.54s\n",
      "Epoch 7/200\n",
      "Training loss at step 0: 3.5718\n",
      "Training loss at step 100: 3.8347\n",
      "Training loss at step 200: 3.6416\n",
      "Training loss at step 300: 3.7392\n",
      "Training accuracy: 0.1366 Validation accuracy: 0.1354 Time taken: 110.82s\n",
      "Epoch 8/200\n",
      "Training loss at step 0: 3.3841\n",
      "Training loss at step 100: 3.4089\n",
      "Training loss at step 200: 3.4764\n",
      "Training loss at step 300: 3.3294\n",
      "Training accuracy: 0.1548 Validation accuracy: 0.1684 Time taken: 112.21s\n",
      "Epoch 9/200\n",
      "Training loss at step 0: 3.6172\n",
      "Training loss at step 100: 3.1914\n",
      "Training loss at step 200: 3.5928\n",
      "Training loss at step 300: 3.2889\n",
      "Training accuracy: 0.1723 Validation accuracy: 0.1832 Time taken: 111.54s\n",
      "Epoch 10/200\n",
      "Training loss at step 0: 3.4618\n",
      "Training loss at step 100: 3.4524\n",
      "Training loss at step 200: 3.2608\n",
      "Training loss at step 300: 3.3259\n",
      "Training accuracy: 0.1911 Validation accuracy: 0.1950 Time taken: 111.84s\n",
      "Epoch 11/200\n",
      "Training loss at step 0: 3.2458\n",
      "Training loss at step 100: 3.4814\n",
      "Training loss at step 200: 3.0895\n",
      "Training loss at step 300: 3.1069\n",
      "Training accuracy: 0.2076 Validation accuracy: 0.2104 Time taken: 111.33s\n",
      "Epoch 12/200\n",
      "Training loss at step 0: 3.1753\n",
      "Training loss at step 100: 3.1736\n",
      "Training loss at step 200: 2.9301\n",
      "Training loss at step 300: 3.1245\n",
      "Training accuracy: 0.2200 Validation accuracy: 0.2384 Time taken: 111.53s\n",
      "Epoch 13/200\n",
      "Training loss at step 0: 3.1282\n",
      "Training loss at step 100: 2.7921\n",
      "Training loss at step 200: 3.0627\n",
      "Training loss at step 300: 2.8865\n",
      "Training accuracy: 0.2380 Validation accuracy: 0.2428 Time taken: 111.51s\n",
      "Epoch 14/200\n",
      "Training loss at step 0: 3.1719\n",
      "Training loss at step 100: 3.0580\n",
      "Training loss at step 200: 2.8701\n",
      "Training loss at step 300: 3.4049\n",
      "Training accuracy: 0.2472 Validation accuracy: 0.0652 Time taken: 111.83s\n",
      "Epoch 15/200\n",
      "Training loss at step 0: 3.0021\n",
      "Training loss at step 100: 2.9609\n",
      "Training loss at step 200: 2.9514\n",
      "Training loss at step 300: 2.9911\n",
      "Training accuracy: 0.2552 Validation accuracy: 0.2394 Time taken: 111.49s\n",
      "Epoch 16/200\n",
      "Training loss at step 0: 2.7178\n",
      "Training loss at step 100: 3.0919\n",
      "Training loss at step 200: 2.5058\n",
      "Training loss at step 300: 2.6984\n",
      "Training accuracy: 0.2789 Validation accuracy: 0.2828 Time taken: 111.91s\n",
      "Epoch 17/200\n",
      "Training loss at step 0: 2.7187\n",
      "Training loss at step 100: 2.5570\n",
      "Training loss at step 200: 2.7708\n",
      "Training loss at step 300: 2.4638\n",
      "Training accuracy: 0.2924 Validation accuracy: 0.2946 Time taken: 111.79s\n",
      "Epoch 18/200\n",
      "Training loss at step 0: 2.8275\n",
      "Training loss at step 100: 2.7537\n",
      "Training loss at step 200: 2.4488\n",
      "Training loss at step 300: 2.5929\n",
      "Training accuracy: 0.3074 Validation accuracy: 0.3344 Time taken: 110.60s\n",
      "Epoch 19/200\n",
      "Training loss at step 0: 2.8504\n",
      "Training loss at step 100: 3.0575\n",
      "Training loss at step 200: 2.7349\n",
      "Training loss at step 300: 2.6069\n",
      "Training accuracy: 0.3193 Validation accuracy: 0.3484 Time taken: 110.69s\n",
      "Epoch 20/200\n",
      "Training loss at step 0: 2.5223\n",
      "Training loss at step 100: 2.5104\n",
      "Training loss at step 200: 2.4174\n",
      "Training loss at step 300: 2.6298\n",
      "Training accuracy: 0.3334 Validation accuracy: 0.3420 Time taken: 115.34s\n",
      "Epoch 21/200\n",
      "Training loss at step 0: 2.3852\n",
      "Training loss at step 100: 2.5617\n",
      "Training loss at step 200: 2.7996\n",
      "Training loss at step 300: 2.4233\n",
      "Training accuracy: 0.3374 Validation accuracy: 0.2894 Time taken: 111.89s\n",
      "Epoch 22/200\n",
      "Training loss at step 0: 2.6667\n",
      "Training loss at step 100: 2.3863\n",
      "Training loss at step 200: 2.4259\n",
      "Training loss at step 300: 2.4561\n",
      "Training accuracy: 0.3494 Validation accuracy: 0.3586 Time taken: 111.51s\n",
      "Epoch 23/200\n",
      "Training loss at step 0: 2.3132\n",
      "Training loss at step 100: 2.4652\n",
      "Training loss at step 200: 2.5738\n",
      "Training loss at step 300: 2.7097\n",
      "Training accuracy: 0.3673 Validation accuracy: 0.3716 Time taken: 111.95s\n",
      "Epoch 24/200\n",
      "Training loss at step 0: 2.3870\n",
      "Training loss at step 100: 2.2492\n",
      "Training loss at step 200: 2.0068\n",
      "Training loss at step 300: 2.5293\n",
      "Training accuracy: 0.3749 Validation accuracy: 0.3660 Time taken: 111.39s\n",
      "Epoch 25/200\n",
      "Training loss at step 0: 2.3069\n",
      "Training loss at step 100: 2.2622\n",
      "Training loss at step 200: 2.4614\n",
      "Training loss at step 300: 2.2508\n",
      "Training accuracy: 0.3828 Validation accuracy: 0.3620 Time taken: 110.54s\n",
      "Epoch 26/200\n",
      "Training loss at step 0: 2.5716\n",
      "Training loss at step 100: 2.1933\n",
      "Training loss at step 200: 2.3216\n",
      "Training loss at step 300: 2.3621\n",
      "Training accuracy: 0.3954 Validation accuracy: 0.4056 Time taken: 111.48s\n",
      "Epoch 27/200\n",
      "Training loss at step 0: 2.6414\n",
      "Training loss at step 100: 2.2087\n",
      "Training loss at step 200: 2.0826\n",
      "Training loss at step 300: 2.1739\n",
      "Training accuracy: 0.4046 Validation accuracy: 0.4190 Time taken: 111.74s\n",
      "Epoch 28/200\n",
      "Training loss at step 0: 1.9858\n",
      "Training loss at step 100: 2.3863\n",
      "Training loss at step 200: 2.0619\n",
      "Training loss at step 300: 2.3554\n",
      "Training accuracy: 0.4124 Validation accuracy: 0.4058 Time taken: 111.18s\n",
      "Epoch 29/200\n",
      "Training loss at step 0: 2.2311\n",
      "Training loss at step 100: 2.0549\n",
      "Training loss at step 200: 2.0999\n",
      "Training loss at step 300: 2.1678\n",
      "Training accuracy: 0.4256 Validation accuracy: 0.4008 Time taken: 112.41s\n",
      "Epoch 30/200\n",
      "Training loss at step 0: 2.1019\n",
      "Training loss at step 100: 2.3441\n",
      "Training loss at step 200: 2.1345\n",
      "Training loss at step 300: 2.1171\n",
      "Training accuracy: 0.4292 Validation accuracy: 0.3406 Time taken: 111.18s\n",
      "Epoch 31/200\n",
      "Training loss at step 0: 2.5230\n",
      "Training loss at step 100: 2.0335\n",
      "Training loss at step 200: 1.8838\n",
      "Training loss at step 300: 2.0880\n",
      "Training accuracy: 0.4331 Validation accuracy: 0.4218 Time taken: 111.78s\n",
      "Epoch 32/200\n",
      "Training loss at step 0: 1.8669\n",
      "Training loss at step 100: 2.1172\n",
      "Training loss at step 200: 1.9304\n",
      "Training loss at step 300: 2.2451\n",
      "Training accuracy: 0.4446 Validation accuracy: 0.4068 Time taken: 111.84s\n",
      "Epoch 33/200\n",
      "Training loss at step 0: 2.0449\n",
      "Training loss at step 100: 2.1913\n",
      "Training loss at step 200: 1.8851\n",
      "Training loss at step 300: 2.3491\n",
      "Training accuracy: 0.4519 Validation accuracy: 0.4142 Time taken: 111.45s\n",
      "Epoch 34/200\n",
      "Training loss at step 0: 2.1244\n",
      "Training loss at step 100: 2.0895\n",
      "Training loss at step 200: 2.1470\n",
      "Training loss at step 300: 1.9460\n",
      "Training accuracy: 0.4550 Validation accuracy: 0.4164 Time taken: 110.60s\n",
      "Epoch 35/200\n",
      "Training loss at step 0: 2.0126\n",
      "Training loss at step 100: 2.2063\n",
      "Training loss at step 200: 2.0105\n",
      "Training loss at step 300: 1.8332\n",
      "Training accuracy: 0.4605 Validation accuracy: 0.3626 Time taken: 111.06s\n",
      "Epoch 36/200\n",
      "Training loss at step 0: 1.8733\n",
      "Training loss at step 100: 1.7968\n",
      "Training loss at step 200: 1.7779\n",
      "Training loss at step 300: 1.8480\n",
      "Training accuracy: 0.4712 Validation accuracy: 0.4602 Time taken: 111.13s\n",
      "Epoch 37/200\n",
      "Training loss at step 0: 1.7421\n",
      "Training loss at step 100: 2.0917\n",
      "Training loss at step 200: 1.7918\n",
      "Training loss at step 300: 1.9272\n",
      "Training accuracy: 0.4746 Validation accuracy: 0.4572 Time taken: 110.62s\n",
      "Epoch 38/200\n",
      "Training loss at step 0: 1.9436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 100: 1.9159\n",
      "Training loss at step 200: 1.9728\n",
      "Training loss at step 300: 1.6878\n",
      "Training accuracy: 0.4840 Validation accuracy: 0.4658 Time taken: 111.08s\n",
      "Epoch 39/200\n",
      "Training loss at step 0: 1.5207\n",
      "Training loss at step 100: 1.8199\n",
      "Training loss at step 200: 2.0307\n",
      "Training loss at step 300: 1.6193\n",
      "Training accuracy: 0.4847 Validation accuracy: 0.4408 Time taken: 111.34s\n",
      "Epoch 40/200\n",
      "Training loss at step 0: 1.8587\n",
      "Training loss at step 100: 1.5940\n",
      "Training loss at step 200: 2.0950\n",
      "Training loss at step 300: 1.6903\n",
      "Training accuracy: 0.4936 Validation accuracy: 0.4800 Time taken: 111.14s\n",
      "Epoch 41/200\n",
      "Training loss at step 0: 2.3314\n",
      "Training loss at step 100: 2.0624\n",
      "Training loss at step 200: 2.0438\n",
      "Training loss at step 300: 2.0769\n",
      "Training accuracy: 0.4930 Validation accuracy: 0.4136 Time taken: 110.69s\n",
      "Epoch 42/200\n",
      "Training loss at step 0: 1.8799\n",
      "Training loss at step 100: 1.6142\n",
      "Training loss at step 200: 1.7635\n",
      "Training loss at step 300: 1.5604\n",
      "Training accuracy: 0.5066 Validation accuracy: 0.4616 Time taken: 110.98s\n",
      "Epoch 43/200\n",
      "Training loss at step 0: 1.9685\n",
      "Training loss at step 100: 1.6259\n",
      "Training loss at step 200: 1.5581\n",
      "Training loss at step 300: 1.5135\n",
      "Training accuracy: 0.5072 Validation accuracy: 0.4884 Time taken: 111.07s\n",
      "Epoch 44/200\n",
      "Training loss at step 0: 1.5451\n",
      "Training loss at step 100: 1.9539\n",
      "Training loss at step 200: 1.5801\n",
      "Training loss at step 300: 2.1862\n",
      "Training accuracy: 0.5106 Validation accuracy: 0.4642 Time taken: 110.87s\n",
      "Epoch 45/200\n",
      "Training loss at step 0: 1.6220\n",
      "Training loss at step 100: 1.7153\n",
      "Training loss at step 200: 1.5958\n",
      "Training loss at step 300: 1.8401\n",
      "Training accuracy: 0.5134 Validation accuracy: 0.4644 Time taken: 111.04s\n",
      "Epoch 46/200\n",
      "Training loss at step 0: 1.9765\n",
      "Training loss at step 100: 1.7103\n",
      "Training loss at step 200: 1.7676\n",
      "Training loss at step 300: 1.7410\n",
      "Training accuracy: 0.5236 Validation accuracy: 0.4856 Time taken: 110.66s\n",
      "Epoch 47/200\n",
      "Training loss at step 0: 1.6562\n",
      "Training loss at step 100: 1.6654\n",
      "Training loss at step 200: 1.6681\n",
      "Training loss at step 300: 1.3516\n",
      "Training accuracy: 0.5264 Validation accuracy: 0.4564 Time taken: 113.29s\n",
      "Epoch 48/200\n",
      "Training loss at step 0: 1.8495\n",
      "Training loss at step 100: 1.6103\n",
      "Training loss at step 200: 1.3874\n",
      "Training loss at step 300: 1.4373\n",
      "Training accuracy: 0.5339 Validation accuracy: 0.4876 Time taken: 112.34s\n",
      "Epoch 49/200\n",
      "Training loss at step 0: 1.3923\n",
      "Training loss at step 100: 1.4029\n",
      "Training loss at step 200: 1.5162\n",
      "Training loss at step 300: 1.5958\n",
      "Training accuracy: 0.5362 Validation accuracy: 0.4788 Time taken: 112.94s\n",
      "Epoch 50/200\n",
      "Training loss at step 0: 1.2883\n",
      "Training loss at step 100: 1.5044\n",
      "Training loss at step 200: 1.6670\n",
      "Training loss at step 300: 1.8945\n",
      "Training accuracy: 0.5390 Validation accuracy: 0.4972 Time taken: 111.82s\n",
      "Epoch 51/200\n",
      "Training loss at step 0: 1.6196\n",
      "Training loss at step 100: 1.9020\n",
      "Training loss at step 200: 1.7353\n",
      "Training loss at step 300: 1.7983\n",
      "Training accuracy: 0.5404 Validation accuracy: 0.4600 Time taken: 111.17s\n",
      "Epoch 52/200\n",
      "Training loss at step 0: 1.7809\n",
      "Training loss at step 100: 1.8011\n",
      "Training loss at step 200: 1.5420\n",
      "Training loss at step 300: 1.6182\n",
      "Training accuracy: 0.5475 Validation accuracy: 0.4862 Time taken: 111.84s\n",
      "Epoch 53/200\n",
      "Training loss at step 0: 1.6694\n",
      "Training loss at step 100: 1.5020\n",
      "Training loss at step 200: 1.5219\n",
      "Training loss at step 300: 1.9813\n",
      "Training accuracy: 0.5486 Validation accuracy: 0.4966 Time taken: 111.13s\n",
      "Epoch 54/200\n",
      "Training loss at step 0: 1.6298\n",
      "Training loss at step 100: 1.4283\n",
      "Training loss at step 200: 1.6944\n",
      "Training loss at step 300: 1.6320\n",
      "Training accuracy: 0.5585 Validation accuracy: 0.5070 Time taken: 111.09s\n",
      "Epoch 55/200\n",
      "Training loss at step 0: 1.6065\n",
      "Training loss at step 100: 1.5573\n",
      "Training loss at step 200: 1.6517\n",
      "Training loss at step 300: 1.6660\n",
      "Training accuracy: 0.5567 Validation accuracy: 0.4754 Time taken: 110.98s\n",
      "Epoch 56/200\n",
      "Training loss at step 0: 1.6625\n",
      "Training loss at step 100: 1.7486\n",
      "Training loss at step 200: 1.7014\n",
      "Training loss at step 300: 1.5414\n",
      "Training accuracy: 0.5673 Validation accuracy: 0.5108 Time taken: 111.96s\n",
      "Epoch 57/200\n",
      "Training loss at step 0: 1.8148\n",
      "Training loss at step 100: 1.7246\n",
      "Training loss at step 200: 1.2672\n",
      "Training loss at step 300: 1.4080\n",
      "Training accuracy: 0.5681 Validation accuracy: 0.5240 Time taken: 111.79s\n",
      "Epoch 58/200\n",
      "Training loss at step 0: 1.4080\n",
      "Training loss at step 100: 1.1803\n",
      "Training loss at step 200: 1.4934\n",
      "Training loss at step 300: 1.4872\n",
      "Training accuracy: 0.5647 Validation accuracy: 0.5310 Time taken: 111.54s\n",
      "Epoch 59/200\n",
      "Training loss at step 0: 1.4386\n",
      "Training loss at step 100: 1.4680\n",
      "Training loss at step 200: 1.2946\n",
      "Training loss at step 300: 1.2220\n",
      "Training accuracy: 0.5746 Validation accuracy: 0.5176 Time taken: 111.61s\n",
      "Epoch 60/200\n",
      "Training loss at step 0: 1.3130\n",
      "Training loss at step 100: 2.0087\n",
      "Training loss at step 200: 1.6878\n",
      "Training loss at step 300: 1.5870\n",
      "Training accuracy: 0.5781 Validation accuracy: 0.5324 Time taken: 110.84s\n",
      "Epoch 61/200\n",
      "Training loss at step 0: 1.5012\n",
      "Training loss at step 100: 1.5424\n",
      "Training loss at step 200: 1.4091\n",
      "Training loss at step 300: 1.3877\n",
      "Training accuracy: 0.5788 Validation accuracy: 0.4934 Time taken: 111.61s\n",
      "Epoch 62/200\n",
      "Training loss at step 0: 1.6422\n",
      "Training loss at step 100: 1.2919\n",
      "Training loss at step 200: 1.4661\n",
      "Training loss at step 300: 1.1966\n",
      "Training accuracy: 0.5844 Validation accuracy: 0.5082 Time taken: 111.32s\n",
      "Epoch 63/200\n",
      "Training loss at step 0: 1.2866\n",
      "Training loss at step 100: 1.4147\n",
      "Training loss at step 200: 1.4786\n",
      "Training loss at step 300: 1.5225\n",
      "Training accuracy: 0.5838 Validation accuracy: 0.5116 Time taken: 110.46s\n",
      "Epoch 64/200\n",
      "Training loss at step 0: 1.4820\n",
      "Training loss at step 100: 1.3375\n",
      "Training loss at step 200: 1.4593\n",
      "Training loss at step 300: 1.4273\n",
      "Training accuracy: 0.5906 Validation accuracy: 0.5364 Time taken: 111.12s\n",
      "Epoch 65/200\n",
      "Training loss at step 0: 1.4444\n",
      "Training loss at step 100: 1.4891\n",
      "Training loss at step 200: 1.3441\n",
      "Training loss at step 300: 1.1626\n",
      "Training accuracy: 0.5914 Validation accuracy: 0.5616 Time taken: 112.13s\n",
      "Epoch 66/200\n",
      "Training loss at step 0: 1.4582\n",
      "Training loss at step 100: 1.3715\n",
      "Training loss at step 200: 1.2094\n",
      "Training loss at step 300: 1.0865\n",
      "Training accuracy: 0.5984 Validation accuracy: 0.5062 Time taken: 112.13s\n",
      "Epoch 67/200\n",
      "Training loss at step 0: 1.7980\n",
      "Training loss at step 100: 1.4060\n",
      "Training loss at step 200: 1.6850\n",
      "Training loss at step 300: 1.5356\n",
      "Training accuracy: 0.5952 Validation accuracy: 0.5432 Time taken: 111.16s\n",
      "Epoch 68/200\n",
      "Training loss at step 0: 1.2360\n",
      "Training loss at step 100: 1.3007\n",
      "Training loss at step 200: 1.3938\n",
      "Training loss at step 300: 1.8934\n",
      "Training accuracy: 0.6006 Validation accuracy: 0.5578 Time taken: 110.89s\n",
      "Epoch 69/200\n",
      "Training loss at step 0: 1.1651\n",
      "Training loss at step 100: 1.2631\n",
      "Training loss at step 200: 1.3008\n",
      "Training loss at step 300: 1.3900\n",
      "Training accuracy: 0.5999 Validation accuracy: 0.5432 Time taken: 112.12s\n",
      "Epoch 70/200\n",
      "Training loss at step 0: 1.5308\n",
      "Training loss at step 100: 1.9118\n",
      "Training loss at step 200: 1.2713\n",
      "Training loss at step 300: 1.7147\n",
      "Training accuracy: 0.6073 Validation accuracy: 0.5452 Time taken: 111.57s\n",
      "Epoch 71/200\n",
      "Training loss at step 0: 1.2199\n",
      "Training loss at step 100: 1.8959\n",
      "Training loss at step 200: 1.3955\n",
      "Training loss at step 300: 1.3274\n",
      "Training accuracy: 0.6110 Validation accuracy: 0.5630 Time taken: 111.58s\n",
      "Epoch 72/200\n",
      "Training loss at step 0: 1.2629\n",
      "Training loss at step 100: 1.6756\n",
      "Training loss at step 200: 1.3799\n",
      "Training loss at step 300: 1.4703\n",
      "Training accuracy: 0.6138 Validation accuracy: 0.5582 Time taken: 111.64s\n",
      "Epoch 73/200\n",
      "Training loss at step 0: 1.8261\n",
      "Training loss at step 100: 1.1948\n",
      "Training loss at step 200: 1.4863\n",
      "Training loss at step 300: 1.0766\n",
      "Training accuracy: 0.6146 Validation accuracy: 0.4950 Time taken: 111.19s\n",
      "Epoch 74/200\n",
      "Training loss at step 0: 1.7092\n",
      "Training loss at step 100: 1.3569\n",
      "Training loss at step 200: 1.2898\n",
      "Training loss at step 300: 1.1638\n",
      "Training accuracy: 0.6168 Validation accuracy: 0.5478 Time taken: 111.84s\n",
      "Epoch 75/200\n",
      "Training loss at step 0: 1.2386\n",
      "Training loss at step 100: 1.3840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 200: 1.5251\n",
      "Training loss at step 300: 1.0884\n",
      "Training accuracy: 0.6218 Validation accuracy: 0.5556 Time taken: 111.97s\n",
      "Epoch 76/200\n",
      "Training loss at step 0: 1.3331\n",
      "Training loss at step 100: 1.1871\n",
      "Training loss at step 200: 1.2889\n",
      "Training loss at step 300: 1.5213\n",
      "Training accuracy: 0.6203 Validation accuracy: 0.5726 Time taken: 110.90s\n",
      "Epoch 77/200\n",
      "Training loss at step 0: 1.5301\n",
      "Training loss at step 100: 1.2655\n",
      "Training loss at step 200: 1.2765\n",
      "Training loss at step 300: 1.3635\n",
      "Training accuracy: 0.6276 Validation accuracy: 0.5588 Time taken: 110.68s\n",
      "Epoch 78/200\n",
      "Training loss at step 0: 1.1997\n",
      "Training loss at step 100: 1.3368\n",
      "Training loss at step 200: 1.9926\n",
      "Training loss at step 300: 1.1692\n",
      "Training accuracy: 0.6222 Validation accuracy: 0.5648 Time taken: 111.82s\n",
      "Epoch 79/200\n",
      "Training loss at step 0: 1.5181\n",
      "Training loss at step 100: 1.1160\n",
      "Training loss at step 200: 1.3933\n",
      "Training loss at step 300: 1.2973\n",
      "Training accuracy: 0.6293 Validation accuracy: 0.5726 Time taken: 110.86s\n",
      "Epoch 80/200\n",
      "Training loss at step 0: 1.2072\n",
      "Training loss at step 100: 0.9865\n",
      "Training loss at step 200: 1.1474\n",
      "Training loss at step 300: 1.4022\n",
      "Training accuracy: 0.6307 Validation accuracy: 0.5406 Time taken: 111.89s\n",
      "Epoch 81/200\n",
      "Training loss at step 0: 1.3398\n",
      "Training loss at step 100: 1.7208\n",
      "Training loss at step 200: 1.6689\n",
      "Training loss at step 300: 1.1572\n",
      "Training accuracy: 0.6317 Validation accuracy: 0.5200 Time taken: 110.69s\n",
      "Epoch 82/200\n",
      "Training loss at step 0: 1.1579\n",
      "Training loss at step 100: 1.1548\n",
      "Training loss at step 200: 1.2517\n",
      "Training loss at step 300: 1.4997\n",
      "Training accuracy: 0.6339 Validation accuracy: 0.5434 Time taken: 111.00s\n",
      "Epoch 83/200\n",
      "Training loss at step 0: 1.3022\n",
      "Training loss at step 100: 1.2385\n",
      "Training loss at step 200: 1.5355\n",
      "Training loss at step 300: 0.9120\n",
      "Training accuracy: 0.6401 Validation accuracy: 0.5494 Time taken: 111.10s\n",
      "Epoch 84/200\n",
      "Training loss at step 0: 1.2823\n",
      "Training loss at step 100: 1.3595\n",
      "Training loss at step 200: 1.3885\n",
      "Training loss at step 300: 1.1912\n",
      "Training accuracy: 0.6415 Validation accuracy: 0.5736 Time taken: 112.09s\n",
      "Epoch 85/200\n",
      "Training loss at step 0: 1.3859\n",
      "Training loss at step 100: 1.1048\n",
      "Training loss at step 200: 1.2817\n",
      "Training loss at step 300: 1.3723\n",
      "Training accuracy: 0.6437 Validation accuracy: 0.5932 Time taken: 110.67s\n",
      "Epoch 86/200\n",
      "Training loss at step 0: 1.0489\n",
      "Training loss at step 100: 1.2720\n",
      "Training loss at step 200: 1.0335\n",
      "Training loss at step 300: 1.2307\n",
      "Training accuracy: 0.6420 Validation accuracy: 0.5794 Time taken: 110.23s\n",
      "Epoch 87/200\n",
      "Training loss at step 0: 1.1525\n",
      "Training loss at step 100: 1.5072\n",
      "Training loss at step 200: 1.1888\n",
      "Training loss at step 300: 1.1873\n",
      "Training accuracy: 0.6432 Validation accuracy: 0.5766 Time taken: 109.97s\n",
      "Epoch 88/200\n",
      "Training loss at step 0: 1.2543\n",
      "Training loss at step 100: 1.2479\n",
      "Training loss at step 200: 1.1454\n",
      "Training loss at step 300: 1.2017\n",
      "Training accuracy: 0.6511 Validation accuracy: 0.5886 Time taken: 110.93s\n",
      "Epoch 89/200\n",
      "Training loss at step 0: 1.2568\n",
      "Training loss at step 100: 1.0944\n",
      "Training loss at step 200: 0.9416\n",
      "Training loss at step 300: 1.0720\n",
      "Training accuracy: 0.6504 Validation accuracy: 0.5740 Time taken: 111.13s\n",
      "Epoch 90/200\n",
      "Training loss at step 0: 1.2447\n",
      "Training loss at step 100: 1.1537\n",
      "Training loss at step 200: 1.2207\n",
      "Training loss at step 300: 1.1644\n",
      "Training accuracy: 0.6518 Validation accuracy: 0.5644 Time taken: 111.54s\n",
      "Epoch 91/200\n",
      "Training loss at step 0: 1.2465\n",
      "Training loss at step 100: 0.9898\n",
      "Training loss at step 200: 1.1582\n",
      "Training loss at step 300: 0.9642\n",
      "Training accuracy: 0.6534 Validation accuracy: 0.5298 Time taken: 111.00s\n",
      "Epoch 92/200\n",
      "Training loss at step 0: 1.0971\n",
      "Training loss at step 100: 1.2421\n",
      "Training loss at step 200: 1.0846\n",
      "Training loss at step 300: 1.1844\n",
      "Training accuracy: 0.6588 Validation accuracy: 0.5834 Time taken: 110.98s\n",
      "Epoch 93/200\n",
      "Training loss at step 0: 1.1586\n",
      "Training loss at step 100: 1.0445\n",
      "Training loss at step 200: 1.0763\n",
      "Training loss at step 300: 1.3383\n",
      "Training accuracy: 0.6624 Validation accuracy: 0.5818 Time taken: 111.29s\n",
      "Epoch 94/200\n",
      "Training loss at step 0: 1.1120\n",
      "Training loss at step 100: 1.2886\n",
      "Training loss at step 200: 1.5776\n",
      "Training loss at step 300: 1.5329\n",
      "Training accuracy: 0.6561 Validation accuracy: 0.6010 Time taken: 111.32s\n",
      "Epoch 95/200\n",
      "Training loss at step 0: 1.1580\n",
      "Training loss at step 100: 0.9035\n",
      "Training loss at step 200: 0.8917\n",
      "Training loss at step 300: 1.3322\n",
      "Training accuracy: 0.6572 Validation accuracy: 0.5834 Time taken: 110.79s\n",
      "Epoch 96/200\n",
      "Training loss at step 0: 1.0006\n",
      "Training loss at step 100: 0.9579\n",
      "Training loss at step 200: 0.9292\n",
      "Training loss at step 300: 1.1632\n",
      "Training accuracy: 0.6639 Validation accuracy: 0.6118 Time taken: 111.26s\n",
      "Epoch 97/200\n",
      "Training loss at step 0: 1.1429\n",
      "Training loss at step 100: 1.0437\n",
      "Training loss at step 200: 1.5534\n",
      "Training loss at step 300: 1.3067\n",
      "Training accuracy: 0.6686 Validation accuracy: 0.5996 Time taken: 111.91s\n",
      "Epoch 98/200\n",
      "Training loss at step 0: 1.3752\n",
      "Training loss at step 100: 1.1552\n",
      "Training loss at step 200: 1.5192\n",
      "Training loss at step 300: 1.1457\n",
      "Training accuracy: 0.6642 Validation accuracy: 0.5866 Time taken: 110.40s\n",
      "Epoch 99/200\n",
      "Training loss at step 0: 1.1057\n",
      "Training loss at step 100: 0.9562\n",
      "Training loss at step 200: 1.2579\n",
      "Training loss at step 300: 1.0419\n",
      "Training accuracy: 0.6687 Validation accuracy: 0.5878 Time taken: 110.72s\n",
      "Epoch 100/200\n",
      "Training loss at step 0: 1.0094\n",
      "Training loss at step 100: 1.0559\n",
      "Training loss at step 200: 1.1339\n",
      "Training loss at step 300: 1.3108\n",
      "Training accuracy: 0.6749 Validation accuracy: 0.5870 Time taken: 111.04s\n",
      "Epoch 101/200\n",
      "Training loss at step 0: 1.6046\n",
      "Training loss at step 100: 0.8649\n",
      "Training loss at step 200: 0.6935\n",
      "Training loss at step 300: 1.4005\n",
      "Training accuracy: 0.7028 Validation accuracy: 0.6514 Time taken: 110.63s\n",
      "Epoch 102/200\n",
      "Training loss at step 0: 0.8639\n",
      "Training loss at step 100: 1.0905\n",
      "Training loss at step 200: 0.6903\n",
      "Training loss at step 300: 1.1492\n",
      "Training accuracy: 0.7089 Validation accuracy: 0.6442 Time taken: 111.53s\n",
      "Epoch 103/200\n",
      "Training loss at step 0: 1.0222\n",
      "Training loss at step 100: 1.0454\n",
      "Training loss at step 200: 0.9252\n",
      "Training loss at step 300: 0.6896\n",
      "Training accuracy: 0.7090 Validation accuracy: 0.6514 Time taken: 111.23s\n",
      "Epoch 104/200\n",
      "Training loss at step 0: 1.1918\n",
      "Training loss at step 100: 0.8849\n",
      "Training loss at step 200: 0.9711\n",
      "Training loss at step 300: 1.0472\n",
      "Training accuracy: 0.7111 Validation accuracy: 0.6500 Time taken: 112.32s\n",
      "Epoch 105/200\n",
      "Training loss at step 0: 0.7968\n",
      "Training loss at step 100: 0.9561\n",
      "Training loss at step 200: 0.9212\n",
      "Training loss at step 300: 1.0866\n",
      "Training accuracy: 0.7114 Validation accuracy: 0.6538 Time taken: 111.14s\n",
      "Epoch 106/200\n",
      "Training loss at step 0: 1.0326\n",
      "Training loss at step 100: 0.8819\n",
      "Training loss at step 200: 0.9829\n",
      "Training loss at step 300: 0.8116\n",
      "Training accuracy: 0.7155 Validation accuracy: 0.6562 Time taken: 111.26s\n",
      "Epoch 107/200\n",
      "Training loss at step 0: 0.8829\n",
      "Training loss at step 100: 0.9682\n",
      "Training loss at step 200: 1.5589\n",
      "Training loss at step 300: 1.0139\n",
      "Training accuracy: 0.7122 Validation accuracy: 0.6562 Time taken: 110.85s\n",
      "Epoch 108/200\n",
      "Training loss at step 0: 0.8921\n",
      "Training loss at step 100: 0.9500\n",
      "Training loss at step 200: 0.9323\n",
      "Training loss at step 300: 1.0438\n",
      "Training accuracy: 0.7202 Validation accuracy: 0.6494 Time taken: 111.48s\n",
      "Epoch 109/200\n",
      "Training loss at step 0: 0.8066\n",
      "Training loss at step 100: 1.0484\n",
      "Training loss at step 200: 0.9832\n",
      "Training loss at step 300: 1.1767\n",
      "Training accuracy: 0.7163 Validation accuracy: 0.6536 Time taken: 111.19s\n",
      "Epoch 110/200\n",
      "Training loss at step 0: 0.7495\n",
      "Training loss at step 100: 0.7211\n",
      "Training loss at step 200: 0.8177\n",
      "Training loss at step 300: 1.0557\n",
      "Training accuracy: 0.7195 Validation accuracy: 0.6530 Time taken: 109.84s\n",
      "Epoch 111/200\n",
      "Training loss at step 0: 0.9303\n",
      "Training loss at step 100: 1.3212\n",
      "Training loss at step 200: 0.7482\n",
      "Training loss at step 300: 1.1491\n",
      "Training accuracy: 0.7197 Validation accuracy: 0.6516 Time taken: 112.15s\n",
      "Epoch 112/200\n",
      "Training loss at step 0: 0.7932\n",
      "Training loss at step 100: 1.0180\n",
      "Training loss at step 200: 0.8384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.7876\n",
      "Training accuracy: 0.7232 Validation accuracy: 0.6498 Time taken: 112.47s\n",
      "Epoch 113/200\n",
      "Training loss at step 0: 1.0521\n",
      "Training loss at step 100: 0.8870\n",
      "Training loss at step 200: 1.0528\n",
      "Training loss at step 300: 0.9038\n",
      "Training accuracy: 0.7204 Validation accuracy: 0.6574 Time taken: 111.43s\n",
      "Epoch 114/200\n",
      "Training loss at step 0: 0.9032\n",
      "Training loss at step 100: 0.9907\n",
      "Training loss at step 200: 0.8290\n",
      "Training loss at step 300: 0.8474\n",
      "Training accuracy: 0.7167 Validation accuracy: 0.6532 Time taken: 111.46s\n",
      "Epoch 115/200\n",
      "Training loss at step 0: 0.8484\n",
      "Training loss at step 100: 0.7205\n",
      "Training loss at step 200: 0.9360\n",
      "Training loss at step 300: 0.8246\n",
      "Training accuracy: 0.7176 Validation accuracy: 0.6522 Time taken: 111.86s\n",
      "Epoch 116/200\n",
      "Training loss at step 0: 0.9130\n",
      "Training loss at step 100: 0.9804\n",
      "Training loss at step 200: 0.9019\n",
      "Training loss at step 300: 0.8440\n",
      "Training accuracy: 0.7240 Validation accuracy: 0.6516 Time taken: 111.32s\n",
      "Epoch 117/200\n",
      "Training loss at step 0: 0.9405\n",
      "Training loss at step 100: 1.0589\n",
      "Training loss at step 200: 0.7194\n",
      "Training loss at step 300: 0.9957\n",
      "Training accuracy: 0.7203 Validation accuracy: 0.6548 Time taken: 110.34s\n",
      "Epoch 118/200\n",
      "Training loss at step 0: 0.8233\n",
      "Training loss at step 100: 0.9923\n",
      "Training loss at step 200: 1.1711\n",
      "Training loss at step 300: 1.0474\n",
      "Training accuracy: 0.7244 Validation accuracy: 0.6532 Time taken: 110.94s\n",
      "Epoch 119/200\n",
      "Training loss at step 0: 1.0789\n",
      "Training loss at step 100: 0.8261\n",
      "Training loss at step 200: 1.0455\n",
      "Training loss at step 300: 0.8268\n",
      "Training accuracy: 0.7206 Validation accuracy: 0.6526 Time taken: 111.06s\n",
      "Epoch 120/200\n",
      "Training loss at step 0: 0.9528\n",
      "Training loss at step 100: 0.8608\n",
      "Training loss at step 200: 0.8532\n",
      "Training loss at step 300: 0.8619\n",
      "Training accuracy: 0.7266 Validation accuracy: 0.6550 Time taken: 111.83s\n",
      "Epoch 121/200\n",
      "Training loss at step 0: 0.7316\n",
      "Training loss at step 100: 0.7591\n",
      "Training loss at step 200: 0.9828\n",
      "Training loss at step 300: 0.9034\n",
      "Training accuracy: 0.7239 Validation accuracy: 0.6582 Time taken: 112.00s\n",
      "Epoch 122/200\n",
      "Training loss at step 0: 1.0817\n",
      "Training loss at step 100: 1.1476\n",
      "Training loss at step 200: 0.8880\n",
      "Training loss at step 300: 0.9868\n",
      "Training accuracy: 0.7260 Validation accuracy: 0.6546 Time taken: 111.95s\n",
      "Epoch 123/200\n",
      "Training loss at step 0: 0.8829\n",
      "Training loss at step 100: 1.0126\n",
      "Training loss at step 200: 0.8709\n",
      "Training loss at step 300: 1.0950\n",
      "Training accuracy: 0.7282 Validation accuracy: 0.6540 Time taken: 110.84s\n",
      "Epoch 124/200\n",
      "Training loss at step 0: 0.7280\n",
      "Training loss at step 100: 0.7408\n",
      "Training loss at step 200: 0.7752\n",
      "Training loss at step 300: 0.9224\n",
      "Training accuracy: 0.7253 Validation accuracy: 0.6576 Time taken: 110.76s\n",
      "Epoch 125/200\n",
      "Training loss at step 0: 1.2434\n",
      "Training loss at step 100: 1.0571\n",
      "Training loss at step 200: 0.6365\n",
      "Training loss at step 300: 0.8663\n",
      "Training accuracy: 0.7234 Validation accuracy: 0.6524 Time taken: 110.53s\n",
      "Epoch 126/200\n",
      "Training loss at step 0: 1.0957\n",
      "Training loss at step 100: 1.0106\n",
      "Training loss at step 200: 0.8174\n",
      "Training loss at step 300: 1.0785\n",
      "Training accuracy: 0.7291 Validation accuracy: 0.6522 Time taken: 112.29s\n",
      "Epoch 127/200\n",
      "Training loss at step 0: 1.2095\n",
      "Training loss at step 100: 0.8628\n",
      "Training loss at step 200: 0.9380\n",
      "Training loss at step 300: 0.8003\n",
      "Training accuracy: 0.7262 Validation accuracy: 0.6588 Time taken: 110.86s\n",
      "Epoch 128/200\n",
      "Training loss at step 0: 0.9623\n",
      "Training loss at step 100: 0.9808\n",
      "Training loss at step 200: 0.8496\n",
      "Training loss at step 300: 0.8882\n",
      "Training accuracy: 0.7292 Validation accuracy: 0.6538 Time taken: 111.53s\n",
      "Epoch 129/200\n",
      "Training loss at step 0: 0.8890\n",
      "Training loss at step 100: 0.8556\n",
      "Training loss at step 200: 0.7841\n",
      "Training loss at step 300: 1.0608\n",
      "Training accuracy: 0.7301 Validation accuracy: 0.6560 Time taken: 112.53s\n",
      "Epoch 130/200\n",
      "Training loss at step 0: 0.9910\n",
      "Training loss at step 100: 0.8134\n",
      "Training loss at step 200: 0.9965\n",
      "Training loss at step 300: 0.8558\n",
      "Training accuracy: 0.7277 Validation accuracy: 0.6586 Time taken: 111.82s\n",
      "Epoch 131/200\n",
      "Training loss at step 0: 1.4292\n",
      "Training loss at step 100: 0.7892\n",
      "Training loss at step 200: 0.8691\n",
      "Training loss at step 300: 0.7482\n",
      "Training accuracy: 0.7274 Validation accuracy: 0.6580 Time taken: 111.65s\n",
      "Epoch 132/200\n",
      "Training loss at step 0: 1.1194\n",
      "Training loss at step 100: 0.6365\n",
      "Training loss at step 200: 1.1273\n",
      "Training loss at step 300: 0.8929\n",
      "Training accuracy: 0.7280 Validation accuracy: 0.6560 Time taken: 111.72s\n",
      "Epoch 133/200\n",
      "Training loss at step 0: 0.9665\n",
      "Training loss at step 100: 0.9688\n",
      "Training loss at step 200: 1.0089\n",
      "Training loss at step 300: 1.0382\n",
      "Training accuracy: 0.7291 Validation accuracy: 0.6614 Time taken: 110.75s\n",
      "Epoch 134/200\n",
      "Training loss at step 0: 0.7585\n",
      "Training loss at step 100: 0.8234\n",
      "Training loss at step 200: 0.8721\n",
      "Training loss at step 300: 0.8592\n",
      "Training accuracy: 0.7291 Validation accuracy: 0.6566 Time taken: 111.42s\n",
      "Epoch 135/200\n",
      "Training loss at step 0: 0.6139\n",
      "Training loss at step 100: 0.8859\n",
      "Training loss at step 200: 0.7213\n",
      "Training loss at step 300: 0.8852\n",
      "Training accuracy: 0.7298 Validation accuracy: 0.6538 Time taken: 110.00s\n",
      "Epoch 136/200\n",
      "Training loss at step 0: 0.9742\n",
      "Training loss at step 100: 0.4843\n",
      "Training loss at step 200: 0.8348\n",
      "Training loss at step 300: 0.8165\n",
      "Training accuracy: 0.7335 Validation accuracy: 0.6612 Time taken: 111.60s\n",
      "Epoch 137/200\n",
      "Training loss at step 0: 0.8886\n",
      "Training loss at step 100: 0.6957\n",
      "Training loss at step 200: 1.3382\n",
      "Training loss at step 300: 0.7830\n",
      "Training accuracy: 0.7285 Validation accuracy: 0.6546 Time taken: 111.04s\n",
      "Epoch 138/200\n",
      "Training loss at step 0: 0.8163\n",
      "Training loss at step 100: 0.7683\n",
      "Training loss at step 200: 1.2614\n",
      "Training loss at step 300: 1.0807\n",
      "Training accuracy: 0.7308 Validation accuracy: 0.6594 Time taken: 111.11s\n",
      "Epoch 139/200\n",
      "Training loss at step 0: 1.0338\n",
      "Training loss at step 100: 0.8794\n",
      "Training loss at step 200: 0.8999\n",
      "Training loss at step 300: 0.9052\n",
      "Training accuracy: 0.7283 Validation accuracy: 0.6608 Time taken: 110.67s\n",
      "Epoch 140/200\n",
      "Training loss at step 0: 0.8026\n",
      "Training loss at step 100: 0.8632\n",
      "Training loss at step 200: 0.9380\n",
      "Training loss at step 300: 0.6669\n",
      "Training accuracy: 0.7325 Validation accuracy: 0.6592 Time taken: 110.02s\n",
      "Epoch 141/200\n",
      "Training loss at step 0: 1.0519\n",
      "Training loss at step 100: 0.9610\n",
      "Training loss at step 200: 0.5478\n",
      "Training loss at step 300: 0.7343\n",
      "Training accuracy: 0.7320 Validation accuracy: 0.6612 Time taken: 110.12s\n",
      "Epoch 142/200\n",
      "Training loss at step 0: 0.6519\n",
      "Training loss at step 100: 0.7272\n",
      "Training loss at step 200: 0.7505\n",
      "Training loss at step 300: 0.7986\n",
      "Training accuracy: 0.7340 Validation accuracy: 0.6556 Time taken: 110.47s\n",
      "Epoch 143/200\n",
      "Training loss at step 0: 0.9299\n",
      "Training loss at step 100: 0.9351\n",
      "Training loss at step 200: 0.8688\n",
      "Training loss at step 300: 0.8717\n",
      "Training accuracy: 0.7326 Validation accuracy: 0.6540 Time taken: 110.55s\n",
      "Epoch 144/200\n",
      "Training loss at step 0: 1.1103\n",
      "Training loss at step 100: 0.7032\n",
      "Training loss at step 200: 0.7554\n",
      "Training loss at step 300: 0.8901\n",
      "Training accuracy: 0.7302 Validation accuracy: 0.6576 Time taken: 111.47s\n",
      "Epoch 145/200\n",
      "Training loss at step 0: 1.0254\n",
      "Training loss at step 100: 1.1578\n",
      "Training loss at step 200: 1.0435\n",
      "Training loss at step 300: 0.8731\n",
      "Training accuracy: 0.7366 Validation accuracy: 0.6640 Time taken: 110.09s\n",
      "Epoch 146/200\n",
      "Training loss at step 0: 0.8514\n",
      "Training loss at step 100: 0.8921\n",
      "Training loss at step 200: 1.0705\n",
      "Training loss at step 300: 0.9765\n",
      "Training accuracy: 0.7341 Validation accuracy: 0.6608 Time taken: 111.55s\n",
      "Epoch 147/200\n",
      "Training loss at step 0: 0.9449\n",
      "Training loss at step 100: 1.0061\n",
      "Training loss at step 200: 0.8024\n",
      "Training loss at step 300: 1.0458\n",
      "Training accuracy: 0.7316 Validation accuracy: 0.6586 Time taken: 111.61s\n",
      "Epoch 148/200\n",
      "Training loss at step 0: 1.2233\n",
      "Training loss at step 100: 0.7250\n",
      "Training loss at step 200: 0.8878\n",
      "Training loss at step 300: 0.6004\n",
      "Training accuracy: 0.7356 Validation accuracy: 0.6578 Time taken: 110.06s\n",
      "Epoch 149/200\n",
      "Training loss at step 0: 0.9901\n",
      "Training loss at step 100: 0.7791\n",
      "Training loss at step 200: 1.1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.6827\n",
      "Training accuracy: 0.7342 Validation accuracy: 0.6596 Time taken: 110.68s\n",
      "Epoch 150/200\n",
      "Training loss at step 0: 0.7623\n",
      "Training loss at step 100: 0.7436\n",
      "Training loss at step 200: 0.7088\n",
      "Training loss at step 300: 0.9231\n",
      "Training accuracy: 0.7332 Validation accuracy: 0.6590 Time taken: 110.21s\n",
      "Epoch 151/200\n",
      "Training loss at step 0: 0.8623\n",
      "Training loss at step 100: 0.8589\n",
      "Training loss at step 200: 0.8298\n",
      "Training loss at step 300: 1.1421\n",
      "Training accuracy: 0.7364 Validation accuracy: 0.6650 Time taken: 110.73s\n",
      "Epoch 152/200\n",
      "Training loss at step 0: 0.8937\n",
      "Training loss at step 100: 0.9266\n",
      "Training loss at step 200: 0.8465\n",
      "Training loss at step 300: 0.6970\n",
      "Training accuracy: 0.7405 Validation accuracy: 0.6648 Time taken: 111.11s\n",
      "Epoch 153/200\n",
      "Training loss at step 0: 0.9152\n",
      "Training loss at step 100: 0.9831\n",
      "Training loss at step 200: 1.0733\n",
      "Training loss at step 300: 0.8161\n",
      "Training accuracy: 0.7378 Validation accuracy: 0.6632 Time taken: 111.44s\n",
      "Epoch 154/200\n",
      "Training loss at step 0: 0.7035\n",
      "Training loss at step 100: 1.0216\n",
      "Training loss at step 200: 0.7708\n",
      "Training loss at step 300: 1.1188\n",
      "Training accuracy: 0.7371 Validation accuracy: 0.6626 Time taken: 110.17s\n",
      "Epoch 155/200\n",
      "Training loss at step 0: 1.0807\n",
      "Training loss at step 100: 0.8713\n",
      "Training loss at step 200: 0.6857\n",
      "Training loss at step 300: 0.6662\n",
      "Training accuracy: 0.7385 Validation accuracy: 0.6624 Time taken: 111.32s\n",
      "Epoch 156/200\n",
      "Training loss at step 0: 0.8153\n",
      "Training loss at step 100: 0.8500\n",
      "Training loss at step 200: 0.6341\n",
      "Training loss at step 300: 0.8859\n",
      "Training accuracy: 0.7369 Validation accuracy: 0.6638 Time taken: 109.77s\n",
      "Epoch 157/200\n",
      "Training loss at step 0: 0.9897\n",
      "Training loss at step 100: 1.1348\n",
      "Training loss at step 200: 0.8718\n",
      "Training loss at step 300: 0.7632\n",
      "Training accuracy: 0.7386 Validation accuracy: 0.6626 Time taken: 109.97s\n",
      "Epoch 158/200\n",
      "Training loss at step 0: 0.8720\n",
      "Training loss at step 100: 0.7069\n",
      "Training loss at step 200: 0.7866\n",
      "Training loss at step 300: 0.7353\n",
      "Training accuracy: 0.7356 Validation accuracy: 0.6636 Time taken: 110.16s\n",
      "Epoch 159/200\n",
      "Training loss at step 0: 0.8539\n",
      "Training loss at step 100: 0.8151\n",
      "Training loss at step 200: 0.9264\n",
      "Training loss at step 300: 0.8219\n",
      "Training accuracy: 0.7361 Validation accuracy: 0.6612 Time taken: 111.26s\n",
      "Epoch 160/200\n",
      "Training loss at step 0: 0.7869\n",
      "Training loss at step 100: 0.6463\n",
      "Training loss at step 200: 0.7202\n",
      "Training loss at step 300: 0.8149\n",
      "Training accuracy: 0.7344 Validation accuracy: 0.6624 Time taken: 109.80s\n",
      "Epoch 161/200\n",
      "Training loss at step 0: 0.5966\n",
      "Training loss at step 100: 0.8090\n",
      "Training loss at step 200: 0.9323\n",
      "Training loss at step 300: 0.8634\n",
      "Training accuracy: 0.7375 Validation accuracy: 0.6658 Time taken: 111.04s\n",
      "Epoch 162/200\n",
      "Training loss at step 0: 0.9554\n",
      "Training loss at step 100: 0.8402\n",
      "Training loss at step 200: 0.9034\n",
      "Training loss at step 300: 1.1935\n",
      "Training accuracy: 0.7354 Validation accuracy: 0.6618 Time taken: 109.82s\n",
      "Epoch 163/200\n",
      "Training loss at step 0: 1.1260\n",
      "Training loss at step 100: 0.9402\n",
      "Training loss at step 200: 0.8708\n",
      "Training loss at step 300: 0.9584\n",
      "Training accuracy: 0.7385 Validation accuracy: 0.6594 Time taken: 111.34s\n",
      "Epoch 164/200\n",
      "Training loss at step 0: 0.7540\n",
      "Training loss at step 100: 0.8220\n",
      "Training loss at step 200: 0.5265\n",
      "Training loss at step 300: 1.2752\n",
      "Training accuracy: 0.7392 Validation accuracy: 0.6610 Time taken: 111.04s\n",
      "Epoch 165/200\n",
      "Training loss at step 0: 1.0071\n",
      "Training loss at step 100: 0.6682\n",
      "Training loss at step 200: 0.9440\n",
      "Training loss at step 300: 0.7494\n",
      "Training accuracy: 0.7392 Validation accuracy: 0.6620 Time taken: 111.11s\n",
      "Epoch 166/200\n",
      "Training loss at step 0: 1.3309\n",
      "Training loss at step 100: 0.7891\n",
      "Training loss at step 200: 1.0895\n",
      "Training loss at step 300: 0.6866\n",
      "Training accuracy: 0.7382 Validation accuracy: 0.6638 Time taken: 111.71s\n",
      "Epoch 167/200\n",
      "Training loss at step 0: 1.0207\n",
      "Training loss at step 100: 0.6980\n",
      "Training loss at step 200: 1.3865\n",
      "Training loss at step 300: 0.5890\n",
      "Training accuracy: 0.7402 Validation accuracy: 0.6644 Time taken: 110.94s\n",
      "Epoch 168/200\n",
      "Training loss at step 0: 0.7645\n",
      "Training loss at step 100: 0.8165\n",
      "Training loss at step 200: 0.6945\n",
      "Training loss at step 300: 0.8650\n",
      "Training accuracy: 0.7380 Validation accuracy: 0.6624 Time taken: 110.52s\n",
      "Epoch 169/200\n",
      "Training loss at step 0: 1.0624\n",
      "Training loss at step 100: 0.7426\n",
      "Training loss at step 200: 0.9651\n",
      "Training loss at step 300: 0.8846\n",
      "Training accuracy: 0.7372 Validation accuracy: 0.6610 Time taken: 110.00s\n",
      "Epoch 170/200\n",
      "Training loss at step 0: 0.8285\n",
      "Training loss at step 100: 0.9776\n",
      "Training loss at step 200: 1.0487\n",
      "Training loss at step 300: 1.0208\n",
      "Training accuracy: 0.7404 Validation accuracy: 0.6580 Time taken: 110.72s\n",
      "Epoch 171/200\n",
      "Training loss at step 0: 0.6115\n",
      "Training loss at step 100: 0.8371\n",
      "Training loss at step 200: 0.9254\n",
      "Training loss at step 300: 0.8964\n",
      "Training accuracy: 0.7396 Validation accuracy: 0.6630 Time taken: 110.57s\n",
      "Epoch 172/200\n",
      "Training loss at step 0: 1.2757\n",
      "Training loss at step 100: 0.8622\n",
      "Training loss at step 200: 0.7029\n",
      "Training loss at step 300: 1.0426\n",
      "Training accuracy: 0.7384 Validation accuracy: 0.6628 Time taken: 111.01s\n",
      "Epoch 173/200\n",
      "Training loss at step 0: 1.1254\n",
      "Training loss at step 100: 0.7714\n",
      "Training loss at step 200: 0.6959\n",
      "Training loss at step 300: 1.0334\n",
      "Training accuracy: 0.7418 Validation accuracy: 0.6632 Time taken: 110.50s\n",
      "Epoch 174/200\n",
      "Training loss at step 0: 1.2375\n",
      "Training loss at step 100: 1.0871\n",
      "Training loss at step 200: 1.0745\n",
      "Training loss at step 300: 0.9993\n",
      "Training accuracy: 0.7414 Validation accuracy: 0.6606 Time taken: 110.62s\n",
      "Epoch 175/200\n",
      "Training loss at step 0: 0.7857\n",
      "Training loss at step 100: 0.6867\n",
      "Training loss at step 200: 0.8435\n",
      "Training loss at step 300: 1.1338\n",
      "Training accuracy: 0.7360 Validation accuracy: 0.6618 Time taken: 111.23s\n",
      "Epoch 176/200\n",
      "Training loss at step 0: 0.8078\n",
      "Training loss at step 100: 0.5934\n",
      "Training loss at step 200: 0.9238\n",
      "Training loss at step 300: 0.6600\n",
      "Training accuracy: 0.7393 Validation accuracy: 0.6630 Time taken: 111.33s\n",
      "Epoch 177/200\n",
      "Training loss at step 0: 0.9077\n",
      "Training loss at step 100: 0.7468\n",
      "Training loss at step 200: 0.9516\n",
      "Training loss at step 300: 1.4024\n",
      "Training accuracy: 0.7386 Validation accuracy: 0.6646 Time taken: 109.40s\n",
      "Epoch 178/200\n",
      "Training loss at step 0: 0.6496\n",
      "Training loss at step 100: 0.9288\n",
      "Training loss at step 200: 0.8938\n",
      "Training loss at step 300: 0.8659\n",
      "Training accuracy: 0.7404 Validation accuracy: 0.6634 Time taken: 111.21s\n",
      "Epoch 179/200\n",
      "Training loss at step 0: 0.6134\n",
      "Training loss at step 100: 0.6288\n",
      "Training loss at step 200: 0.9936\n",
      "Training loss at step 300: 0.9711\n",
      "Training accuracy: 0.7383 Validation accuracy: 0.6628 Time taken: 110.13s\n",
      "Epoch 180/200\n",
      "Training loss at step 0: 0.7884\n",
      "Training loss at step 100: 0.7083\n",
      "Training loss at step 200: 1.0248\n",
      "Training loss at step 300: 0.7081\n",
      "Training accuracy: 0.7417 Validation accuracy: 0.6614 Time taken: 110.58s\n",
      "Epoch 181/200\n",
      "Training loss at step 0: 1.0231\n",
      "Training loss at step 100: 0.7203\n",
      "Training loss at step 200: 0.8484\n",
      "Training loss at step 300: 0.5272\n",
      "Training accuracy: 0.7403 Validation accuracy: 0.6614 Time taken: 110.99s\n",
      "Epoch 182/200\n",
      "Training loss at step 0: 0.7588\n",
      "Training loss at step 100: 0.6961\n",
      "Training loss at step 200: 0.9643\n",
      "Training loss at step 300: 0.9188\n",
      "Training accuracy: 0.7394 Validation accuracy: 0.6636 Time taken: 111.36s\n",
      "Epoch 183/200\n",
      "Training loss at step 0: 1.0138\n",
      "Training loss at step 100: 1.0744\n",
      "Training loss at step 200: 0.9119\n",
      "Training loss at step 300: 0.7687\n",
      "Training accuracy: 0.7376 Validation accuracy: 0.6608 Time taken: 110.09s\n",
      "Epoch 184/200\n",
      "Training loss at step 0: 1.0222\n",
      "Training loss at step 100: 0.7445\n",
      "Training loss at step 200: 0.8105\n",
      "Training loss at step 300: 0.8578\n",
      "Training accuracy: 0.7352 Validation accuracy: 0.6646 Time taken: 110.18s\n",
      "Epoch 185/200\n",
      "Training loss at step 0: 0.5432\n",
      "Training loss at step 100: 0.8300\n",
      "Training loss at step 200: 1.0914\n",
      "Training loss at step 300: 0.9445\n",
      "Training accuracy: 0.7405 Validation accuracy: 0.6624 Time taken: 111.29s\n",
      "Epoch 186/200\n",
      "Training loss at step 0: 1.0978\n",
      "Training loss at step 100: 0.6073\n",
      "Training loss at step 200: 0.8177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 1.0337\n",
      "Training accuracy: 0.7396 Validation accuracy: 0.6650 Time taken: 110.74s\n",
      "Epoch 187/200\n",
      "Training loss at step 0: 0.6981\n",
      "Training loss at step 100: 0.8628\n",
      "Training loss at step 200: 0.8150\n",
      "Training loss at step 300: 1.0012\n",
      "Training accuracy: 0.7419 Validation accuracy: 0.6630 Time taken: 111.73s\n",
      "Epoch 188/200\n",
      "Training loss at step 0: 0.8220\n",
      "Training loss at step 100: 0.8567\n",
      "Training loss at step 200: 0.8873\n",
      "Training loss at step 300: 0.7652\n",
      "Training accuracy: 0.7378 Validation accuracy: 0.6656 Time taken: 111.68s\n",
      "Epoch 189/200\n",
      "Training loss at step 0: 0.7491\n",
      "Training loss at step 100: 0.6329\n",
      "Training loss at step 200: 0.8521\n",
      "Training loss at step 300: 1.0476\n",
      "Training accuracy: 0.7409 Validation accuracy: 0.6638 Time taken: 111.00s\n",
      "Epoch 190/200\n",
      "Training loss at step 0: 0.7670\n",
      "Training loss at step 100: 0.8638\n",
      "Training loss at step 200: 0.7248\n",
      "Training loss at step 300: 0.7292\n",
      "Training accuracy: 0.7434 Validation accuracy: 0.6636 Time taken: 112.00s\n",
      "Epoch 191/200\n",
      "Training loss at step 0: 0.7210\n",
      "Training loss at step 100: 1.4063\n",
      "Training loss at step 200: 1.1580\n",
      "Training loss at step 300: 0.9277\n",
      "Training accuracy: 0.7400 Validation accuracy: 0.6618 Time taken: 112.50s\n",
      "Epoch 192/200\n",
      "Training loss at step 0: 0.7030\n",
      "Training loss at step 100: 1.0070\n",
      "Training loss at step 200: 0.9782\n",
      "Training loss at step 300: 0.9646\n",
      "Training accuracy: 0.7444 Validation accuracy: 0.6652 Time taken: 112.24s\n",
      "Epoch 193/200\n",
      "Training loss at step 0: 1.3701\n",
      "Training loss at step 100: 0.9643\n",
      "Training loss at step 200: 0.7959\n",
      "Training loss at step 300: 0.9420\n",
      "Training accuracy: 0.7388 Validation accuracy: 0.6640 Time taken: 111.66s\n",
      "Epoch 194/200\n",
      "Training loss at step 0: 0.5877\n",
      "Training loss at step 100: 1.0066\n",
      "Training loss at step 200: 0.8645\n",
      "Training loss at step 300: 0.7903\n",
      "Training accuracy: 0.7427 Validation accuracy: 0.6602 Time taken: 112.26s\n",
      "Epoch 195/200\n",
      "Training loss at step 0: 1.0785\n",
      "Training loss at step 100: 0.7109\n",
      "Training loss at step 200: 0.6764\n",
      "Training loss at step 300: 0.9585\n",
      "Training accuracy: 0.7410 Validation accuracy: 0.6634 Time taken: 111.52s\n",
      "Epoch 196/200\n",
      "Training loss at step 0: 1.3094\n",
      "Training loss at step 100: 0.7603\n",
      "Training loss at step 200: 0.7892\n",
      "Training loss at step 300: 0.9452\n",
      "Training accuracy: 0.7402 Validation accuracy: 0.6646 Time taken: 111.70s\n",
      "Epoch 197/200\n",
      "Training loss at step 0: 0.7111\n",
      "Training loss at step 100: 1.0697\n",
      "Training loss at step 200: 0.9432\n",
      "Training loss at step 300: 1.0583\n",
      "Training accuracy: 0.7405 Validation accuracy: 0.6634 Time taken: 111.89s\n",
      "Epoch 198/200\n",
      "Training loss at step 0: 0.9256\n",
      "Training loss at step 100: 0.7961\n",
      "Training loss at step 200: 1.0820\n",
      "Training loss at step 300: 0.7112\n",
      "Training accuracy: 0.7433 Validation accuracy: 0.6656 Time taken: 113.31s\n",
      "Epoch 199/200\n",
      "Training loss at step 0: 0.8410\n",
      "Training loss at step 100: 0.9167\n",
      "Training loss at step 200: 0.7336\n",
      "Training loss at step 300: 0.8488\n",
      "Training accuracy: 0.7400 Validation accuracy: 0.6630 Time taken: 111.14s\n",
      "Epoch 200/200\n",
      "Training loss at step 0: 0.8990\n",
      "Training loss at step 100: 0.8087\n",
      "Training loss at step 200: 1.2390\n",
      "Training loss at step 300: 0.8406\n",
      "Training accuracy: 0.7375 Validation accuracy: 0.6618 Time taken: 111.25s\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1,nesterov=True)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "history = [[],[],[]]\n",
    "time_0 = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch %d/%d\" % (epoch+1,epochs))\n",
    "    if (epoch==100) | (epoch==150):\n",
    "        optimizer.learning_rate = optimizer.learning_rate/10\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    for x_batch_train, y_batch_train in train_data:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                \"Training loss at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "        step += 1\n",
    "        if step > len(x_train)/batch_size:\n",
    "            break\n",
    "\n",
    "    history[0].append(loss_value)\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    \n",
    "    step = 0\n",
    "    for x_batch_val, y_batch_val in validation_data:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "        step += 1\n",
    "        if step > len(x_val)/batch_size:\n",
    "            break\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    history[1].append(train_acc)\n",
    "    history[2].append(val_acc)\n",
    "    print(\"Training accuracy: %.4f\" % (float(train_acc),)\n",
    "          ,\"Validation accuracy: %.4f\" % (float(val_acc),),\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "total_time = time.time() - time_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74e4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = np.array(history)\n",
    "np.save(\"./Logs/StochasticNet110_cifar100\",log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b674eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "m.update_state(y_test, y_predict)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8eb7b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22273.5688893795\n"
     ]
    }
   ],
   "source": [
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dca6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Logs/StochasticNet110_cifar100.npy', 'rb') as f:\n",
    "     log = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6285406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa823796550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1-log[1],label='training error')\n",
    "plt.plot(1-log[2],label='validation error')\n",
    "plt.ylim(0,0.8)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505df7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
