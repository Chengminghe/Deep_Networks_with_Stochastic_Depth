{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confident-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "elder-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "organized-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train-np.mean(x_train,axis=0)\n",
    "x_test = x_test - np.mean(x_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "figured-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "planned-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D, BatchNormalization\n",
    "input_shape = (32,32,3)\n",
    "\"\"\"\n",
    "For training on cifar10/cifar100 data\n",
    "create a plain network model, 6n+2 layers,\n",
    "\"\"\"\n",
    "def create_model(input_shape,n):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(filters=16,kernel_size=(3, 3),input_shape=input_shape,activation='relu'\n",
    "             ,kernel_initializer=tf.keras.initializers.HeNormal(),padding=\"same\",use_bias=True))\n",
    "    for i in range(2*n):\n",
    "        model.add(Conv2D(filters=16,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(Conv2D(filters=32,kernel_size=(3, 3),activation='relu',strides=(2,2),padding=\"same\"\n",
    "             ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    for i in range(2*n-1):\n",
    "        model.add(Conv2D(filters=32,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3),activation='relu',strides=(2,2),padding=\"same\"\n",
    "             ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    for i in range(2*n-1):\n",
    "        model.add(Conv2D(filters=64,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "stable-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "neural-reporter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_260 (Conv2D)          (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_261 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_262 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_263 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_264 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_265 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_266 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_267 (Conv2D)          (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_268 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_269 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_270 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_271 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_272 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_273 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_274 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_275 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_276 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_277 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_278 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 269,290\n",
      "Trainable params: 269,162\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "exact-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "sticky-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=x_train, \n",
    "#           y=y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=10, \n",
    "#           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "literary-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D, BatchNormalization, ReLU\n",
    "\n",
    "class ResNet(Model):\n",
    "\n",
    "    def __init__(self, num_block, input_shape, output_size=100):\n",
    "        '''\n",
    "        For training the cifar10/cifar100 data in the ResNet paper\n",
    "        input_shape: The size of the input. (img_len, img_len, channel_num).\n",
    "        output_size: The size of the output. It should be equal to the number of classes.\n",
    "        '''\n",
    "        super(ResNet, self).__init__()\n",
    "        #############################################################\n",
    "        # TODO: Define layers for your custom LeNet network         \n",
    "        # Hint: Try adding additional convolution and avgpool layers\n",
    "        #############################################################\n",
    "        self.num_block = num_block\n",
    "        self.layer = dict()\n",
    "        self.layer['conv1'] = Conv2D(filters=16,kernel_size=(3, 3),input_shape=input_shape,activation='relu'\n",
    "                                ,kernel_initializer=tf.keras.initializers.HeNormal(),padding=\"same\",use_bias=True)\n",
    "\n",
    "        for i in range(2*num_block):\n",
    "            self.layer['conv1_%d'%(i+1)] = Conv2D(filters=16,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                                    ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "        self.layer['conv2_1'] = Conv2D(filters=32,kernel_size=(3, 3),activation='relu',strides=(2,2),padding=\"same\"\n",
    "             ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        for i in range(2*num_block-1):\n",
    "            self.layer['conv2_%d'%(i+2)] = Conv2D(filters=32,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        \n",
    "        self.layer['conv3_1'] = Conv2D(filters=64,kernel_size=(3, 3),activation='relu',strides=(2,2),padding=\"same\"\n",
    "             ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        for i in range(2*num_block-1):\n",
    "            self.layer['conv3_%d'%(i+2)] = Conv2D(filters=64,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "        \n",
    "        self.layer['avgpool'] = GlobalAveragePooling2D()\n",
    "        self.layer['bn'] = BatchNormalization()\n",
    "        self.layer['fc'] = Dense(100,activation='softmax')\n",
    "    \n",
    "        #############################################################\n",
    "        #                          END TODO                         #                                              \n",
    "        #############################################################\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        '''\n",
    "        x: input to LeNet model.\n",
    "        '''\n",
    "        #call function returns forward pass output of the network\n",
    "        #############################################################\n",
    "        # TODO: Implement forward pass for custom network defined \n",
    "        # in __init__ and return network output\n",
    "        #############################################################\n",
    "        num_block = self.num_block\n",
    "        x = self.layer['conv1'](x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x_prev = x\n",
    "        \n",
    "        for i in range(2*num_block):\n",
    "            if i%2 == 0:\n",
    "                x = self.layer['conv1_%d'%(i+1)](x)\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                x = ReLU()(self.layer['conv1_%d'%(i+1)](x) + x_prev)\n",
    "                x = BatchNormalization()(x)\n",
    "                x_prev = x\n",
    "        \n",
    "\n",
    "\n",
    "        for i in range(2*num_block):\n",
    "            if i%2 == 0:\n",
    "                x = self.layer['conv2_%d'%(i+1)](x)\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                if x.shape == x_prev.shape:\n",
    "                    x =  ReLU()(self.layer['conv2_%d'%(i+1)](x) + x_prev)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x_prev = x\n",
    "                else:\n",
    "                    x_prev = Conv2D(filters=32,kernel_size=(1, 1),strides=(2, 2)\n",
    "                            ,use_bias=False,kernel_initializer=tf.keras.initializers.Ones())(x_prev)/16\n",
    "                    x =  ReLU()(self.layer['conv2_%d'%(i+1)](x) + x_prev)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x_prev = x\n",
    "\n",
    "        for i in range(2*num_block):\n",
    "            if i%2 == 0:\n",
    "                x = self.layer['conv3_%d'%(i+1)](x)\n",
    "                x = BatchNormalization()(x)\n",
    "            else:\n",
    "                if x.shape == x_prev.shape:\n",
    "                    x =  ReLU()(self.layer['conv3_%d'%(i+1)](x) + x_prev)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x_prev = x\n",
    "                else:\n",
    "                    x_prev = Conv2D(filters=64,kernel_size=(1, 1),strides=(2, 2)\n",
    "                            ,use_bias=False,kernel_initializer=tf.keras.initializers.Ones())(x_prev)/32\n",
    "                    x =  ReLU()(self.layer['conv3_%d'%(i+1)](x) + x_prev)\n",
    "                    x = BatchNormalization()(x)\n",
    "                    x_prev = x\n",
    "\n",
    "        x = self.layer['avgpool'](x)\n",
    "        x = self.layer['bn'](x)\n",
    "        out = self.layer['fc'](x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Training loss at step 0: 5.2383\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model = ResNet(num_block=1, input_shape=input_shape)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "batch_size = 128\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "history = [[],[],[]]\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch %d/%d\" % (epoch+1,epochs))\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        if step % 400 == 0:\n",
    "            print(\n",
    "                \"Training loss at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "\n",
    "    history[0].append(loss_value)\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    history[1].append(train_acc)\n",
    "    history[2].append(val_acc)\n",
    "    print(\"Training accuracy: %.4f\" % (float(train_acc),)\n",
    "          ,\"Validation accuracy: %.4f\" % (float(val_acc),),\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "protected-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(filters=16,kernel_size=(3, 3),input_shape=input_shape,activation='relu'\n",
    "                                ,kernel_initializer=tf.keras.initializers.HeNormal(),padding=\"same\",use_bias=True)(x)\n",
    "x_pre = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "charged-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(filters=16,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                                    ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())(x)\n",
    "x = Conv2D(filters=16,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                                    ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())(x) + x_pre\n",
    "x =  ReLU()(x)\n",
    "x_pre = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "brief-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(filters=32,kernel_size=(3, 3),activation='relu',strides=(2,2),padding=\"same\"\n",
    "             ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())(x)\n",
    "x_pre = Conv2D(filters=32,kernel_size=(1, 1),strides=(2, 2)\n",
    "                            ,use_bias=False,kernel_initializer=tf.keras.initializers.Ones())(x_pre)/16\n",
    "x = Conv2D(filters=32,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())(x) + x_pre\n",
    "x =  ReLU()(x)\n",
    "x_pre = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "double-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(filters=64,kernel_size=(3, 3),activation='relu',strides=(2,2),padding=\"same\"\n",
    "             ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())(x)\n",
    "x_pre = Conv2D(filters=64,kernel_size=(1, 1),strides=(2, 2)\n",
    "                            ,use_bias=False,kernel_initializer=tf.keras.initializers.Ones())(x_pre)/32\n",
    "x = Conv2D(filters=64,kernel_size=(3, 3),activation='relu',padding=\"same\"\n",
    "                     ,use_bias=True,kernel_initializer=tf.keras.initializers.HeNormal())(x) + x_pre\n",
    "x =  ReLU()(x)\n",
    "x_pre = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "through-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "constitutional-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(100,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "raised-evaluation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 100), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        3.2832270e-07, 0.0000000e+00, 0.0000000e+00, 3.9675338e-03,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        9.9603206e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        6.7386478e-11, 0.0000000e+00, 0.0000000e+00, 8.1893960e-03,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        9.9181056e-01, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 6.3687607e-35, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.5847671e-33,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3695788e-24,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 3.3427092e-21, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        9.4956232e-34, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        8.8881993e-01, 0.0000000e+00, 0.0000000e+00, 1.0045591e-01,\n",
       "        2.7188192e-28, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0724231e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 3.6736628e-27, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.9436832e-20,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.4081984e-13, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        3.2768300e-15, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 9.1919850e-31, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-burner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
