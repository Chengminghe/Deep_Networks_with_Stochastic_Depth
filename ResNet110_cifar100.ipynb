{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rural-musical",
   "metadata": {},
   "source": [
    "## Training of CIFAR-100 using 110-layer ResNet with constant depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.neuralnets.ResNet110 import ResNet110\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D,Input,Flatten,Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "personalized-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data and standardize cifar10\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train = (x_train - np.mean(x_train,axis=0))/np.std(x_train,axis=0)\n",
    "x_test = (x_test - np.mean(x_test,axis=0))/np.std(x_test,axis=0)\n",
    "##train validation split, 45000 for training and 5000 for validation\n",
    "np.random.seed(42)\n",
    "mask_val = np.random.choice(50000,5000,replace=False)\n",
    "mask_train = np.array([i for i in range(50000) if i not in mask_val])\n",
    "x_val, y_val = x_train[mask_val], y_train[mask_val]\n",
    "x_train, y_train = x_train[mask_train], y_train[mask_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "datagen_for_train = ImageDataGenerator(horizontal_flip=True,width_shift_range= 4, height_shift_range= 4)\n",
    "datagen_for_test = ImageDataGenerator()\n",
    "train_data = datagen_for_train.flow(x_train,y_train,batch_size=batch_size)\n",
    "validation_data = datagen_for_test.flow(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "martial-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a ResNet110 model\n",
    "input_shape = x_train.shape[1:]\n",
    "num_class = 100\n",
    "model = ResNet110(input_shape=input_shape,num_class=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wound-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training loss at step 0: 13.5569\n",
      "Training loss at step 100: 4.7295\n",
      "Training loss at step 200: 4.7128\n",
      "Training loss at step 300: 4.6507\n",
      "Training accuracy: 0.0151 Validation accuracy: 0.0222 Time taken: 156.84s\n",
      "Epoch 2/200\n",
      "Training loss at step 0: 4.4776\n",
      "Training loss at step 100: 4.1353\n",
      "Training loss at step 200: 4.0339\n",
      "Training loss at step 300: 3.8852\n",
      "Training accuracy: 0.0526 Validation accuracy: 0.0718 Time taken: 123.10s\n",
      "Epoch 3/200\n",
      "Training loss at step 0: 4.0443\n",
      "Training loss at step 100: 3.8986\n",
      "Training loss at step 200: 3.8353\n",
      "Training loss at step 300: 3.7436\n",
      "Training accuracy: 0.0951 Validation accuracy: 0.0956 Time taken: 121.90s\n",
      "Epoch 4/200\n",
      "Training loss at step 0: 3.5797\n",
      "Training loss at step 100: 3.6265\n",
      "Training loss at step 200: 3.5595\n",
      "Training loss at step 300: 3.6065\n",
      "Training accuracy: 0.1360 Validation accuracy: 0.1354 Time taken: 122.11s\n",
      "Epoch 5/200\n",
      "Training loss at step 0: 3.2863\n",
      "Training loss at step 100: 3.7224\n",
      "Training loss at step 200: 3.3379\n",
      "Training loss at step 300: 3.4805\n",
      "Training accuracy: 0.1716 Validation accuracy: 0.1656 Time taken: 122.74s\n",
      "Epoch 6/200\n",
      "Training loss at step 0: 3.1249\n",
      "Training loss at step 100: 3.1904\n",
      "Training loss at step 200: 3.0196\n",
      "Training loss at step 300: 3.0339\n",
      "Training accuracy: 0.2039 Validation accuracy: 0.1682 Time taken: 122.62s\n",
      "Epoch 7/200\n",
      "Training loss at step 0: 3.0859\n",
      "Training loss at step 100: 3.2962\n",
      "Training loss at step 200: 3.2379\n",
      "Training loss at step 300: 2.8302\n",
      "Training accuracy: 0.2332 Validation accuracy: 0.2172 Time taken: 122.69s\n",
      "Epoch 8/200\n",
      "Training loss at step 0: 3.1680\n",
      "Training loss at step 100: 2.8720\n",
      "Training loss at step 200: 2.5825\n",
      "Training loss at step 300: 3.0741\n",
      "Training accuracy: 0.2607 Validation accuracy: 0.1986 Time taken: 122.02s\n",
      "Epoch 9/200\n",
      "Training loss at step 0: 2.9415\n",
      "Training loss at step 100: 2.7231\n",
      "Training loss at step 200: 2.8829\n",
      "Training loss at step 300: 2.8809\n",
      "Training accuracy: 0.2839 Validation accuracy: 0.2508 Time taken: 123.05s\n",
      "Epoch 10/200\n",
      "Training loss at step 0: 2.8778\n",
      "Training loss at step 100: 2.7069\n",
      "Training loss at step 200: 2.6726\n",
      "Training loss at step 300: 2.4216\n",
      "Training accuracy: 0.3103 Validation accuracy: 0.2442 Time taken: 121.83s\n",
      "Epoch 11/200\n",
      "Training loss at step 0: 2.6092\n",
      "Training loss at step 100: 2.6870\n",
      "Training loss at step 200: 2.5003\n",
      "Training loss at step 300: 2.4401\n",
      "Training accuracy: 0.3362 Validation accuracy: 0.2620 Time taken: 122.64s\n",
      "Epoch 12/200\n",
      "Training loss at step 0: 2.2638\n",
      "Training loss at step 100: 2.4143\n",
      "Training loss at step 200: 2.4391\n",
      "Training loss at step 300: 2.5963\n",
      "Training accuracy: 0.3584 Validation accuracy: 0.2878 Time taken: 123.16s\n",
      "Epoch 13/200\n",
      "Training loss at step 0: 2.5346\n",
      "Training loss at step 100: 2.4472\n",
      "Training loss at step 200: 2.6141\n",
      "Training loss at step 300: 2.4819\n",
      "Training accuracy: 0.3839 Validation accuracy: 0.2864 Time taken: 122.33s\n",
      "Epoch 14/200\n",
      "Training loss at step 0: 2.3310\n",
      "Training loss at step 100: 1.8185\n",
      "Training loss at step 200: 2.2163\n",
      "Training loss at step 300: 2.1665\n",
      "Training accuracy: 0.4015 Validation accuracy: 0.3208 Time taken: 122.75s\n",
      "Epoch 15/200\n",
      "Training loss at step 0: 2.1893\n",
      "Training loss at step 100: 1.9502\n",
      "Training loss at step 200: 2.0468\n",
      "Training loss at step 300: 2.2842\n",
      "Training accuracy: 0.4211 Validation accuracy: 0.3394 Time taken: 122.76s\n",
      "Epoch 16/200\n",
      "Training loss at step 0: 2.3345\n",
      "Training loss at step 100: 1.9081\n",
      "Training loss at step 200: 2.4185\n",
      "Training loss at step 300: 1.7522\n",
      "Training accuracy: 0.4394 Validation accuracy: 0.3532 Time taken: 122.49s\n",
      "Epoch 17/200\n",
      "Training loss at step 0: 1.8831\n",
      "Training loss at step 100: 2.1774\n",
      "Training loss at step 200: 1.9392\n",
      "Training loss at step 300: 1.7228\n",
      "Training accuracy: 0.4557 Validation accuracy: 0.3560 Time taken: 122.83s\n",
      "Epoch 18/200\n",
      "Training loss at step 0: 1.8060\n",
      "Training loss at step 100: 1.8895\n",
      "Training loss at step 200: 1.8950\n",
      "Training loss at step 300: 1.8990\n",
      "Training accuracy: 0.4761 Validation accuracy: 0.3614 Time taken: 123.31s\n",
      "Epoch 19/200\n",
      "Training loss at step 0: 1.9334\n",
      "Training loss at step 100: 1.8164\n",
      "Training loss at step 200: 1.8991\n",
      "Training loss at step 300: 1.6315\n",
      "Training accuracy: 0.4888 Validation accuracy: 0.3726 Time taken: 122.54s\n",
      "Epoch 20/200\n",
      "Training loss at step 0: 1.7363\n",
      "Training loss at step 100: 2.0856\n",
      "Training loss at step 200: 1.7007\n",
      "Training loss at step 300: 1.7104\n",
      "Training accuracy: 0.5056 Validation accuracy: 0.4108 Time taken: 123.10s\n",
      "Epoch 21/200\n",
      "Training loss at step 0: 1.7621\n",
      "Training loss at step 100: 1.7277\n",
      "Training loss at step 200: 1.7182\n",
      "Training loss at step 300: 2.0780\n",
      "Training accuracy: 0.5165 Validation accuracy: 0.4386 Time taken: 122.66s\n",
      "Epoch 22/200\n",
      "Training loss at step 0: 1.6876\n",
      "Training loss at step 100: 1.3766\n",
      "Training loss at step 200: 1.5825\n",
      "Training loss at step 300: 1.5560\n",
      "Training accuracy: 0.5277 Validation accuracy: 0.3994 Time taken: 123.39s\n",
      "Epoch 23/200\n",
      "Training loss at step 0: 1.8386\n",
      "Training loss at step 100: 1.2986\n",
      "Training loss at step 200: 1.6620\n",
      "Training loss at step 300: 1.6923\n",
      "Training accuracy: 0.5398 Validation accuracy: 0.3734 Time taken: 123.46s\n",
      "Epoch 24/200\n",
      "Training loss at step 0: 1.7236\n",
      "Training loss at step 100: 1.4820\n",
      "Training loss at step 200: 1.5288\n",
      "Training loss at step 300: 1.3227\n",
      "Training accuracy: 0.5537 Validation accuracy: 0.4122 Time taken: 123.31s\n",
      "Epoch 25/200\n",
      "Training loss at step 0: 1.4666\n",
      "Training loss at step 100: 1.3543\n",
      "Training loss at step 200: 1.5958\n",
      "Training loss at step 300: 1.4207\n",
      "Training accuracy: 0.5654 Validation accuracy: 0.4380 Time taken: 123.29s\n",
      "Epoch 26/200\n",
      "Training loss at step 0: 1.4468\n",
      "Training loss at step 100: 1.5377\n",
      "Training loss at step 200: 1.5701\n",
      "Training loss at step 300: 1.4967\n",
      "Training accuracy: 0.5743 Validation accuracy: 0.4654 Time taken: 123.64s\n",
      "Epoch 27/200\n",
      "Training loss at step 0: 1.3805\n",
      "Training loss at step 100: 1.1467\n",
      "Training loss at step 200: 1.3367\n",
      "Training loss at step 300: 1.5175\n",
      "Training accuracy: 0.5863 Validation accuracy: 0.3964 Time taken: 123.65s\n",
      "Epoch 28/200\n",
      "Training loss at step 0: 1.5163\n",
      "Training loss at step 100: 1.3157\n",
      "Training loss at step 200: 1.3295\n",
      "Training loss at step 300: 1.5461\n",
      "Training accuracy: 0.5965 Validation accuracy: 0.4552 Time taken: 123.09s\n",
      "Epoch 29/200\n",
      "Training loss at step 0: 1.6758\n",
      "Training loss at step 100: 1.4963\n",
      "Training loss at step 200: 1.4878\n",
      "Training loss at step 300: 1.5846\n",
      "Training accuracy: 0.6082 Validation accuracy: 0.4810 Time taken: 123.51s\n",
      "Epoch 30/200\n",
      "Training loss at step 0: 1.4126\n",
      "Training loss at step 100: 1.2921\n",
      "Training loss at step 200: 1.3699\n",
      "Training loss at step 300: 1.0651\n",
      "Training accuracy: 0.6133 Validation accuracy: 0.4674 Time taken: 123.66s\n",
      "Epoch 31/200\n",
      "Training loss at step 0: 1.1879\n",
      "Training loss at step 100: 1.2075\n",
      "Training loss at step 200: 1.3449\n",
      "Training loss at step 300: 1.6273\n",
      "Training accuracy: 0.6234 Validation accuracy: 0.4582 Time taken: 123.21s\n",
      "Epoch 32/200\n",
      "Training loss at step 0: 1.1620\n",
      "Training loss at step 100: 1.1828\n",
      "Training loss at step 200: 1.1380\n",
      "Training loss at step 300: 1.1943\n",
      "Training accuracy: 0.6312 Validation accuracy: 0.4856 Time taken: 122.93s\n",
      "Epoch 33/200\n",
      "Training loss at step 0: 1.3353\n",
      "Training loss at step 100: 1.0892\n",
      "Training loss at step 200: 1.3471\n",
      "Training loss at step 300: 1.1830\n",
      "Training accuracy: 0.6404 Validation accuracy: 0.4734 Time taken: 123.07s\n",
      "Epoch 34/200\n",
      "Training loss at step 0: 1.3601\n",
      "Training loss at step 100: 1.2667\n",
      "Training loss at step 200: 1.2131\n",
      "Training loss at step 300: 1.3224\n",
      "Training accuracy: 0.6508 Validation accuracy: 0.4134 Time taken: 123.02s\n",
      "Epoch 35/200\n",
      "Training loss at step 0: 1.0814\n",
      "Training loss at step 100: 1.1957\n",
      "Training loss at step 200: 1.2059\n",
      "Training loss at step 300: 0.9691\n",
      "Training accuracy: 0.6562 Validation accuracy: 0.4470 Time taken: 123.92s\n",
      "Epoch 36/200\n",
      "Training loss at step 0: 1.2981\n",
      "Training loss at step 100: 1.1665\n",
      "Training loss at step 200: 1.2971\n",
      "Training loss at step 300: 1.2171\n",
      "Training accuracy: 0.6656 Validation accuracy: 0.4574 Time taken: 123.12s\n",
      "Epoch 37/200\n",
      "Training loss at step 0: 0.9580\n",
      "Training loss at step 100: 0.9047\n",
      "Training loss at step 200: 1.1456\n",
      "Training loss at step 300: 1.3258\n",
      "Training accuracy: 0.6703 Validation accuracy: 0.4846 Time taken: 122.28s\n",
      "Epoch 38/200\n",
      "Training loss at step 0: 1.2249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 100: 1.1134\n",
      "Training loss at step 200: 1.3177\n",
      "Training loss at step 300: 0.9008\n",
      "Training accuracy: 0.6752 Validation accuracy: 0.4854 Time taken: 123.59s\n",
      "Epoch 39/200\n",
      "Training loss at step 0: 1.0952\n",
      "Training loss at step 100: 1.1239\n",
      "Training loss at step 200: 0.9809\n",
      "Training loss at step 300: 1.2649\n",
      "Training accuracy: 0.6873 Validation accuracy: 0.4532 Time taken: 123.80s\n",
      "Epoch 40/200\n",
      "Training loss at step 0: 1.0123\n",
      "Training loss at step 100: 1.0079\n",
      "Training loss at step 200: 1.0605\n",
      "Training loss at step 300: 1.0548\n",
      "Training accuracy: 0.6924 Validation accuracy: 0.4778 Time taken: 123.62s\n",
      "Epoch 41/200\n",
      "Training loss at step 0: 1.0108\n",
      "Training loss at step 100: 0.9226\n",
      "Training loss at step 200: 0.9436\n",
      "Training loss at step 300: 1.0238\n",
      "Training accuracy: 0.6993 Validation accuracy: 0.4754 Time taken: 122.90s\n",
      "Epoch 42/200\n",
      "Training loss at step 0: 0.9227\n",
      "Training loss at step 100: 1.0636\n",
      "Training loss at step 200: 1.0079\n",
      "Training loss at step 300: 1.1519\n",
      "Training accuracy: 0.7069 Validation accuracy: 0.4784 Time taken: 123.87s\n",
      "Epoch 43/200\n",
      "Training loss at step 0: 0.8254\n",
      "Training loss at step 100: 1.1503\n",
      "Training loss at step 200: 0.7678\n",
      "Training loss at step 300: 0.8220\n",
      "Training accuracy: 0.7136 Validation accuracy: 0.4748 Time taken: 123.74s\n",
      "Epoch 44/200\n",
      "Training loss at step 0: 0.7760\n",
      "Training loss at step 100: 0.8183\n",
      "Training loss at step 200: 1.0071\n",
      "Training loss at step 300: 0.9297\n",
      "Training accuracy: 0.7222 Validation accuracy: 0.4822 Time taken: 123.22s\n",
      "Epoch 45/200\n",
      "Training loss at step 0: 1.0404\n",
      "Training loss at step 100: 0.9793\n",
      "Training loss at step 200: 0.9615\n",
      "Training loss at step 300: 0.8536\n",
      "Training accuracy: 0.7239 Validation accuracy: 0.4600 Time taken: 122.28s\n",
      "Epoch 46/200\n",
      "Training loss at step 0: 0.9465\n",
      "Training loss at step 100: 0.7931\n",
      "Training loss at step 200: 0.9878\n",
      "Training loss at step 300: 0.8762\n",
      "Training accuracy: 0.7344 Validation accuracy: 0.4960 Time taken: 122.83s\n",
      "Epoch 47/200\n",
      "Training loss at step 0: 0.9361\n",
      "Training loss at step 100: 1.0973\n",
      "Training loss at step 200: 0.7777\n",
      "Training loss at step 300: 1.0377\n",
      "Training accuracy: 0.7365 Validation accuracy: 0.5110 Time taken: 123.55s\n",
      "Epoch 48/200\n",
      "Training loss at step 0: 0.9393\n",
      "Training loss at step 100: 0.8173\n",
      "Training loss at step 200: 1.0075\n",
      "Training loss at step 300: 0.9952\n",
      "Training accuracy: 0.7440 Validation accuracy: 0.4966 Time taken: 123.43s\n",
      "Epoch 49/200\n",
      "Training loss at step 0: 0.7552\n",
      "Training loss at step 100: 0.7353\n",
      "Training loss at step 200: 0.8134\n",
      "Training loss at step 300: 0.7979\n",
      "Training accuracy: 0.7482 Validation accuracy: 0.4938 Time taken: 124.49s\n",
      "Epoch 50/200\n",
      "Training loss at step 0: 0.8890\n",
      "Training loss at step 100: 0.6765\n",
      "Training loss at step 200: 0.8712\n",
      "Training loss at step 300: 0.6689\n",
      "Training accuracy: 0.7589 Validation accuracy: 0.5212 Time taken: 123.28s\n",
      "Epoch 51/200\n",
      "Training loss at step 0: 0.8049\n",
      "Training loss at step 100: 0.7740\n",
      "Training loss at step 200: 0.8257\n",
      "Training loss at step 300: 0.8278\n",
      "Training accuracy: 0.7617 Validation accuracy: 0.5300 Time taken: 123.14s\n",
      "Epoch 52/200\n",
      "Training loss at step 0: 0.6596\n",
      "Training loss at step 100: 0.6846\n",
      "Training loss at step 200: 0.8451\n",
      "Training loss at step 300: 0.6571\n",
      "Training accuracy: 0.7663 Validation accuracy: 0.4956 Time taken: 122.61s\n",
      "Epoch 53/200\n",
      "Training loss at step 0: 0.6063\n",
      "Training loss at step 100: 0.8365\n",
      "Training loss at step 200: 0.7540\n",
      "Training loss at step 300: 0.7818\n",
      "Training accuracy: 0.7713 Validation accuracy: 0.4510 Time taken: 121.65s\n",
      "Epoch 54/200\n",
      "Training loss at step 0: 0.5282\n",
      "Training loss at step 100: 0.7563\n",
      "Training loss at step 200: 0.8431\n",
      "Training loss at step 300: 0.8958\n",
      "Training accuracy: 0.7762 Validation accuracy: 0.4892 Time taken: 123.02s\n",
      "Epoch 55/200\n",
      "Training loss at step 0: 0.6894\n",
      "Training loss at step 100: 0.6192\n",
      "Training loss at step 200: 0.7577\n",
      "Training loss at step 300: 0.7805\n",
      "Training accuracy: 0.7757 Validation accuracy: 0.5194 Time taken: 122.45s\n",
      "Epoch 56/200\n",
      "Training loss at step 0: 0.5608\n",
      "Training loss at step 100: 0.6186\n",
      "Training loss at step 200: 0.4656\n",
      "Training loss at step 300: 0.7503\n",
      "Training accuracy: 0.7843 Validation accuracy: 0.4972 Time taken: 121.99s\n",
      "Epoch 57/200\n",
      "Training loss at step 0: 0.7988\n",
      "Training loss at step 100: 0.6206\n",
      "Training loss at step 200: 0.7153\n",
      "Training loss at step 300: 0.6163\n",
      "Training accuracy: 0.7897 Validation accuracy: 0.4632 Time taken: 122.63s\n",
      "Epoch 58/200\n",
      "Training loss at step 0: 0.6752\n",
      "Training loss at step 100: 0.8696\n",
      "Training loss at step 200: 0.6631\n",
      "Training loss at step 300: 0.7636\n",
      "Training accuracy: 0.7965 Validation accuracy: 0.5094 Time taken: 123.36s\n",
      "Epoch 59/200\n",
      "Training loss at step 0: 0.5522\n",
      "Training loss at step 100: 0.5204\n",
      "Training loss at step 200: 0.5294\n",
      "Training loss at step 300: 0.9127\n",
      "Training accuracy: 0.8014 Validation accuracy: 0.4928 Time taken: 122.70s\n",
      "Epoch 60/200\n",
      "Training loss at step 0: 0.6977\n",
      "Training loss at step 100: 0.7458\n",
      "Training loss at step 200: 0.5995\n",
      "Training loss at step 300: 0.4464\n",
      "Training accuracy: 0.8026 Validation accuracy: 0.4758 Time taken: 123.42s\n",
      "Epoch 61/200\n",
      "Training loss at step 0: 0.5208\n",
      "Training loss at step 100: 0.7032\n",
      "Training loss at step 200: 0.5490\n",
      "Training loss at step 300: 0.6149\n",
      "Training accuracy: 0.8083 Validation accuracy: 0.5080 Time taken: 122.93s\n",
      "Epoch 62/200\n",
      "Training loss at step 0: 0.4799\n",
      "Training loss at step 100: 0.6729\n",
      "Training loss at step 200: 0.8132\n",
      "Training loss at step 300: 0.6282\n",
      "Training accuracy: 0.8108 Validation accuracy: 0.4644 Time taken: 123.00s\n",
      "Epoch 63/200\n",
      "Training loss at step 0: 0.6203\n",
      "Training loss at step 100: 0.5090\n",
      "Training loss at step 200: 0.4259\n",
      "Training loss at step 300: 0.6168\n",
      "Training accuracy: 0.8158 Validation accuracy: 0.5044 Time taken: 124.98s\n",
      "Epoch 64/200\n",
      "Training loss at step 0: 0.6280\n",
      "Training loss at step 100: 0.6305\n",
      "Training loss at step 200: 0.6649\n",
      "Training loss at step 300: 0.6120\n",
      "Training accuracy: 0.8180 Validation accuracy: 0.4940 Time taken: 122.99s\n",
      "Epoch 65/200\n",
      "Training loss at step 0: 0.7039\n",
      "Training loss at step 100: 0.4674\n",
      "Training loss at step 200: 0.5304\n",
      "Training loss at step 300: 0.5477\n",
      "Training accuracy: 0.8226 Validation accuracy: 0.5190 Time taken: 123.23s\n",
      "Epoch 66/200\n",
      "Training loss at step 0: 0.5173\n",
      "Training loss at step 100: 0.5329\n",
      "Training loss at step 200: 0.6352\n",
      "Training loss at step 300: 0.5593\n",
      "Training accuracy: 0.8295 Validation accuracy: 0.4746 Time taken: 123.59s\n",
      "Epoch 67/200\n",
      "Training loss at step 0: 0.5372\n",
      "Training loss at step 100: 0.5472\n",
      "Training loss at step 200: 0.5821\n",
      "Training loss at step 300: 0.5209\n",
      "Training accuracy: 0.8313 Validation accuracy: 0.4962 Time taken: 122.99s\n",
      "Epoch 68/200\n",
      "Training loss at step 0: 0.6527\n",
      "Training loss at step 100: 0.5346\n",
      "Training loss at step 200: 0.6191\n",
      "Training loss at step 300: 0.5484\n",
      "Training accuracy: 0.8361 Validation accuracy: 0.5326 Time taken: 123.14s\n",
      "Epoch 69/200\n",
      "Training loss at step 0: 0.4031\n",
      "Training loss at step 100: 0.6429\n",
      "Training loss at step 200: 0.3574\n",
      "Training loss at step 300: 0.5679\n",
      "Training accuracy: 0.8397 Validation accuracy: 0.5390 Time taken: 122.62s\n",
      "Epoch 70/200\n",
      "Training loss at step 0: 0.4687\n",
      "Training loss at step 100: 0.4686\n",
      "Training loss at step 200: 0.4366\n",
      "Training loss at step 300: 0.5774\n",
      "Training accuracy: 0.8432 Validation accuracy: 0.5174 Time taken: 122.96s\n",
      "Epoch 71/200\n",
      "Training loss at step 0: 0.4114\n",
      "Training loss at step 100: 0.3675\n",
      "Training loss at step 200: 0.5776\n",
      "Training loss at step 300: 0.4739\n",
      "Training accuracy: 0.8454 Validation accuracy: 0.5118 Time taken: 122.73s\n",
      "Epoch 72/200\n",
      "Training loss at step 0: 0.3522\n",
      "Training loss at step 100: 0.3833\n",
      "Training loss at step 200: 0.5217\n",
      "Training loss at step 300: 0.5782\n",
      "Training accuracy: 0.8491 Validation accuracy: 0.5124 Time taken: 123.13s\n",
      "Epoch 73/200\n",
      "Training loss at step 0: 0.3466\n",
      "Training loss at step 100: 0.3970\n",
      "Training loss at step 200: 0.5513\n",
      "Training loss at step 300: 0.5047\n",
      "Training accuracy: 0.8520 Validation accuracy: 0.4500 Time taken: 123.28s\n",
      "Epoch 74/200\n",
      "Training loss at step 0: 0.3934\n",
      "Training loss at step 100: 0.5081\n",
      "Training loss at step 200: 0.5005\n",
      "Training loss at step 300: 0.5273\n",
      "Training accuracy: 0.8526 Validation accuracy: 0.5272 Time taken: 122.99s\n",
      "Epoch 75/200\n",
      "Training loss at step 0: 0.3908\n",
      "Training loss at step 100: 0.4216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 200: 0.6542\n",
      "Training loss at step 300: 0.5097\n",
      "Training accuracy: 0.8577 Validation accuracy: 0.5114 Time taken: 123.44s\n",
      "Epoch 76/200\n",
      "Training loss at step 0: 0.4512\n",
      "Training loss at step 100: 0.6346\n",
      "Training loss at step 200: 0.5471\n",
      "Training loss at step 300: 0.5076\n",
      "Training accuracy: 0.8616 Validation accuracy: 0.5262 Time taken: 122.96s\n",
      "Epoch 77/200\n",
      "Training loss at step 0: 0.3584\n",
      "Training loss at step 100: 0.3454\n",
      "Training loss at step 200: 0.4516\n",
      "Training loss at step 300: 0.3716\n",
      "Training accuracy: 0.8620 Validation accuracy: 0.4870 Time taken: 122.96s\n",
      "Epoch 78/200\n",
      "Training loss at step 0: 0.3715\n",
      "Training loss at step 100: 0.3151\n",
      "Training loss at step 200: 0.4066\n",
      "Training loss at step 300: 0.4340\n",
      "Training accuracy: 0.8680 Validation accuracy: 0.5270 Time taken: 123.11s\n",
      "Epoch 79/200\n",
      "Training loss at step 0: 0.3651\n",
      "Training loss at step 100: 0.4449\n",
      "Training loss at step 200: 0.3471\n",
      "Training loss at step 300: 0.3509\n",
      "Training accuracy: 0.8710 Validation accuracy: 0.4938 Time taken: 122.72s\n",
      "Epoch 80/200\n",
      "Training loss at step 0: 0.4112\n",
      "Training loss at step 100: 0.3601\n",
      "Training loss at step 200: 0.4725\n",
      "Training loss at step 300: 0.4171\n",
      "Training accuracy: 0.8744 Validation accuracy: 0.5034 Time taken: 122.91s\n",
      "Epoch 81/200\n",
      "Training loss at step 0: 0.3810\n",
      "Training loss at step 100: 0.4023\n",
      "Training loss at step 200: 0.3679\n",
      "Training loss at step 300: 0.4250\n",
      "Training accuracy: 0.8760 Validation accuracy: 0.5096 Time taken: 122.90s\n",
      "Epoch 82/200\n",
      "Training loss at step 0: 0.3432\n",
      "Training loss at step 100: 0.3293\n",
      "Training loss at step 200: 0.3461\n",
      "Training loss at step 300: 0.5014\n",
      "Training accuracy: 0.8794 Validation accuracy: 0.5246 Time taken: 122.79s\n",
      "Epoch 83/200\n",
      "Training loss at step 0: 0.3622\n",
      "Training loss at step 100: 0.4511\n",
      "Training loss at step 200: 0.3877\n",
      "Training loss at step 300: 0.3591\n",
      "Training accuracy: 0.8806 Validation accuracy: 0.5068 Time taken: 123.64s\n",
      "Epoch 84/200\n",
      "Training loss at step 0: 0.5476\n",
      "Training loss at step 100: 0.4229\n",
      "Training loss at step 200: 0.3290\n",
      "Training loss at step 300: 0.2917\n",
      "Training accuracy: 0.8854 Validation accuracy: 0.5190 Time taken: 122.86s\n",
      "Epoch 85/200\n",
      "Training loss at step 0: 0.3709\n",
      "Training loss at step 100: 0.3795\n",
      "Training loss at step 200: 0.2907\n",
      "Training loss at step 300: 0.3366\n",
      "Training accuracy: 0.8868 Validation accuracy: 0.5304 Time taken: 123.05s\n",
      "Epoch 86/200\n",
      "Training loss at step 0: 0.2520\n",
      "Training loss at step 100: 0.2045\n",
      "Training loss at step 200: 0.2421\n",
      "Training loss at step 300: 0.2917\n",
      "Training accuracy: 0.8900 Validation accuracy: 0.5292 Time taken: 122.32s\n",
      "Epoch 87/200\n",
      "Training loss at step 0: 0.3920\n",
      "Training loss at step 100: 0.4446\n",
      "Training loss at step 200: 0.3983\n",
      "Training loss at step 300: 0.3764\n",
      "Training accuracy: 0.8927 Validation accuracy: 0.5036 Time taken: 123.37s\n",
      "Epoch 88/200\n",
      "Training loss at step 0: 0.2024\n",
      "Training loss at step 100: 0.4603\n",
      "Training loss at step 200: 0.4080\n",
      "Training loss at step 300: 0.3959\n",
      "Training accuracy: 0.8923 Validation accuracy: 0.4412 Time taken: 122.74s\n",
      "Epoch 89/200\n",
      "Training loss at step 0: 0.3949\n",
      "Training loss at step 100: 0.2975\n",
      "Training loss at step 200: 0.2779\n",
      "Training loss at step 300: 0.2827\n",
      "Training accuracy: 0.8960 Validation accuracy: 0.5154 Time taken: 123.05s\n",
      "Epoch 90/200\n",
      "Training loss at step 0: 0.2965\n",
      "Training loss at step 100: 0.3342\n",
      "Training loss at step 200: 0.3621\n",
      "Training loss at step 300: 0.3145\n",
      "Training accuracy: 0.8937 Validation accuracy: 0.5394 Time taken: 123.50s\n",
      "Epoch 91/200\n",
      "Training loss at step 0: 0.2279\n",
      "Training loss at step 100: 0.2074\n",
      "Training loss at step 200: 0.3924\n",
      "Training loss at step 300: 0.4623\n",
      "Training accuracy: 0.9002 Validation accuracy: 0.5172 Time taken: 122.46s\n",
      "Epoch 92/200\n",
      "Training loss at step 0: 0.4099\n",
      "Training loss at step 100: 0.2188\n",
      "Training loss at step 200: 0.3220\n",
      "Training loss at step 300: 0.3037\n",
      "Training accuracy: 0.9009 Validation accuracy: 0.4974 Time taken: 122.55s\n",
      "Epoch 93/200\n",
      "Training loss at step 0: 0.2561\n",
      "Training loss at step 100: 0.2495\n",
      "Training loss at step 200: 0.2205\n",
      "Training loss at step 300: 0.4258\n",
      "Training accuracy: 0.9025 Validation accuracy: 0.5294 Time taken: 122.69s\n",
      "Epoch 94/200\n",
      "Training loss at step 0: 0.2779\n",
      "Training loss at step 100: 0.3567\n",
      "Training loss at step 200: 0.3423\n",
      "Training loss at step 300: 0.2485\n",
      "Training accuracy: 0.9044 Validation accuracy: 0.5134 Time taken: 123.60s\n",
      "Epoch 95/200\n",
      "Training loss at step 0: 0.4525\n",
      "Training loss at step 100: 0.2789\n",
      "Training loss at step 200: 0.2057\n",
      "Training loss at step 300: 0.4202\n",
      "Training accuracy: 0.9066 Validation accuracy: 0.5006 Time taken: 123.03s\n",
      "Epoch 96/200\n",
      "Training loss at step 0: 0.2994\n",
      "Training loss at step 100: 0.2391\n",
      "Training loss at step 200: 0.2672\n",
      "Training loss at step 300: 0.3321\n",
      "Training accuracy: 0.9108 Validation accuracy: 0.5160 Time taken: 123.07s\n",
      "Epoch 97/200\n",
      "Training loss at step 0: 0.2532\n",
      "Training loss at step 100: 0.2994\n",
      "Training loss at step 200: 0.2837\n",
      "Training loss at step 300: 0.2535\n",
      "Training accuracy: 0.9131 Validation accuracy: 0.5010 Time taken: 123.56s\n",
      "Epoch 98/200\n",
      "Training loss at step 0: 0.2459\n",
      "Training loss at step 100: 0.2078\n",
      "Training loss at step 200: 0.2927\n",
      "Training loss at step 300: 0.3176\n",
      "Training accuracy: 0.9128 Validation accuracy: 0.5500 Time taken: 123.53s\n",
      "Epoch 99/200\n",
      "Training loss at step 0: 0.2058\n",
      "Training loss at step 100: 0.2688\n",
      "Training loss at step 200: 0.3667\n",
      "Training loss at step 300: 0.2847\n",
      "Training accuracy: 0.9123 Validation accuracy: 0.5272 Time taken: 123.06s\n",
      "Epoch 100/200\n",
      "Training loss at step 0: 0.2106\n",
      "Training loss at step 100: 0.2506\n",
      "Training loss at step 200: 0.2593\n",
      "Training loss at step 300: 0.2060\n",
      "Training accuracy: 0.9187 Validation accuracy: 0.4966 Time taken: 123.42s\n",
      "Epoch 101/200\n",
      "Training loss at step 0: 0.2789\n",
      "Training loss at step 100: 0.1545\n",
      "Training loss at step 200: 0.1368\n",
      "Training loss at step 300: 0.1682\n",
      "Training accuracy: 0.9548 Validation accuracy: 0.6238 Time taken: 122.86s\n",
      "Epoch 102/200\n",
      "Training loss at step 0: 0.0768\n",
      "Training loss at step 100: 0.0922\n",
      "Training loss at step 200: 0.0840\n",
      "Training loss at step 300: 0.1038\n",
      "Training accuracy: 0.9685 Validation accuracy: 0.6292 Time taken: 123.29s\n",
      "Epoch 103/200\n",
      "Training loss at step 0: 0.0876\n",
      "Training loss at step 100: 0.0786\n",
      "Training loss at step 200: 0.0445\n",
      "Training loss at step 300: 0.0691\n",
      "Training accuracy: 0.9720 Validation accuracy: 0.6304 Time taken: 123.84s\n",
      "Epoch 104/200\n",
      "Training loss at step 0: 0.0580\n",
      "Training loss at step 100: 0.0784\n",
      "Training loss at step 200: 0.0570\n",
      "Training loss at step 300: 0.0989\n",
      "Training accuracy: 0.9754 Validation accuracy: 0.6306 Time taken: 122.94s\n",
      "Epoch 105/200\n",
      "Training loss at step 0: 0.1058\n",
      "Training loss at step 100: 0.0607\n",
      "Training loss at step 200: 0.0862\n",
      "Training loss at step 300: 0.0491\n",
      "Training accuracy: 0.9768 Validation accuracy: 0.6240 Time taken: 123.04s\n",
      "Epoch 106/200\n",
      "Training loss at step 0: 0.1366\n",
      "Training loss at step 100: 0.0576\n",
      "Training loss at step 200: 0.0520\n",
      "Training loss at step 300: 0.0987\n",
      "Training accuracy: 0.9776 Validation accuracy: 0.6302 Time taken: 123.47s\n",
      "Epoch 107/200\n",
      "Training loss at step 0: 0.0850\n",
      "Training loss at step 100: 0.0616\n",
      "Training loss at step 200: 0.1017\n",
      "Training loss at step 300: 0.0982\n",
      "Training accuracy: 0.9782 Validation accuracy: 0.6274 Time taken: 123.16s\n",
      "Epoch 108/200\n",
      "Training loss at step 0: 0.1052\n",
      "Training loss at step 100: 0.0539\n",
      "Training loss at step 200: 0.0974\n",
      "Training loss at step 300: 0.0624\n",
      "Training accuracy: 0.9804 Validation accuracy: 0.6306 Time taken: 123.67s\n",
      "Epoch 109/200\n",
      "Training loss at step 0: 0.1153\n",
      "Training loss at step 100: 0.0856\n",
      "Training loss at step 200: 0.0375\n",
      "Training loss at step 300: 0.1030\n",
      "Training accuracy: 0.9802 Validation accuracy: 0.6286 Time taken: 123.55s\n",
      "Epoch 110/200\n",
      "Training loss at step 0: 0.0383\n",
      "Training loss at step 100: 0.0893\n",
      "Training loss at step 200: 0.0780\n",
      "Training loss at step 300: 0.0529\n",
      "Training accuracy: 0.9804 Validation accuracy: 0.6296 Time taken: 122.81s\n",
      "Epoch 111/200\n",
      "Training loss at step 0: 0.0785\n",
      "Training loss at step 100: 0.0527\n",
      "Training loss at step 200: 0.1091\n",
      "Training loss at step 300: 0.1249\n",
      "Training accuracy: 0.9816 Validation accuracy: 0.6274 Time taken: 121.74s\n",
      "Epoch 112/200\n",
      "Training loss at step 0: 0.0620\n",
      "Training loss at step 100: 0.1123\n",
      "Training loss at step 200: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.0426\n",
      "Training accuracy: 0.9819 Validation accuracy: 0.6270 Time taken: 122.53s\n",
      "Epoch 113/200\n",
      "Training loss at step 0: 0.0420\n",
      "Training loss at step 100: 0.0587\n",
      "Training loss at step 200: 0.0351\n",
      "Training loss at step 300: 0.0546\n",
      "Training accuracy: 0.9827 Validation accuracy: 0.6294 Time taken: 121.94s\n",
      "Epoch 114/200\n",
      "Training loss at step 0: 0.0312\n",
      "Training loss at step 100: 0.0815\n",
      "Training loss at step 200: 0.0719\n",
      "Training loss at step 300: 0.0403\n",
      "Training accuracy: 0.9835 Validation accuracy: 0.6264 Time taken: 123.22s\n",
      "Epoch 115/200\n",
      "Training loss at step 0: 0.0752\n",
      "Training loss at step 100: 0.0692\n",
      "Training loss at step 200: 0.0473\n",
      "Training loss at step 300: 0.0431\n",
      "Training accuracy: 0.9842 Validation accuracy: 0.6268 Time taken: 123.09s\n",
      "Epoch 116/200\n",
      "Training loss at step 0: 0.0547\n",
      "Training loss at step 100: 0.1014\n",
      "Training loss at step 200: 0.0615\n",
      "Training loss at step 300: 0.0390\n",
      "Training accuracy: 0.9842 Validation accuracy: 0.6306 Time taken: 123.21s\n",
      "Epoch 117/200\n",
      "Training loss at step 0: 0.0267\n",
      "Training loss at step 100: 0.0643\n",
      "Training loss at step 200: 0.0899\n",
      "Training loss at step 300: 0.0294\n",
      "Training accuracy: 0.9859 Validation accuracy: 0.6282 Time taken: 123.33s\n",
      "Epoch 118/200\n",
      "Training loss at step 0: 0.0649\n",
      "Training loss at step 100: 0.0813\n",
      "Training loss at step 200: 0.0483\n",
      "Training loss at step 300: 0.0508\n",
      "Training accuracy: 0.9849 Validation accuracy: 0.6296 Time taken: 122.85s\n",
      "Epoch 119/200\n",
      "Training loss at step 0: 0.0485\n",
      "Training loss at step 100: 0.0479\n",
      "Training loss at step 200: 0.0578\n",
      "Training loss at step 300: 0.0909\n",
      "Training accuracy: 0.9854 Validation accuracy: 0.6282 Time taken: 122.90s\n",
      "Epoch 120/200\n",
      "Training loss at step 0: 0.0743\n",
      "Training loss at step 100: 0.0624\n",
      "Training loss at step 200: 0.0730\n",
      "Training loss at step 300: 0.0771\n",
      "Training accuracy: 0.9858 Validation accuracy: 0.6300 Time taken: 123.37s\n",
      "Epoch 121/200\n",
      "Training loss at step 0: 0.0465\n",
      "Training loss at step 100: 0.0387\n",
      "Training loss at step 200: 0.0822\n",
      "Training loss at step 300: 0.0594\n",
      "Training accuracy: 0.9868 Validation accuracy: 0.6278 Time taken: 123.29s\n",
      "Epoch 122/200\n",
      "Training loss at step 0: 0.0714\n",
      "Training loss at step 100: 0.0503\n",
      "Training loss at step 200: 0.1050\n",
      "Training loss at step 300: 0.0719\n",
      "Training accuracy: 0.9868 Validation accuracy: 0.6292 Time taken: 122.26s\n",
      "Epoch 123/200\n",
      "Training loss at step 0: 0.0719\n",
      "Training loss at step 100: 0.0448\n",
      "Training loss at step 200: 0.0200\n",
      "Training loss at step 300: 0.0634\n",
      "Training accuracy: 0.9867 Validation accuracy: 0.6278 Time taken: 123.37s\n",
      "Epoch 124/200\n",
      "Training loss at step 0: 0.0553\n",
      "Training loss at step 100: 0.0526\n",
      "Training loss at step 200: 0.0697\n",
      "Training loss at step 300: 0.0664\n",
      "Training accuracy: 0.9874 Validation accuracy: 0.6292 Time taken: 123.35s\n",
      "Epoch 125/200\n",
      "Training loss at step 0: 0.0395\n",
      "Training loss at step 100: 0.0408\n",
      "Training loss at step 200: 0.0475\n",
      "Training loss at step 300: 0.0653\n",
      "Training accuracy: 0.9861 Validation accuracy: 0.6280 Time taken: 123.26s\n",
      "Epoch 126/200\n",
      "Training loss at step 0: 0.0941\n",
      "Training loss at step 100: 0.0523\n",
      "Training loss at step 200: 0.0475\n",
      "Training loss at step 300: 0.0427\n",
      "Training accuracy: 0.9876 Validation accuracy: 0.6334 Time taken: 122.77s\n",
      "Epoch 127/200\n",
      "Training loss at step 0: 0.0594\n",
      "Training loss at step 100: 0.0594\n",
      "Training loss at step 200: 0.0721\n",
      "Training loss at step 300: 0.0695\n",
      "Training accuracy: 0.9879 Validation accuracy: 0.6332 Time taken: 123.30s\n",
      "Epoch 128/200\n",
      "Training loss at step 0: 0.0421\n",
      "Training loss at step 100: 0.0682\n",
      "Training loss at step 200: 0.0361\n",
      "Training loss at step 300: 0.0946\n",
      "Training accuracy: 0.9872 Validation accuracy: 0.6266 Time taken: 123.09s\n",
      "Epoch 129/200\n",
      "Training loss at step 0: 0.1375\n",
      "Training loss at step 100: 0.1155\n",
      "Training loss at step 200: 0.0600\n",
      "Training loss at step 300: 0.0819\n",
      "Training accuracy: 0.9881 Validation accuracy: 0.6280 Time taken: 122.87s\n",
      "Epoch 130/200\n",
      "Training loss at step 0: 0.0382\n",
      "Training loss at step 100: 0.0608\n",
      "Training loss at step 200: 0.0744\n",
      "Training loss at step 300: 0.0566\n",
      "Training accuracy: 0.9884 Validation accuracy: 0.6298 Time taken: 123.77s\n",
      "Epoch 131/200\n",
      "Training loss at step 0: 0.0454\n",
      "Training loss at step 100: 0.0350\n",
      "Training loss at step 200: 0.0343\n",
      "Training loss at step 300: 0.0606\n",
      "Training accuracy: 0.9884 Validation accuracy: 0.6304 Time taken: 123.78s\n",
      "Epoch 132/200\n",
      "Training loss at step 0: 0.0596\n",
      "Training loss at step 100: 0.0942\n",
      "Training loss at step 200: 0.0328\n",
      "Training loss at step 300: 0.0507\n",
      "Training accuracy: 0.9884 Validation accuracy: 0.6256 Time taken: 123.45s\n",
      "Epoch 133/200\n",
      "Training loss at step 0: 0.0689\n",
      "Training loss at step 100: 0.0804\n",
      "Training loss at step 200: 0.0541\n",
      "Training loss at step 300: 0.0639\n",
      "Training accuracy: 0.9886 Validation accuracy: 0.6272 Time taken: 123.14s\n",
      "Epoch 134/200\n",
      "Training loss at step 0: 0.0545\n",
      "Training loss at step 100: 0.0310\n",
      "Training loss at step 200: 0.0412\n",
      "Training loss at step 300: 0.0345\n",
      "Training accuracy: 0.9886 Validation accuracy: 0.6274 Time taken: 122.66s\n",
      "Epoch 135/200\n",
      "Training loss at step 0: 0.0265\n",
      "Training loss at step 100: 0.0289\n",
      "Training loss at step 200: 0.0748\n",
      "Training loss at step 300: 0.0470\n",
      "Training accuracy: 0.9890 Validation accuracy: 0.6292 Time taken: 123.14s\n",
      "Epoch 136/200\n",
      "Training loss at step 0: 0.0695\n",
      "Training loss at step 100: 0.0994\n",
      "Training loss at step 200: 0.0553\n",
      "Training loss at step 300: 0.0799\n",
      "Training accuracy: 0.9891 Validation accuracy: 0.6276 Time taken: 122.75s\n",
      "Epoch 137/200\n",
      "Training loss at step 0: 0.0316\n",
      "Training loss at step 100: 0.0729\n",
      "Training loss at step 200: 0.0418\n",
      "Training loss at step 300: 0.0523\n",
      "Training accuracy: 0.9892 Validation accuracy: 0.6286 Time taken: 122.95s\n",
      "Epoch 138/200\n",
      "Training loss at step 0: 0.0426\n",
      "Training loss at step 100: 0.0290\n",
      "Training loss at step 200: 0.0124\n",
      "Training loss at step 300: 0.0603\n",
      "Training accuracy: 0.9894 Validation accuracy: 0.6296 Time taken: 123.13s\n",
      "Epoch 139/200\n",
      "Training loss at step 0: 0.0628\n",
      "Training loss at step 100: 0.0520\n",
      "Training loss at step 200: 0.0425\n",
      "Training loss at step 300: 0.0296\n",
      "Training accuracy: 0.9900 Validation accuracy: 0.6274 Time taken: 123.27s\n",
      "Epoch 140/200\n",
      "Training loss at step 0: 0.0585\n",
      "Training loss at step 100: 0.0345\n",
      "Training loss at step 200: 0.0383\n",
      "Training loss at step 300: 0.0240\n",
      "Training accuracy: 0.9902 Validation accuracy: 0.6298 Time taken: 122.80s\n",
      "Epoch 141/200\n",
      "Training loss at step 0: 0.0538\n",
      "Training loss at step 100: 0.0587\n",
      "Training loss at step 200: 0.0528\n",
      "Training loss at step 300: 0.0472\n",
      "Training accuracy: 0.9901 Validation accuracy: 0.6306 Time taken: 122.92s\n",
      "Epoch 142/200\n",
      "Training loss at step 0: 0.0295\n",
      "Training loss at step 100: 0.0475\n",
      "Training loss at step 200: 0.0380\n",
      "Training loss at step 300: 0.0390\n",
      "Training accuracy: 0.9901 Validation accuracy: 0.6288 Time taken: 122.25s\n",
      "Epoch 143/200\n",
      "Training loss at step 0: 0.0371\n",
      "Training loss at step 100: 0.0385\n",
      "Training loss at step 200: 0.0723\n",
      "Training loss at step 300: 0.0469\n",
      "Training accuracy: 0.9904 Validation accuracy: 0.6278 Time taken: 122.93s\n",
      "Epoch 144/200\n",
      "Training loss at step 0: 0.0325\n",
      "Training loss at step 100: 0.0502\n",
      "Training loss at step 200: 0.0643\n",
      "Training loss at step 300: 0.0158\n",
      "Training accuracy: 0.9904 Validation accuracy: 0.6292 Time taken: 123.37s\n",
      "Epoch 145/200\n",
      "Training loss at step 0: 0.0306\n",
      "Training loss at step 100: 0.0245\n",
      "Training loss at step 200: 0.0421\n",
      "Training loss at step 300: 0.0239\n",
      "Training accuracy: 0.9912 Validation accuracy: 0.6282 Time taken: 122.71s\n",
      "Epoch 146/200\n",
      "Training loss at step 0: 0.0411\n",
      "Training loss at step 100: 0.0630\n",
      "Training loss at step 200: 0.0383\n",
      "Training loss at step 300: 0.0498\n",
      "Training accuracy: 0.9904 Validation accuracy: 0.6290 Time taken: 122.56s\n",
      "Epoch 147/200\n",
      "Training loss at step 0: 0.0361\n",
      "Training loss at step 100: 0.0397\n",
      "Training loss at step 200: 0.0214\n",
      "Training loss at step 300: 0.0482\n",
      "Training accuracy: 0.9909 Validation accuracy: 0.6310 Time taken: 122.68s\n",
      "Epoch 148/200\n",
      "Training loss at step 0: 0.0401\n",
      "Training loss at step 100: 0.0274\n",
      "Training loss at step 200: 0.0187\n",
      "Training loss at step 300: 0.0351\n",
      "Training accuracy: 0.9897 Validation accuracy: 0.6300 Time taken: 122.39s\n",
      "Epoch 149/200\n",
      "Training loss at step 0: 0.0660\n",
      "Training loss at step 100: 0.0445\n",
      "Training loss at step 200: 0.0511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.0318\n",
      "Training accuracy: 0.9906 Validation accuracy: 0.6254 Time taken: 124.63s\n",
      "Epoch 150/200\n",
      "Training loss at step 0: 0.0429\n",
      "Training loss at step 100: 0.0313\n",
      "Training loss at step 200: 0.0374\n",
      "Training loss at step 300: 0.0430\n",
      "Training accuracy: 0.9904 Validation accuracy: 0.6300 Time taken: 124.47s\n",
      "Epoch 151/200\n",
      "Training loss at step 0: 0.0365\n",
      "Training loss at step 100: 0.0409\n",
      "Training loss at step 200: 0.0405\n",
      "Training loss at step 300: 0.0259\n",
      "Training accuracy: 0.9912 Validation accuracy: 0.6290 Time taken: 123.45s\n",
      "Epoch 152/200\n",
      "Training loss at step 0: 0.0385\n",
      "Training loss at step 100: 0.0345\n",
      "Training loss at step 200: 0.0286\n",
      "Training loss at step 300: 0.0218\n",
      "Training accuracy: 0.9920 Validation accuracy: 0.6284 Time taken: 122.66s\n",
      "Epoch 153/200\n",
      "Training loss at step 0: 0.0381\n",
      "Training loss at step 100: 0.0230\n",
      "Training loss at step 200: 0.0364\n",
      "Training loss at step 300: 0.0399\n",
      "Training accuracy: 0.9912 Validation accuracy: 0.6306 Time taken: 122.94s\n",
      "Epoch 154/200\n",
      "Training loss at step 0: 0.0224\n",
      "Training loss at step 100: 0.0504\n",
      "Training loss at step 200: 0.0454\n",
      "Training loss at step 300: 0.0205\n",
      "Training accuracy: 0.9916 Validation accuracy: 0.6300 Time taken: 123.04s\n",
      "Epoch 155/200\n",
      "Training loss at step 0: 0.0243\n",
      "Training loss at step 100: 0.0321\n",
      "Training loss at step 200: 0.0617\n",
      "Training loss at step 300: 0.0256\n",
      "Training accuracy: 0.9916 Validation accuracy: 0.6300 Time taken: 122.88s\n",
      "Epoch 156/200\n",
      "Training loss at step 0: 0.0234\n",
      "Training loss at step 100: 0.0249\n",
      "Training loss at step 200: 0.0542\n",
      "Training loss at step 300: 0.0490\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6286 Time taken: 123.07s\n",
      "Epoch 157/200\n",
      "Training loss at step 0: 0.0391\n",
      "Training loss at step 100: 0.0350\n",
      "Training loss at step 200: 0.0343\n",
      "Training loss at step 300: 0.0452\n",
      "Training accuracy: 0.9907 Validation accuracy: 0.6304 Time taken: 122.90s\n",
      "Epoch 158/200\n",
      "Training loss at step 0: 0.0307\n",
      "Training loss at step 100: 0.0412\n",
      "Training loss at step 200: 0.0257\n",
      "Training loss at step 300: 0.0788\n",
      "Training accuracy: 0.9921 Validation accuracy: 0.6296 Time taken: 122.89s\n",
      "Epoch 159/200\n",
      "Training loss at step 0: 0.0551\n",
      "Training loss at step 100: 0.0362\n",
      "Training loss at step 200: 0.0317\n",
      "Training loss at step 300: 0.0185\n",
      "Training accuracy: 0.9914 Validation accuracy: 0.6302 Time taken: 123.57s\n",
      "Epoch 160/200\n",
      "Training loss at step 0: 0.0242\n",
      "Training loss at step 100: 0.0494\n",
      "Training loss at step 200: 0.0601\n",
      "Training loss at step 300: 0.0415\n",
      "Training accuracy: 0.9913 Validation accuracy: 0.6302 Time taken: 122.80s\n",
      "Epoch 161/200\n",
      "Training loss at step 0: 0.0291\n",
      "Training loss at step 100: 0.0509\n",
      "Training loss at step 200: 0.0239\n",
      "Training loss at step 300: 0.0330\n",
      "Training accuracy: 0.9917 Validation accuracy: 0.6302 Time taken: 122.06s\n",
      "Epoch 162/200\n",
      "Training loss at step 0: 0.0399\n",
      "Training loss at step 100: 0.0491\n",
      "Training loss at step 200: 0.0338\n",
      "Training loss at step 300: 0.0461\n",
      "Training accuracy: 0.9916 Validation accuracy: 0.6308 Time taken: 122.68s\n",
      "Epoch 163/200\n",
      "Training loss at step 0: 0.0392\n",
      "Training loss at step 100: 0.0262\n",
      "Training loss at step 200: 0.0519\n",
      "Training loss at step 300: 0.0310\n",
      "Training accuracy: 0.9923 Validation accuracy: 0.6320 Time taken: 123.49s\n",
      "Epoch 164/200\n",
      "Training loss at step 0: 0.0360\n",
      "Training loss at step 100: 0.0361\n",
      "Training loss at step 200: 0.0642\n",
      "Training loss at step 300: 0.0595\n",
      "Training accuracy: 0.9922 Validation accuracy: 0.6308 Time taken: 122.87s\n",
      "Epoch 165/200\n",
      "Training loss at step 0: 0.0312\n",
      "Training loss at step 100: 0.0330\n",
      "Training loss at step 200: 0.0727\n",
      "Training loss at step 300: 0.0706\n",
      "Training accuracy: 0.9919 Validation accuracy: 0.6314 Time taken: 121.26s\n",
      "Epoch 166/200\n",
      "Training loss at step 0: 0.0323\n",
      "Training loss at step 100: 0.0415\n",
      "Training loss at step 200: 0.0328\n",
      "Training loss at step 300: 0.0552\n",
      "Training accuracy: 0.9923 Validation accuracy: 0.6310 Time taken: 121.96s\n",
      "Epoch 167/200\n",
      "Training loss at step 0: 0.0519\n",
      "Training loss at step 100: 0.0583\n",
      "Training loss at step 200: 0.0336\n",
      "Training loss at step 300: 0.0272\n",
      "Training accuracy: 0.9920 Validation accuracy: 0.6298 Time taken: 122.11s\n",
      "Epoch 168/200\n",
      "Training loss at step 0: 0.0671\n",
      "Training loss at step 100: 0.0241\n",
      "Training loss at step 200: 0.0690\n",
      "Training loss at step 300: 0.0288\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6302 Time taken: 122.51s\n",
      "Epoch 169/200\n",
      "Training loss at step 0: 0.0367\n",
      "Training loss at step 100: 0.0329\n",
      "Training loss at step 200: 0.0223\n",
      "Training loss at step 300: 0.0304\n",
      "Training accuracy: 0.9925 Validation accuracy: 0.6304 Time taken: 123.23s\n",
      "Epoch 170/200\n",
      "Training loss at step 0: 0.0303\n",
      "Training loss at step 100: 0.0330\n",
      "Training loss at step 200: 0.0239\n",
      "Training loss at step 300: 0.0419\n",
      "Training accuracy: 0.9924 Validation accuracy: 0.6302 Time taken: 123.11s\n",
      "Epoch 171/200\n",
      "Training loss at step 0: 0.0222\n",
      "Training loss at step 100: 0.0259\n",
      "Training loss at step 200: 0.0234\n",
      "Training loss at step 300: 0.0289\n",
      "Training accuracy: 0.9916 Validation accuracy: 0.6302 Time taken: 122.86s\n",
      "Epoch 172/200\n",
      "Training loss at step 0: 0.0464\n",
      "Training loss at step 100: 0.0306\n",
      "Training loss at step 200: 0.0310\n",
      "Training loss at step 300: 0.0441\n",
      "Training accuracy: 0.9924 Validation accuracy: 0.6284 Time taken: 123.18s\n",
      "Epoch 173/200\n",
      "Training loss at step 0: 0.0559\n",
      "Training loss at step 100: 0.0555\n",
      "Training loss at step 200: 0.0352\n",
      "Training loss at step 300: 0.0167\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6296 Time taken: 123.53s\n",
      "Epoch 174/200\n",
      "Training loss at step 0: 0.0426\n",
      "Training loss at step 100: 0.0292\n",
      "Training loss at step 200: 0.0666\n",
      "Training loss at step 300: 0.0522\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6298 Time taken: 123.37s\n",
      "Epoch 175/200\n",
      "Training loss at step 0: 0.0473\n",
      "Training loss at step 100: 0.0205\n",
      "Training loss at step 200: 0.0394\n",
      "Training loss at step 300: 0.0182\n",
      "Training accuracy: 0.9928 Validation accuracy: 0.6286 Time taken: 123.27s\n",
      "Epoch 176/200\n",
      "Training loss at step 0: 0.0275\n",
      "Training loss at step 100: 0.0438\n",
      "Training loss at step 200: 0.0363\n",
      "Training loss at step 300: 0.0625\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6288 Time taken: 123.37s\n",
      "Epoch 177/200\n",
      "Training loss at step 0: 0.0224\n",
      "Training loss at step 100: 0.0746\n",
      "Training loss at step 200: 0.0299\n",
      "Training loss at step 300: 0.0313\n",
      "Training accuracy: 0.9915 Validation accuracy: 0.6284 Time taken: 122.92s\n",
      "Epoch 178/200\n",
      "Training loss at step 0: 0.0191\n",
      "Training loss at step 100: 0.0245\n",
      "Training loss at step 200: 0.0478\n",
      "Training loss at step 300: 0.0307\n",
      "Training accuracy: 0.9928 Validation accuracy: 0.6292 Time taken: 122.69s\n",
      "Epoch 179/200\n",
      "Training loss at step 0: 0.0345\n",
      "Training loss at step 100: 0.0374\n",
      "Training loss at step 200: 0.0421\n",
      "Training loss at step 300: 0.0581\n",
      "Training accuracy: 0.9921 Validation accuracy: 0.6286 Time taken: 123.53s\n",
      "Epoch 180/200\n",
      "Training loss at step 0: 0.0200\n",
      "Training loss at step 100: 0.0357\n",
      "Training loss at step 200: 0.0233\n",
      "Training loss at step 300: 0.0484\n",
      "Training accuracy: 0.9924 Validation accuracy: 0.6302 Time taken: 123.81s\n",
      "Epoch 181/200\n",
      "Training loss at step 0: 0.0245\n",
      "Training loss at step 100: 0.0280\n",
      "Training loss at step 200: 0.0431\n",
      "Training loss at step 300: 0.0254\n",
      "Training accuracy: 0.9923 Validation accuracy: 0.6284 Time taken: 123.43s\n",
      "Epoch 182/200\n",
      "Training loss at step 0: 0.0547\n",
      "Training loss at step 100: 0.0423\n",
      "Training loss at step 200: 0.0189\n",
      "Training loss at step 300: 0.0685\n",
      "Training accuracy: 0.9928 Validation accuracy: 0.6298 Time taken: 123.50s\n",
      "Epoch 183/200\n",
      "Training loss at step 0: 0.0524\n",
      "Training loss at step 100: 0.0279\n",
      "Training loss at step 200: 0.0441\n",
      "Training loss at step 300: 0.1082\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6302 Time taken: 122.52s\n",
      "Epoch 184/200\n",
      "Training loss at step 0: 0.0323\n",
      "Training loss at step 100: 0.0175\n",
      "Training loss at step 200: 0.0378\n",
      "Training loss at step 300: 0.0329\n",
      "Training accuracy: 0.9918 Validation accuracy: 0.6312 Time taken: 123.08s\n",
      "Epoch 185/200\n",
      "Training loss at step 0: 0.0439\n",
      "Training loss at step 100: 0.0514\n",
      "Training loss at step 200: 0.0470\n",
      "Training loss at step 300: 0.0509\n",
      "Training accuracy: 0.9921 Validation accuracy: 0.6296 Time taken: 122.66s\n",
      "Epoch 186/200\n",
      "Training loss at step 0: 0.0380\n",
      "Training loss at step 100: 0.0156\n",
      "Training loss at step 200: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at step 300: 0.0622\n",
      "Training accuracy: 0.9930 Validation accuracy: 0.6294 Time taken: 121.44s\n",
      "Epoch 187/200\n",
      "Training loss at step 0: 0.0257\n",
      "Training loss at step 100: 0.0159\n",
      "Training loss at step 200: 0.0399\n",
      "Training loss at step 300: 0.0596\n",
      "Training accuracy: 0.9923 Validation accuracy: 0.6292 Time taken: 122.16s\n",
      "Epoch 188/200\n",
      "Training loss at step 0: 0.0251\n",
      "Training loss at step 100: 0.0284\n",
      "Training loss at step 200: 0.0226\n",
      "Training loss at step 300: 0.0413\n",
      "Training accuracy: 0.9928 Validation accuracy: 0.6286 Time taken: 122.80s\n",
      "Epoch 189/200\n",
      "Training loss at step 0: 0.0250\n",
      "Training loss at step 100: 0.0388\n",
      "Training loss at step 200: 0.0250\n",
      "Training loss at step 300: 0.0250\n",
      "Training accuracy: 0.9927 Validation accuracy: 0.6288 Time taken: 123.22s\n",
      "Epoch 190/200\n",
      "Training loss at step 0: 0.0356\n",
      "Training loss at step 100: 0.0511\n",
      "Training loss at step 200: 0.0210\n",
      "Training loss at step 300: 0.0421\n",
      "Training accuracy: 0.9924 Validation accuracy: 0.6286 Time taken: 123.12s\n",
      "Epoch 191/200\n",
      "Training loss at step 0: 0.0240\n",
      "Training loss at step 100: 0.0294\n",
      "Training loss at step 200: 0.0401\n",
      "Training loss at step 300: 0.0338\n",
      "Training accuracy: 0.9915 Validation accuracy: 0.6284 Time taken: 123.51s\n",
      "Epoch 192/200\n",
      "Training loss at step 0: 0.0465\n",
      "Training loss at step 100: 0.0342\n",
      "Training loss at step 200: 0.0410\n",
      "Training loss at step 300: 0.0297\n",
      "Training accuracy: 0.9926 Validation accuracy: 0.6300 Time taken: 122.44s\n",
      "Epoch 193/200\n",
      "Training loss at step 0: 0.0159\n",
      "Training loss at step 100: 0.0204\n",
      "Training loss at step 200: 0.0334\n",
      "Training loss at step 300: 0.0116\n",
      "Training accuracy: 0.9928 Validation accuracy: 0.6298 Time taken: 123.19s\n",
      "Epoch 194/200\n",
      "Training loss at step 0: 0.0400\n",
      "Training loss at step 100: 0.0505\n",
      "Training loss at step 200: 0.0737\n",
      "Training loss at step 300: 0.0240\n",
      "Training accuracy: 0.9922 Validation accuracy: 0.6290 Time taken: 122.84s\n",
      "Epoch 195/200\n",
      "Training loss at step 0: 0.0361\n",
      "Training loss at step 100: 0.0567\n",
      "Training loss at step 200: 0.0232\n",
      "Training loss at step 300: 0.0265\n",
      "Training accuracy: 0.9917 Validation accuracy: 0.6286 Time taken: 122.24s\n",
      "Epoch 196/200\n",
      "Training loss at step 0: 0.0347\n",
      "Training loss at step 100: 0.0332\n",
      "Training loss at step 200: 0.0377\n",
      "Training loss at step 300: 0.0257\n",
      "Training accuracy: 0.9927 Validation accuracy: 0.6290 Time taken: 124.35s\n",
      "Epoch 197/200\n",
      "Training loss at step 0: 0.0369\n",
      "Training loss at step 100: 0.0310\n",
      "Training loss at step 200: 0.0589\n",
      "Training loss at step 300: 0.0225\n",
      "Training accuracy: 0.9924 Validation accuracy: 0.6310 Time taken: 122.25s\n",
      "Epoch 198/200\n",
      "Training loss at step 0: 0.0332\n",
      "Training loss at step 100: 0.0266\n",
      "Training loss at step 200: 0.0294\n",
      "Training loss at step 300: 0.0484\n",
      "Training accuracy: 0.9925 Validation accuracy: 0.6302 Time taken: 122.47s\n",
      "Epoch 199/200\n",
      "Training loss at step 0: 0.0276\n",
      "Training loss at step 100: 0.0383\n",
      "Training loss at step 200: 0.0191\n",
      "Training loss at step 300: 0.0428\n",
      "Training accuracy: 0.9920 Validation accuracy: 0.6304 Time taken: 122.37s\n",
      "Epoch 200/200\n",
      "Training loss at step 0: 0.0396\n",
      "Training loss at step 100: 0.0334\n",
      "Training loss at step 200: 0.0073\n",
      "Training loss at step 300: 0.0307\n",
      "Training accuracy: 0.9924 Validation accuracy: 0.6302 Time taken: 122.56s\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1,nesterov=True)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "history = [[],[],[]]\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch %d/%d\" % (epoch+1,epochs))\n",
    "    if (epoch==100) | (epoch==150):\n",
    "        optimizer.learning_rate = optimizer.learning_rate/10\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step = 0\n",
    "    for x_batch_train, y_batch_train in train_data:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        if step % 100 == 0:\n",
    "            print(\n",
    "                \"Training loss at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "        step += 1\n",
    "        if step > len(x_train)/batch_size:\n",
    "            break\n",
    "\n",
    "    history[0].append(loss_value.numpy())\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    \n",
    "    step = 0\n",
    "    for x_batch_val, y_batch_val in validation_data:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "        step += 1\n",
    "        if step > len(x_val)/batch_size:\n",
    "            break\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    history[1].append(train_acc.numpy())\n",
    "    history[2].append(val_acc.numpy())\n",
    "    print(\"Training accuracy: %.4f\" % (float(train_acc),)\n",
    "          ,\"Validation accuracy: %.4f\" % (float(val_acc),),\"Time taken: %.2fs\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9b850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = np.array(history)\n",
    "# np.save(\"./Logs/ResNet110_cifar100\",log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9967c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Logs/ResNet110_cifar100.npy', 'rb') as f:\n",
    "     log = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d0d541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f504b8e72e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(1-log[1],label='training error')\n",
    "plt.plot(1-log[2],label='validation error')\n",
    "plt.ylim(0,0.9)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2fdf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6283"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "m.update_state(y_test, y_pred)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9970d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
